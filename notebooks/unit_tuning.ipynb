{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc5767d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run common_imports.py\n",
    "import seaborn as sns\n",
    "%matplotlib qt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "pd.options.display.max_rows = 600\n",
    "pd.set_option('display.float_format', lambda x: '%.9f' % x)\n",
    "\n",
    "dj.config['display.limit'] = 10**3  \n",
    "\n",
    "os.environ[\"SPYGLASS_USE_TRANSACTIONS\"] = \"1\"  \n",
    "os.environ['KACHERY_API_KEY'] = \"RhysjLwgmBAt2ObCyXXaDnqAv2kTdYRa\"\n",
    "\n",
    "import sys\n",
    "import tuning_analysis.sorting_multiprocessing as smp\n",
    "import spyglass.spikesorting.v1 as sgs\n",
    "import spikeinterface as si\n",
    "import spikeinterface.widgets as sw\n",
    "import spikeinterface.core as sc\n",
    "import spyglass.position.v1 as sgp\n",
    "import spyglass.linearization.v1 as sgpl\n",
    "\n",
    "from spyglass.position import PositionOutput\n",
    "from spyglass.spikesorting.analysis.v1.group import UnitSelectionParams\n",
    "from spyglass.spikesorting.analysis.v1.group import SortedSpikesGroup\n",
    "from tuning_analysis.trial_extraction import *\n",
    "from spyglass.spikesorting.spikesorting_merge import SpikeSortingOutput\n",
    "from tuning_analysis.spike_analysis import *\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d236b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFHRFWHRUaXRsZQB0YWIyMCBjb2xvcm1hcM5rFwoAAAAadEVYdERlc2NyaXB0aW9uAHRhYjIwIGNvbG9ybWFwMDS+7AAAADF0RVh0QXV0aG9yAE1hdHBsb3RsaWIgdjMuMTAuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZxYcXggAAAAzdEVYdFNvZnR3YXJlAE1hdHBsb3RsaWIgdjMuMTAuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ7M4TfwAAAHGSURBVHic7dYxStYBHIfxr56gQcIhfDelwSBoaBCFBnndbA46gEngokewzanVsa3NoRuIUwdojI6ga53i9yf4fj4XeNZnY3V19zcLuDl9s0Qm73/szkcOzuYbSfb/3I03zo8+jjeS5HB9O954efF5vJEkX3/ujTden2yPN5Lk/tvlIp23xyfjjdWvV+ONJNk6ejbe+PLwfbyRJOv1erzx+PRhvJEkq51P442D3+/GG0ly/eL5Ip3NRSoAwH/FAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIX+AfjSGNwLVnItAAAAAElFTkSuQmCC",
      "text/html": [
       "<div style=\"vertical-align: middle;\"><strong>tab20</strong> </div><div class=\"cmap\"><img alt=\"tab20 colormap\" title=\"tab20\" style=\"border: 1px solid #555;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFHRFWHRUaXRsZQB0YWIyMCBjb2xvcm1hcM5rFwoAAAAadEVYdERlc2NyaXB0aW9uAHRhYjIwIGNvbG9ybWFwMDS+7AAAADF0RVh0QXV0aG9yAE1hdHBsb3RsaWIgdjMuMTAuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZxYcXggAAAAzdEVYdFNvZnR3YXJlAE1hdHBsb3RsaWIgdjMuMTAuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ7M4TfwAAAHGSURBVHic7dYxStYBHIfxr56gQcIhfDelwSBoaBCFBnndbA46gEngokewzanVsa3NoRuIUwdojI6ga53i9yf4fj4XeNZnY3V19zcLuDl9s0Qm73/szkcOzuYbSfb/3I03zo8+jjeS5HB9O954efF5vJEkX3/ujTden2yPN5Lk/tvlIp23xyfjjdWvV+ONJNk6ejbe+PLwfbyRJOv1erzx+PRhvJEkq51P442D3+/GG0ly/eL5Ip3NRSoAwH/FAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIX+AfjSGNwLVnItAAAAAElFTkSuQmCC\"></div><div style=\"vertical-align: middle; max-width: 514px; display: flex; justify-content: space-between;\"><div style=\"float: left;\"><div title=\"#1f77b4ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #1f77b4ff;\"></div> under</div><div style=\"margin: 0 auto; display: inline-block;\">bad <div title=\"#00000000\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00000000;\"></div></div><div style=\"float: right;\">over <div title=\"#9edae5ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #9edae5ff;\"></div></div></div>"
      ],
      "text/plain": [
       "<matplotlib.colors.ListedColormap at 0x77195c657be0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cycler import cycler\n",
    "cmap = 'tab20'\n",
    "n_colors = 6\n",
    "cmap = plt.get_cmap(cmap)\n",
    "colors = [cmap(i) for i in np.linspace(0,1,n_colors)]\n",
    "plt.rcParams[\"axes.prop_cycle\"] = cycler(color = colors)\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['font.family'] = 'Sans'/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb7e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select track graph\n",
    "graph = sgpl.TrackGraph() & {\"track_graph_name\":\"Wtrack_wilbur20210512\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328fb55",
   "metadata": {},
   "source": [
    "### Plot unit-wise spiking locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eff9f01",
   "metadata": {},
   "source": [
    "#### Fetch spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d1f8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:17:59][WARNING] Spyglass: V0 requires artifact restrict. Ignoring \"restrict_by_artifact\" flag.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    <style type=\"text/css\">\n",
       "        .Table{\n",
       "            border-collapse:collapse;\n",
       "        }\n",
       "        .Table th{\n",
       "            background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "            font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "        }\n",
       "        .Table td{\n",
       "            padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "        }\n",
       "        .Table tr:nth-child(odd){\n",
       "            background: #ffffff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        .Table tr:nth-child(even){\n",
       "            background: #f3f1ff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        /* Tooltip container */\n",
       "        .djtooltip {\n",
       "        }\n",
       "        /* Tooltip text */\n",
       "        .djtooltip .djtooltiptext {\n",
       "            visibility: hidden;\n",
       "            width: 120px;\n",
       "            background-color: black;\n",
       "            color: #fff;\n",
       "            text-align: center;\n",
       "            padding: 5px 0;\n",
       "            border-radius: 6px;\n",
       "            /* Position the tooltip text - see examples below! */\n",
       "            position: absolute;\n",
       "            z-index: 1;\n",
       "        }\n",
       "        #primary {\n",
       "            font-weight: bold;\n",
       "            color: black;\n",
       "        }\n",
       "        #nonprimary {\n",
       "            font-weight: normal;\n",
       "            color: white;\n",
       "        }\n",
       "\n",
       "        /* Show the tooltip text when you mouse over the tooltip container */\n",
       "        .djtooltip:hover .djtooltiptext {\n",
       "            visibility: visible;\n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "    <b></b>\n",
       "        <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "        <table border=\"1\" class=\"Table\">\n",
       "            <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">merge_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">sorting_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">curation_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div> </th> </tr> </thead>\n",
       "            <tbody> <tr> <td>047f4da5-c1d4-ca9e-f923-cdb63c0d04e7</td>\n",
       "<td>d14d9669-4f3e-47c8-bed9-e0cc90be7a71</td>\n",
       "<td>2</td></tr><tr><td>0a29f32c-7036-e6bb-fd45-dc7ac35137fe</td>\n",
       "<td>45539c29-3436-4633-b63d-f499fe8e4073</td>\n",
       "<td>2</td></tr><tr><td>1a818a97-6f62-8d75-565f-7be81c6961c3</td>\n",
       "<td>ee34cd1e-e742-4c73-bdae-9974c2b1d74a</td>\n",
       "<td>2</td></tr><tr><td>3b2a05fa-9642-5ef4-58d7-1f8e9bf3e217</td>\n",
       "<td>76904362-d49e-4883-98d1-442822ebb9a1</td>\n",
       "<td>2</td></tr><tr><td>4db00acd-003c-de9a-b640-fb78fb276985</td>\n",
       "<td>df857aaa-ccd8-4abf-82e2-e9b97706c162</td>\n",
       "<td>2</td></tr><tr><td>6e499686-18c3-ef61-e344-d4e7d7c5e773</td>\n",
       "<td>bae249c1-f797-4e38-83ee-a21f51684a20</td>\n",
       "<td>2</td></tr><tr><td>70ca787c-23b6-feb6-84af-6e3ba338fdf3</td>\n",
       "<td>1dd1e911-c185-4488-b607-83502ac5225f</td>\n",
       "<td>2</td></tr><tr><td>d4644925-b88e-850f-36a2-291d1e1b99f7</td>\n",
       "<td>48a2c037-f872-4a63-9ccb-1bd14cb727e4</td>\n",
       "<td>2</td></tr><tr><td>e7eb99a4-da0e-a1ca-3be6-36e6037f9275</td>\n",
       "<td>6868b312-14db-473b-ae34-ce1bd193055d</td>\n",
       "<td>2</td></tr><tr><td>e9df24a9-9413-0623-2987-3064c50394ed</td>\n",
       "<td>0c0d6f10-5af6-4add-beac-67f101ecb017</td>\n",
       "<td>2</td></tr><tr><td>f04678f5-4b56-818c-3865-95449b8721d8</td>\n",
       "<td>f3df9cb1-5729-4521-8624-1dd556b3adb2</td>\n",
       "<td>2</td></tr><tr><td>fae2cacf-00d2-891f-441e-abf3f51a5206</td>\n",
       "<td>103990e9-2063-4541-906e-5c69fdf42339</td>\n",
       "<td>2</td> </tr> </tbody>\n",
       "        </table>\n",
       "        \n",
       "        <p>Total: 12</p></div>\n",
       "        "
      ],
      "text/plain": [
       "*merge_id      sorting_id     curation_id   \n",
       "+------------+ +------------+ +------------+\n",
       "047f4da5-c1d4- d14d9669-4f3e- 2             \n",
       "0a29f32c-7036- 45539c29-3436- 2             \n",
       "1a818a97-6f62- ee34cd1e-e742- 2             \n",
       "3b2a05fa-9642- 76904362-d49e- 2             \n",
       "4db00acd-003c- df857aaa-ccd8- 2             \n",
       "6e499686-18c3- bae249c1-f797- 2             \n",
       "70ca787c-23b6- 1dd1e911-c185- 2             \n",
       "d4644925-b88e- 48a2c037-f872- 2             \n",
       "e7eb99a4-da0e- 6868b312-14db- 2             \n",
       "e9df24a9-9413- 0c0d6f10-5af6- 2             \n",
       "f04678f5-4b56- f3df9cb1-5729- 2             \n",
       "fae2cacf-00d2- 103990e9-2063- 2             \n",
       " (Total: 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorter_keys = {\n",
    "    \"nwb_file_name\": nwb_copy_file_name,\n",
    "    \"sorter\": \"mountainsort4\",\n",
    "    \"curation_id\": 2,\n",
    "}\n",
    "\n",
    "pfc_merge_ids = SpikeSortingOutput().get_restricted_merge_ids(sorter_keys, restrict_by_artifact = True)\n",
    "\n",
    "keys = [{\"merge_id\": merge_id} for merge_id in pfc_merge_ids]\n",
    "(SpikeSortingOutput.CurationV1 & keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9dd263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spikes from a specific group\n",
    "group_key = {\n",
    "    \"nwb_file_name\": nwb_copy_file_name,\n",
    "    \"sorted_spikes_group_name\": \"left mPFC\",\n",
    "}\n",
    "\n",
    "SortedSpikesGroup().Units & group_key\n",
    "group_key = (SortedSpikesGroup & group_key).fetch1(\"KEY\")\n",
    "\n",
    "l_mpfc_spikes = SortedSpikesGroup().fetch_spike_data(group_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ccab3",
   "metadata": {},
   "source": [
    "#### Fetch position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca47a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 2\n",
    "dlc_centroid_params_name = \"four_paw_centroid\"\n",
    "pos_key = {\n",
    "    \"nwb_file_name\": nwb_copy_file_name,\n",
    "    \"epoch\": f\"{epoch}\", \n",
    "    \"dlc_model_params_name\": \"WtrackSep5\",\n",
    "    \"dlc_centroid_params_name\": dlc_centroid_params_name  \n",
    "}\n",
    "\n",
    "merge_id = (PositionOutput.DLCPosV1() & pos_key).fetch1(\"merge_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cc9a61",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "998f4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_position = (PositionOutput() & {\"merge_id\": merge_id}).fetch1_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7dd9f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single unit firing across all positions\n",
    "unit = 4\n",
    "spike_times = l_mpfc_spikes[unit]\n",
    "spike_times = spike_times\n",
    "spike_times = pd.Series([spike_time if spike_time < centroid_position.index[-1] else np.nan for spike_time in spike_times]).dropna().to_list()\n",
    "spike_positions = np.searchsorted(centroid_position.index.tolist(), spike_times)\n",
    "fig,ax = plt.subplots(layout = \"tight\")\n",
    "ax.scatter(centroid_position.position_x, centroid_position.position_y, s = 4, color = 'k', alpha = 0.03)\n",
    "ax.scatter(centroid_position.position_x.iloc[spike_positions], centroid_position.position_y.iloc[spike_positions], color = \"#1188d8\", s = 4, label = \"spikes\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa4ecd",
   "metadata": {},
   "source": [
    "### Extract trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all poisition data\n",
    "epoch2_centroid_df, epoch2_linear_df = get_centroid_and_linear_position(epoch=2,)\n",
    "epoch4_centroid_df, epoch4_linear_df = get_centroid_and_linear_position(epoch=4, )\n",
    "epoch6_centroid_df, epoch6_linear_df = get_centroid_and_linear_position(epoch=6,)\n",
    "epoch8_centroid_df, epoch8_linear_df = get_centroid_and_linear_position(epoch=8,)\n",
    "\n",
    "#get lick evenets and trial events\n",
    "lick_events_df = prepare_DIO_data(session_restriction=session_restrict, lick_event_threshold=2)\n",
    "trials_df = prepare_trial_data(lick_events_df)\n",
    "# merge position information with all trials\n",
    "target = pd.concat([epoch2_centroid_df, epoch2_linear_df], axis = 1)\n",
    "e2_trialized_position = merge_trial_df_with_target(target, trials_df)\n",
    "\n",
    "target = pd.concat([epoch4_centroid_df, epoch4_linear_df], axis = 1)\n",
    "e4_trialized_position = merge_trial_df_with_target(target, trials_df)\n",
    "\n",
    "target = pd.concat([epoch6_centroid_df, epoch6_linear_df], axis = 1)\n",
    "e6_trialized_position = merge_trial_df_with_target(target, trials_df)\n",
    "\n",
    "target = pd.concat([epoch8_centroid_df, epoch8_linear_df], axis = 1)\n",
    "e8_trialized_position = merge_trial_df_with_target(target, trials_df)\n",
    "\n",
    "\n",
    "trialized_position = pd.concat([e2_trialized_position, e4_trialized_position, e6_trialized_position, e8_trialized_position], axis = 0)\n",
    "\n",
    "maximum_trial_number_epoch_2 = e2_trialized_position[\"trial_number\"].max()\n",
    "maximum_trial_number_epoch_4 = e4_trialized_position[\"trial_number\"].max()\n",
    "maximum_trial_number_epoch_6 = e6_trialized_position[\"trial_number\"].max()\n",
    "maximum_trial_number_epoch_8 = e8_trialized_position[\"trial_number\"].max()\n",
    "\n",
    "trial_number_is_in_epoch_2 = (\n",
    "    trialized_position[\"trial_number\"] <= maximum_trial_number_epoch_2\n",
    ")\n",
    "\n",
    "trial_number_is_in_epoch_4 = (\n",
    "    (trialized_position[\"trial_number\"] > maximum_trial_number_epoch_2)\n",
    "    & (trialized_position[\"trial_number\"] <= maximum_trial_number_epoch_4)\n",
    ")\n",
    "\n",
    "trial_number_is_in_epoch_6 = (\n",
    "    (trialized_position[\"trial_number\"] > maximum_trial_number_epoch_4)\n",
    "    & (trialized_position[\"trial_number\"] <= maximum_trial_number_epoch_6)\n",
    ")\n",
    "\n",
    "trial_number_is_in_epoch_8 = (\n",
    "    (trialized_position[\"trial_number\"] > maximum_trial_number_epoch_6)\n",
    "    & (trialized_position[\"trial_number\"] <= maximum_trial_number_epoch_8)\n",
    ")\n",
    "\n",
    "trialized_position[\"epoch\"] = np.select(\n",
    "    condlist=[\n",
    "        trial_number_is_in_epoch_2,\n",
    "        trial_number_is_in_epoch_4,\n",
    "        trial_number_is_in_epoch_6,\n",
    "        trial_number_is_in_epoch_8,\n",
    "    ],\n",
    "    choicelist=[2, 4, 6, 8],\n",
    "    default=np.nan,\n",
    ")\n",
    "\n",
    "rows_with_unassigned_epoch = trialized_position[\"epoch\"].isna()\n",
    "print(\n",
    "    \"error: \",\n",
    "    trialized_position.loc[rows_with_unassigned_epoch, \"trial_number\"].unique(),\n",
    ")\n",
    "\n",
    "trialized_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save position data\n",
    "# out_dir = Path(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/position/\") \n",
    "# out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# dataframes = [e2_trialized_position, e4_trialized_position, e6_trialized_position, e8_trialized_position, trialized_position]\n",
    "# names = [\"e2_trialized_position\", \"e4_trialized_position\", \"e6_trialized_position\", \"e8_trialized_position\", \"trialized_position\"]\n",
    "\n",
    "# for name, df in zip(names, dataframes):\n",
    "#     df.to_csv(out_dir / f\"{name}.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16706d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from csv\n",
    "e2_trialized_position = pd.read_csv(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/position/e2_trialized_position.csv\", index_col = \"time\")\n",
    "e4_trialized_position = pd.read_csv(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/position/e4_trialized_position.csv\", index_col = \"time\")\n",
    "e6_trialized_position = pd.read_csv(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/position/e6_trialized_position.csv\", index_col = \"time\")\n",
    "e8_trialized_position = pd.read_csv(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/position/e8_trialized_position.csv\", index_col = \"time\")\n",
    "trialized_position = pd.read_csv(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/position/trialized_position.csv\", index_col = \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68610b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_frame_ind</th>\n",
       "      <th>position_x</th>\n",
       "      <th>position_y</th>\n",
       "      <th>orientation</th>\n",
       "      <th>velocity_x</th>\n",
       "      <th>velocity_y</th>\n",
       "      <th>speed</th>\n",
       "      <th>linear_position</th>\n",
       "      <th>track_segment_id</th>\n",
       "      <th>projected_x_position</th>\n",
       "      <th>...</th>\n",
       "      <th>trial_duration (s)</th>\n",
       "      <th>trial_label</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>trial_direction (previous, current, next)</th>\n",
       "      <th>left/right</th>\n",
       "      <th>speed_norm</th>\n",
       "      <th>trial_progress</th>\n",
       "      <th>trial_progress_distance</th>\n",
       "      <th>zone</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1620843475.612429380</th>\n",
       "      <td>83.000000000</td>\n",
       "      <td>130.841658279</td>\n",
       "      <td>64.731790850</td>\n",
       "      <td>-0.053658240</td>\n",
       "      <td>6.960407628</td>\n",
       "      <td>-0.472843676</td>\n",
       "      <td>6.976450064</td>\n",
       "      <td>316.186089589</td>\n",
       "      <td>2</td>\n",
       "      <td>130.840792016</td>\n",
       "      <td>...</td>\n",
       "      <td>31.147236824</td>\n",
       "      <td>error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('middle', 'left')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061862556</td>\n",
       "      <td>0.000412091</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>reward</td>\n",
       "      <td>2.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620843475.627006292</th>\n",
       "      <td>84.000000000</td>\n",
       "      <td>130.978969045</td>\n",
       "      <td>64.705678785</td>\n",
       "      <td>-0.042659516</td>\n",
       "      <td>6.028157129</td>\n",
       "      <td>-0.518424175</td>\n",
       "      <td>6.050408415</td>\n",
       "      <td>316.323341727</td>\n",
       "      <td>2</td>\n",
       "      <td>130.978043812</td>\n",
       "      <td>...</td>\n",
       "      <td>31.147236824</td>\n",
       "      <td>error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('middle', 'left')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053651030</td>\n",
       "      <td>0.000880091</td>\n",
       "      <td>0.000199549</td>\n",
       "      <td>reward</td>\n",
       "      <td>2.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      video_frame_ind    position_x   position_y  orientation  \\\n",
       "time                                                                            \n",
       "1620843475.612429380     83.000000000 130.841658279 64.731790850 -0.053658240   \n",
       "1620843475.627006292     84.000000000 130.978969045 64.705678785 -0.042659516   \n",
       "\n",
       "                      velocity_x   velocity_y       speed  linear_position  \\\n",
       "time                                                                         \n",
       "1620843475.612429380 6.960407628 -0.472843676 6.976450064    316.186089589   \n",
       "1620843475.627006292 6.028157129 -0.518424175 6.050408415    316.323341727   \n",
       "\n",
       "                      track_segment_id  projected_x_position  ...  \\\n",
       "time                                                          ...   \n",
       "1620843475.612429380                 2         130.840792016  ...   \n",
       "1620843475.627006292                 2         130.978043812  ...   \n",
       "\n",
       "                      trial_duration (s)  trial_label  trial_type  \\\n",
       "time                                                                \n",
       "1620843475.612429380        31.147236824        error         NaN   \n",
       "1620843475.627006292        31.147236824        error         NaN   \n",
       "\n",
       "                      trial_direction (previous, current, next)  left/right  \\\n",
       "time                                                                          \n",
       "1620843475.612429380                         ('middle', 'left')         NaN   \n",
       "1620843475.627006292                         ('middle', 'left')         NaN   \n",
       "\n",
       "                      speed_norm trial_progress trial_progress_distance  \\\n",
       "time                                                                      \n",
       "1620843475.612429380 0.061862556    0.000412091             0.000000000   \n",
       "1620843475.627006292 0.053651030    0.000880091             0.000199549   \n",
       "\n",
       "                        zone       epoch  \n",
       "time                                      \n",
       "1620843475.612429380  reward 2.000000000  \n",
       "1620843475.627006292  reward 2.000000000  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trialized_position.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trajectory for a single trial\n",
    "trial = 12\n",
    "\n",
    "t_start = trials_df.loc[trials_df[\"trial_number\"] == trial, \"trial_start\"].iloc[0]\n",
    "t_end = trials_df.loc[trials_df[\"trial_number\"] == trial, \"trial_end\"].iloc[0]\n",
    "\n",
    "# build boolean mask and select rows between the timestamps\n",
    "mask = (l_centroid_df.index > t_start) & (l_centroid_df.index < t_end)\n",
    "fig, ax = plt.subplots(layout = 'tight')\n",
    "plot_background_position(l_centroid_df, ax)\n",
    "l_centroid_df.loc[mask].plot.scatter(x = \"position_x\", y = \"position_y\", s = 8, ax = ax, c = l_centroid_df.loc[mask].index, cmap = \"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b08fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot various phases of a task\n",
    "trial = 10\n",
    "\n",
    "\n",
    "mask_reward = ( trialized_position[\"trial_number\"] == trial) & ( trialized_position[\"zone\"] == \"reward\")\n",
    "mask_run = ( trialized_position[\"trial_number\"] == trial) & ( trialized_position[\"zone\"] == \"run\")\n",
    "mask_turn = ( trialized_position[\"trial_number\"] == trial) & ( trialized_position[\"zone\"] == \"turn\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 15), layout = \"tight\")\n",
    "plot_background_position( trialized_position.iloc[::20], ax)\n",
    "# graph.plot_track_graph()\n",
    "s = 40\n",
    "trialized_position[mask_reward].plot.scatter(x = \"position_x\", y = \"position_y\", ax = ax,s = s )\n",
    "trialized_position[mask_turn].plot.scatter(x = \"position_x\", y = \"position_y\", ax = ax, s=s)\n",
    "trialized_position[mask_run].plot.scatter(x = \"position_x\", y = \"position_y\", ax = ax, s=s);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f312e61f",
   "metadata": {},
   "source": [
    "### Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "511ef193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of trials per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bd84ae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num trials in epoch 2:  50\n",
      "num trials in epoch 4:  56\n",
      "num trials in epoch 6:  59\n",
      "num trials in epoch 8:  56\n"
     ]
    }
   ],
   "source": [
    "print(\"num trials in epoch 2: \", (len(pd.unique(trialized_position[trialized_position[\"epoch\"]==2][\"trial_number\"]))))\n",
    "print(\"num trials in epoch 4: \", (len(pd.unique(trialized_position[trialized_position[\"epoch\"]==4][\"trial_number\"]))))\n",
    "print(\"num trials in epoch 6: \", (len(pd.unique(trialized_position[trialized_position[\"epoch\"]==6][\"trial_number\"]))))\n",
    "print(\"num trials in epoch 8: \", (len(pd.unique(trialized_position[trialized_position[\"epoch\"]==8][\"trial_number\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e27c67a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   3   4  53  54  56  64  98 104 122 124 126 136 154 156 168 170\n",
      " 173 186 204]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "#Incorrect trial numbers\n",
    "print(pd.unique(trialized_position[trialized_position[\"trial_label\"]==\"error\"][\"trial_number\"]))\n",
    "print(len(pd.unique(trialized_position[trialized_position[\"trial_label\"]==\"error\"][\"trial_number\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afc1d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot single trial trajectory and speed \n",
    "trial = 106\n",
    "mask = (trialized_position[\"trial_number\"]==trial) &( trialized_position[\"zone\"]==\"run\")\n",
    "timestamps = trialized_position[mask].index - trialized_position[mask].index.tolist()[0]\n",
    "with plt.style.context(\"dark_background\"):\n",
    "    fig, ax = plt.subplots(1, 2, layout = \"tight\", figsize = (20, 10))\n",
    "    plot_background_position(trialized_position, ax[0], background_color=\"white\")\n",
    "    trialized_position[mask].plot.scatter(x = \"position_x\", y = \"position_y\", ax = ax[0], c = \"speed\", s = 20, vmin = 0, vmax = 80)\n",
    "    ax[1].plot(timestamps, trialized_position[mask][\"speed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e6625",
   "metadata": {},
   "source": [
    "### Spingle unit spikes/behavior tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff3fca5",
   "metadata": {},
   "source": [
    "#### Fetch spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "778e4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_single_epoch_spikes(nwb_file_name: str,\n",
    "                              sorted_spikes_group_nane: str):\n",
    "    group_key = {\n",
    "        \"nwb_file_name\": nwb_file_name,\n",
    "        \"sorted_spikes_group_name\": sorted_spikes_group_nane\n",
    "    }\n",
    "    \n",
    "    SortedSpikesGroup.Units & group_key\n",
    "    \n",
    "    group_key = (SortedSpikesGroup & group_key).fetch1(\"KEY\")\n",
    "    return SortedSpikesGroup().fetch_spike_data(group_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01e57ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpfc_spikes = fetch_single_epoch_spikes(nwb_file_name=nwb_copy_file_name, sorted_spikes_group_nane=\"mPFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519fc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as .npz\n",
    "# out_dir = Path(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/final_spikes/\")\n",
    "# out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# np.savez_compressed(out_dir / \"mfpc_spikes.npz\", *mpfc_spikes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8913500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved spikes\n",
    "data = np.load(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/final_spikes/mfpc_spikes.npz\", allow_pickle=True)\n",
    "mpfc_spikes = [data[f\"arr_{i}\"] for i in range(len(data.files))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532ec1ec",
   "metadata": {},
   "source": [
    "#### Speed tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc228e",
   "metadata": {},
   "source": [
    "##### Compute tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fcd8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n"
     ]
    }
   ],
   "source": [
    "#rest vs run single unit comparison\n",
    "mean_fr_df = rest_vs_run_firing_rates(mpfc_spikes, trialized_position[(trialized_position[\"track_segment_id\"]==2)]\n",
    "                                      , speed_threshold=5, segment_threshold=3)\n",
    "plot_rest_vs_run_fr(mean_fr_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f2772ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute tuning\n",
    "df = trialized_position.copy()\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "zones = [\"run\"]\n",
    "trial_types = [\"inbound\", \"outbound\"]\n",
    "track_segment_ids = [0, 1,2,3,4]\n",
    "epochs = [2,4]\n",
    "\n",
    "mask = ( df[\"trial_type\"].isin(trial_types)) & \\\n",
    "            ( df[\"track_segment_id\"].isin(track_segment_ids)) & \\\n",
    "                ( df[\"zone\"].isin(zones)) & \\\n",
    "                    df[\"epoch\"].isin(epochs)\n",
    "\n",
    "\n",
    "speed_tuning, speed_centers, lo, hi, slope_boot, curv_boot = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    spikes_list=spikes_list,\n",
    "    mask=mask,\n",
    "    column =\"speed\",\n",
    "    binning=\"sliding\",\n",
    "    window_width=20,\n",
    "    window_step=2,\n",
    "    tuner_min=0,\n",
    "    tuner_max=120,\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    "    peak_normalize = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "shape_by_unit, stats_by_unit = classify_tuning_shapes_from_bootstraps(\n",
    "    slope_boot,\n",
    "    curv_boot,\n",
    "    ci=0.95,\n",
    "    min_valid_boot=200,   \n",
    ")\n",
    "unit_shapes = pd.Series(shape_by_unit)\n",
    "speed_bell_unit_ids = unit_shapes[unit_shapes==\"bell\"].index.tolist()\n",
    "speed_increasing_unit_ids = unit_shapes[unit_shapes==\"increasing\"].index.tolist()\n",
    "speed_decreasing_unit_ids = unit_shapes[unit_shapes==\"decreasing\"].index.tolist()\n",
    "speed_u_unit_ids = unit_shapes[unit_shapes==\"U\"].index.tolist()\n",
    "speed_complex_unit_ids = unit_shapes[unit_shapes==\"flat/complex\"].index.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9ca8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot tuning grid\n",
    "plot_tuning_grid_bootstrap(\n",
    "    speed_tuning, lo, hi, speed_centers,\n",
    "    column=\"speed\",\n",
    "    n_units=80,\n",
    "    s=3,\n",
    "    color=\"tab:blue\",\n",
    "    peak_normalize = True,\n",
    "    linewidth = 2,\n",
    "    indices = None,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f53fea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _counts_in_windows(values: np.ndarray, left_edges: np.ndarray, right_edges: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Count how many `values` fall in each half-open interval [left, right).\n",
    "\n",
    "    This is used for sliding-window (\"continuous\") binning where windows can overlap.\n",
    "    \"\"\"\n",
    "    left_edges = np.asarray(left_edges, dtype=float)\n",
    "    right_edges = np.asarray(right_edges, dtype=float)\n",
    "    if left_edges.shape != right_edges.shape:\n",
    "        raise ValueError(\"left_edges and right_edges must have the same shape\")\n",
    "\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    values = values[np.isfinite(values)]\n",
    "    if values.size == 0:\n",
    "        return np.zeros(left_edges.shape, dtype=np.int64)\n",
    "\n",
    "    values_sorted = np.sort(values)\n",
    "    li = np.searchsorted(values_sorted, left_edges, side=\"left\")\n",
    "    ri = np.searchsorted(values_sorted, right_edges, side=\"left\")\n",
    "    return (ri - li).astype(np.int64)\n",
    "\n",
    "\n",
    "def _bootstrap_rates_boot_trials_1d(\n",
    "    position_df: pd.DataFrame,\n",
    "    *,\n",
    "    column: str,\n",
    "    spikes_list: list,\n",
    "    mask: np.ndarray,\n",
    "    trial_column: str = \"trial_number\",\n",
    "    n_boot: int = 500,\n",
    "    ci: float = 0.95,\n",
    "    random_state: int = 0,\n",
    "    # binning params (match your compute_tuning_bootstrap_trials call)\n",
    "    n_bins: int = 6,\n",
    "    tuner_bins: np.ndarray = None,\n",
    "    binning: str = \"edges\",\n",
    "    window_width: float = None,\n",
    "    window_step: float = None,\n",
    "    tuner_min: float = None,\n",
    "    tuner_max: float = None,\n",
    "    # options\n",
    "    unit_ids=None,\n",
    "    peak_normalize: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Reconstruct per-unit bootstrap replicate tuning curves rates_boot (n_boot, n_bins)\n",
    "    using the same trial-resampling logic as compute_tuning_bootstrap_trials(...).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    centers : (n_bins,) array\n",
    "    rates_boot_by_unit : dict[unit_id] -> (n_boot, n_bins) float array\n",
    "    meta : dict with trial_ids, occupancy_time_trials, etc. (useful for debugging)\n",
    "    \"\"\"\n",
    "    if trial_column not in position_df.columns:\n",
    "        raise KeyError(f\"position_df missing {trial_column=}\")\n",
    "    if len(position_df.index) < 2:\n",
    "        raise ValueError(\"position_df must have >=2 timestamp samples\")\n",
    "    if not pd.Index(position_df.index).is_monotonic_increasing:\n",
    "        raise ValueError(\"position_df.index must be sorted/monotonic increasing\")\n",
    "\n",
    "    timestamps = position_df.index.to_numpy()\n",
    "    x_raw = position_df[column].to_numpy()\n",
    "    trial_ids_raw = position_df[trial_column].to_numpy()\n",
    "\n",
    "    mask = np.asarray(mask, dtype=bool)\n",
    "    if mask.shape[0] != x_raw.shape[0]:\n",
    "        raise ValueError(\"mask length must match position_df length\")\n",
    "\n",
    "    # match compute_tuning_bootstrap_trials: require valid trial id under mask\n",
    "    trial_ok = ~pd.isna(trial_ids_raw)\n",
    "    mask = mask & trial_ok\n",
    "\n",
    "    dt = float(np.median(np.diff(timestamps)))\n",
    "    if not np.isfinite(dt) or dt <= 0:\n",
    "        raise ValueError(\"Bad dt from timestamps\")\n",
    "\n",
    "    x_masked = x_raw[mask]\n",
    "    if x_masked.size == 0:\n",
    "        raise ValueError(\"Mask leaves zero samples\")\n",
    "\n",
    "    # --- build bins/windows exactly like compute_tuning_bootstrap_trials ---\n",
    "    mode = _validate_binning_mode(binning)\n",
    "\n",
    "    if mode == \"edges\":\n",
    "        if tuner_bins is None:\n",
    "            max_tuner = float(np.nanmax(x_masked))\n",
    "            tuner_bins = np.linspace(0, max_tuner, int(n_bins) + 1)\n",
    "        else:\n",
    "            tuner_bins = np.asarray(tuner_bins, dtype=float)\n",
    "            if tuner_bins.ndim != 1 or len(tuner_bins) != int(n_bins) + 1:\n",
    "                raise ValueError(\"tuner_bins must be 1D length n_bins+1\")\n",
    "            if not np.all(np.diff(tuner_bins) > 0):\n",
    "                raise ValueError(\"tuner_bins must be strictly increasing\")\n",
    "        centers = (tuner_bins[:-1] + tuner_bins[1:]) / 2.0\n",
    "        left_edges = None\n",
    "        right_edges = None\n",
    "        n_bins_eff = int(n_bins)\n",
    "    else:\n",
    "        bin_spec = _prepare_tuner_binning(\n",
    "            x_masked,\n",
    "            n_bins=int(n_bins),\n",
    "            tuner_bins=None,\n",
    "            binning=\"sliding\",\n",
    "            window_width=window_width,\n",
    "            window_step=window_step,\n",
    "            tuner_min=tuner_min,\n",
    "            tuner_max=tuner_max,\n",
    "        )\n",
    "        centers = np.asarray(bin_spec[\"centers\"], dtype=float)\n",
    "        left_edges = np.asarray(bin_spec[\"left\"], dtype=float)\n",
    "        right_edges = np.asarray(bin_spec[\"right\"], dtype=float)\n",
    "        n_bins_eff = int(centers.size)\n",
    "\n",
    "    # --- trial list (match compute_tuning_bootstrap_trials) ---\n",
    "    trial_ids_masked = np.asarray(trial_ids_raw[mask]).astype(int)\n",
    "    trial_ids = np.unique(trial_ids_masked)\n",
    "    trial_ids = np.sort(trial_ids)\n",
    "    n_trials = int(trial_ids.size)\n",
    "    if n_trials < 2:\n",
    "        raise ValueError(f\"Need >=2 trials for bootstrap; found {n_trials}\")\n",
    "\n",
    "    # --- occupancy per (trial, bin) from masked samples ---\n",
    "    if mode == \"edges\":\n",
    "        trial_idx_per_sample = np.searchsorted(trial_ids, trial_ids_masked)\n",
    "\n",
    "        x_masked_vals = np.asarray(x_masked, dtype=float)\n",
    "        finite = np.isfinite(x_masked_vals)\n",
    "        bin_idx = np.searchsorted(tuner_bins, x_masked_vals, side=\"right\") - 1\n",
    "        bin_idx[bin_idx == n_bins_eff] = n_bins_eff - 1\n",
    "        valid_bin = finite & (bin_idx >= 0) & (bin_idx < n_bins_eff)\n",
    "\n",
    "        flat_occ = np.bincount(\n",
    "            trial_idx_per_sample[valid_bin] * n_bins_eff + bin_idx[valid_bin],\n",
    "            minlength=n_trials * n_bins_eff,\n",
    "        )\n",
    "        occupancy_counts_trials = flat_occ.reshape(n_trials, n_bins_eff)\n",
    "    else:\n",
    "        # sliding: count samples per window within each trial\n",
    "        x_masked_vals = np.asarray(x_masked, dtype=float)\n",
    "        t_masked_vals = np.asarray(trial_ids_masked, dtype=int)\n",
    "\n",
    "        finite = np.isfinite(x_masked_vals)\n",
    "        x_masked_vals = x_masked_vals[finite]\n",
    "        t_masked_vals = t_masked_vals[finite]\n",
    "\n",
    "        trial_idx = np.searchsorted(trial_ids, t_masked_vals)\n",
    "        order = np.argsort(trial_idx, kind=\"mergesort\")\n",
    "        trial_idx_sorted = trial_idx[order]\n",
    "        x_sorted_by_trial = x_masked_vals[order]\n",
    "\n",
    "        occupancy_counts_trials = np.zeros((n_trials, n_bins_eff), dtype=np.int64)\n",
    "        for t in range(n_trials):\n",
    "            s = np.searchsorted(trial_idx_sorted, t, side=\"left\")\n",
    "            e = np.searchsorted(trial_idx_sorted, t, side=\"right\")\n",
    "            if e <= s:\n",
    "                continue\n",
    "            occupancy_counts_trials[t, :] = _counts_in_windows(x_sorted_by_trial[s:e], left_edges, right_edges)\n",
    "\n",
    "    occupancy_time_trials = occupancy_counts_trials * dt  # seconds\n",
    "\n",
    "    # --- bootstrap weights (trial resampling) ---\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    weights = rng.multinomial(n_trials, np.ones(n_trials) / n_trials, size=int(n_boot)).astype(float)\n",
    "\n",
    "    occupancy_time_boot = weights @ occupancy_time_trials  # (n_boot, n_bins)\n",
    "\n",
    "    # --- per-unit spike counts per (trial, bin) ---\n",
    "    # IMPORTANT: this maps spikes -> position sample index -> (trial, x)\n",
    "    # like compute_tuning_bootstrap_trials does around tuning_analysis/spike_analysis.py:2591\n",
    "    timestamps_arr = np.asarray(timestamps)\n",
    "    x_arr = np.asarray(x_raw, dtype=float)\n",
    "    mask_arr = np.asarray(mask, dtype=bool)\n",
    "\n",
    "    def _spike_counts_trials_for_unit(spike_times: np.ndarray) -> np.ndarray:\n",
    "        spike_times = np.asarray(spike_times)\n",
    "\n",
    "        t0, t1 = timestamps_arr[0], timestamps_arr[-1]\n",
    "        in_window = (spike_times >= t0) & (spike_times <= t1)\n",
    "        spike_times_win = spike_times[in_window]\n",
    "        if spike_times_win.size == 0:\n",
    "            return np.zeros((n_trials, n_bins_eff), dtype=np.int64)\n",
    "\n",
    "        spike_pos_idx = np.searchsorted(timestamps_arr, spike_times_win, side=\"right\") - 1\n",
    "        spike_pos_idx = np.clip(spike_pos_idx, 0, len(timestamps_arr) - 1)\n",
    "\n",
    "        keep = mask_arr[spike_pos_idx]\n",
    "        if not np.any(keep):\n",
    "            return np.zeros((n_trials, n_bins_eff), dtype=np.int64)\n",
    "        spike_pos_idx = spike_pos_idx[keep]\n",
    "\n",
    "        spike_trials = trial_ids_raw[spike_pos_idx]\n",
    "        spike_x = x_arr[spike_pos_idx]\n",
    "\n",
    "        ok = (~pd.isna(spike_trials)) & np.isfinite(spike_x)\n",
    "        if not np.any(ok):\n",
    "            return np.zeros((n_trials, n_bins_eff), dtype=np.int64)\n",
    "\n",
    "        spike_trials = spike_trials[ok].astype(int)\n",
    "        spike_x = spike_x[ok].astype(float)\n",
    "\n",
    "        spike_trial_idx = np.searchsorted(trial_ids, spike_trials)\n",
    "        valid_trial = (\n",
    "            (spike_trial_idx >= 0)\n",
    "            & (spike_trial_idx < n_trials)\n",
    "            & (trial_ids[spike_trial_idx] == spike_trials)\n",
    "        )\n",
    "        if not np.any(valid_trial):\n",
    "            return np.zeros((n_trials, n_bins_eff), dtype=np.int64)\n",
    "\n",
    "        spike_trial_idx = spike_trial_idx[valid_trial]\n",
    "        spike_x = spike_x[valid_trial]\n",
    "\n",
    "        if mode == \"edges\":\n",
    "            spike_bin_idx = np.searchsorted(tuner_bins, spike_x, side=\"right\") - 1\n",
    "            spike_bin_idx[spike_bin_idx == n_bins_eff] = n_bins_eff - 1\n",
    "            valid = (spike_bin_idx >= 0) & (spike_bin_idx < n_bins_eff)\n",
    "            if not np.any(valid):\n",
    "                return np.zeros((n_trials, n_bins_eff), dtype=np.int64)\n",
    "\n",
    "            flat = np.bincount(\n",
    "                spike_trial_idx[valid] * n_bins_eff + spike_bin_idx[valid],\n",
    "                minlength=n_trials * n_bins_eff,\n",
    "            )\n",
    "            return flat.reshape(n_trials, n_bins_eff)\n",
    "\n",
    "        # sliding: count spikes per window within each trial\n",
    "        out = np.zeros((n_trials, n_bins_eff), dtype=np.int64)\n",
    "        order = np.argsort(spike_trial_idx, kind=\"mergesort\")\n",
    "        trial_idx_sorted = spike_trial_idx[order]\n",
    "        x_sorted_by_trial = spike_x[order]\n",
    "        for t in range(n_trials):\n",
    "            s = np.searchsorted(trial_idx_sorted, t, side=\"left\")\n",
    "            e = np.searchsorted(trial_idx_sorted, t, side=\"right\")\n",
    "            if e <= s:\n",
    "                continue\n",
    "            out[t, :] = _counts_in_windows(x_sorted_by_trial[s:e], left_edges, right_edges)\n",
    "        return out\n",
    "\n",
    "    if unit_ids is None:\n",
    "        unit_ids = list(range(len(spikes_list)))\n",
    "    unit_ids = list(unit_ids)\n",
    "\n",
    "    # --- CI quantiles (for optional peak-normalization of boot curves) ---\n",
    "    alpha = 1.0 - float(ci)\n",
    "    lo_q = 100.0 * (alpha / 2.0)\n",
    "    hi_q = 100.0 * (1.0 - alpha / 2.0)\n",
    "\n",
    "    rates_boot_by_unit = {}\n",
    "    for u in unit_ids:\n",
    "        counts_trials = _spike_counts_trials_for_unit(spikes_list[u])\n",
    "        spike_counts_boot = weights @ counts_trials  # (n_boot, n_bins)\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            rates_boot = spike_counts_boot / occupancy_time_boot\n",
    "\n",
    "        # match compute_tuning_bootstrap_trials thresholding\n",
    "        rates_boot[occupancy_time_boot <= MIN_OCCUPANCY] = np.nan\n",
    "\n",
    "        if peak_normalize:\n",
    "            # mirror your moduleâ€™s peak-normalize definition: scale = max_x upper_CI(x)\n",
    "            hi = np.nanpercentile(rates_boot, hi_q, axis=0)\n",
    "            scale = float(np.nanmax(hi)) if np.any(np.isfinite(hi)) else np.nan\n",
    "            if np.isfinite(scale) and scale > 0:\n",
    "                rates_boot = rates_boot / scale\n",
    "\n",
    "        rates_boot_by_unit[u] = rates_boot\n",
    "\n",
    "    meta = dict(\n",
    "        trial_ids=trial_ids,\n",
    "        centers=centers,\n",
    "        occupancy_time_trials=occupancy_time_trials,\n",
    "        occupancy_time_boot=occupancy_time_boot,\n",
    "        weights=weights,\n",
    "        dt=dt,\n",
    "        mode=mode,\n",
    "    )\n",
    "    return centers, rates_boot_by_unit, meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "438b45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _moving_average_1d(y: np.ndarray, win: int) -> np.ndarray:\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if win is None or win <= 1:\n",
    "        return y\n",
    "    win = int(win)\n",
    "    if win % 2 == 0:\n",
    "        win += 1  # force odd so output length matches input\n",
    "    pad = win // 2\n",
    "    ypad = np.pad(y, (pad, pad), mode=\"edge\")\n",
    "    kernel = np.ones(win, dtype=float) / win\n",
    "    out = np.convolve(ypad, kernel, mode=\"valid\")\n",
    "    if out.shape[0] != y.shape[0]:\n",
    "        raise RuntimeError(f\"moving average length mismatch: {out.shape[0]} vs {y.shape[0]}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def _robust_sigma_y_from_boot(rates_boot: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    rates_boot: (n_boot, n_bins)\n",
    "    Estimate typical per-bin variability, then summarize across bins.\n",
    "    \"\"\"\n",
    "    rb = np.asarray(rates_boot, dtype=float)\n",
    "    if rb.ndim != 2:\n",
    "        raise ValueError(\"rates_boot must be 2D (n_boot, n_bins)\")\n",
    "    # per-bin IQR across replicates\n",
    "    q75 = np.nanpercentile(rb, 75, axis=0)\n",
    "    q25 = np.nanpercentile(rb, 25, axis=0)\n",
    "    iqr = q75 - q25\n",
    "    # normal approx: sigma ~= IQR / 1.349\n",
    "    sigma_bins = iqr / 1.349\n",
    "    sigma = float(np.nanmedian(sigma_bins)) if np.any(np.isfinite(sigma_bins)) else np.nan\n",
    "    return sigma\n",
    "\n",
    "def classify_curve_deriv_extrema(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    *,\n",
    "    sigma_y: float,\n",
    "    smooth_win: int = 3,\n",
    "    edge_bins: int = 2,\n",
    "    monotone_frac: float = 0.8,  # kept for API compatibility (unused)\n",
    "    flat_factor: float = 1.0,\n",
    "    prom_factor: float = 2.0,\n",
    "    prom_factor_local: float = 2.0,\n",
    "    dx_factor: float = 1.0,\n",
    "    min_valid_bins: int = 5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Derivative/extrema-based shape classifier with bootstrap-scale thresholds.\n",
    "\n",
    "    Labels: flat, increasing, decreasing, bell, U, complex, unusable\n",
    "\n",
    "    Design goals:\n",
    "    - \"flat\" if overall modulation is small vs bootstrap noise scale\n",
    "    - \"bell\"/\"U\" if there is a strong *global* interior max/min (two-sided vs endpoints)\n",
    "      AND curve is not multimodal (veto based on significant local extrema)\n",
    "    - \"increasing\"/\"decreasing\" should include \"trend then plateau\" curves:\n",
    "      allow most derivatives to be \"flat\" as long as net_change is strongly signed\n",
    "    - \"complex\" otherwise\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "\n",
    "    ok = np.isfinite(x) & np.isfinite(y)\n",
    "    if np.sum(ok) < min_valid_bins:\n",
    "        return \"unusable\", {\"n_ok\": int(np.sum(ok))}\n",
    "\n",
    "    xv = x[ok]\n",
    "    yv = y[ok]\n",
    "\n",
    "    order = np.argsort(xv)\n",
    "    xv = xv[order]\n",
    "    yv = yv[order]\n",
    "\n",
    "    y_s = _moving_average_1d(yv, smooth_win)\n",
    "\n",
    "    n = y_s.size\n",
    "    eb = int(edge_bins)\n",
    "    eb = max(1, min(eb, max(1, n // 4)))\n",
    "\n",
    "    # ---- flat gate ----\n",
    "    y_range = float(np.nanmax(y_s) - np.nanmin(y_s))\n",
    "    flat_thr = float(flat_factor) * float(sigma_y) if np.isfinite(sigma_y) else np.nan\n",
    "    if np.isfinite(flat_thr) and y_range < flat_thr:\n",
    "        return \"flat\", {\"y_range\": y_range, \"flat_thr\": flat_thr}\n",
    "\n",
    "    # ---- derivative threshold ----\n",
    "    dx = np.diff(xv)\n",
    "    dx_med = float(np.median(dx)) if dx.size else np.nan\n",
    "    if not np.isfinite(dx_med) or dx_med <= 0 or (not np.isfinite(sigma_y)) or sigma_y <= 0:\n",
    "        eps_dx = 0.0\n",
    "    else:\n",
    "        eps_dx = float(dx_factor) * float(sigma_y) / dx_med\n",
    "\n",
    "    dy = np.gradient(y_s, xv)\n",
    "\n",
    "    # ---- candidate extrema via derivative sign changes ----\n",
    "    def _fill_zeros_with_neighbors(sign_arr: np.ndarray) -> np.ndarray:\n",
    "        s = sign_arr.copy()\n",
    "        last = 0\n",
    "        for i in range(s.size):\n",
    "            if s[i] == 0:\n",
    "                s[i] = last\n",
    "            else:\n",
    "                last = s[i]\n",
    "        if s.size and s[0] == 0:\n",
    "            first_nz = 0\n",
    "            for v in s:\n",
    "                if v != 0:\n",
    "                    first_nz = v\n",
    "                    break\n",
    "            s[s == 0] = first_nz\n",
    "        return s\n",
    "\n",
    "    def _segments(sign_arr: np.ndarray):\n",
    "        segs = []\n",
    "        start = 0\n",
    "        cur = int(sign_arr[0])\n",
    "        for i in range(1, sign_arr.size):\n",
    "            if int(sign_arr[i]) != cur:\n",
    "                segs.append((start, i - 1, cur))\n",
    "                start = i\n",
    "                cur = int(sign_arr[i])\n",
    "        segs.append((start, sign_arr.size - 1, cur))\n",
    "        return segs\n",
    "\n",
    "    def _candidate_extrema_indices(y_s: np.ndarray, dy: np.ndarray, eps_dx: float):\n",
    "        s = np.zeros_like(dy, dtype=int)\n",
    "        s[dy > eps_dx] = 1\n",
    "        s[dy < -eps_dx] = -1\n",
    "        if not np.any(s != 0):\n",
    "            return [], []\n",
    "\n",
    "        s_f = _fill_zeros_with_neighbors(s)\n",
    "        segs = _segments(s_f)\n",
    "\n",
    "        cand_max = []\n",
    "        cand_min = []\n",
    "        for (a0, b0, s0), (a1, b1, s1) in zip(segs[:-1], segs[1:]):\n",
    "            if s0 == 1 and s1 == -1:\n",
    "                lo = max(0, a0)\n",
    "                hi = min(n - 1, b1 + 1)\n",
    "                idx = int(lo + np.nanargmax(y_s[lo : hi + 1]))\n",
    "                cand_max.append(idx)\n",
    "            elif s0 == -1 and s1 == 1:\n",
    "                lo = max(0, a0)\n",
    "                hi = min(n - 1, b1 + 1)\n",
    "                idx = int(lo + np.nanargmin(y_s[lo : hi + 1]))\n",
    "                cand_min.append(idx)\n",
    "\n",
    "        return sorted(set(cand_max)), sorted(set(cand_min))\n",
    "\n",
    "    def _significant_extrema(y_s: np.ndarray):\n",
    "        cand_max, cand_min = _candidate_extrema_indices(y_s, dy, eps_dx)\n",
    "\n",
    "        # only interior candidates\n",
    "        cand_max = sorted([i for i in cand_max if (i >= eb) and (i <= n - eb - 1)])\n",
    "        cand_min = sorted([i for i in cand_min if (i >= eb) and (i <= n - eb - 1)])\n",
    "\n",
    "        prom_thr_local = float(prom_factor_local) * float(sigma_y) if np.isfinite(sigma_y) else np.nan\n",
    "        if (not np.isfinite(prom_thr_local)) or prom_thr_local <= 0:\n",
    "            return [], [], prom_thr_local\n",
    "\n",
    "        def _nearest_left(sorted_list, idx):\n",
    "            out = None\n",
    "            for v in sorted_list:\n",
    "                if v < idx:\n",
    "                    out = v\n",
    "                else:\n",
    "                    break\n",
    "            return out\n",
    "\n",
    "        def _nearest_right(sorted_list, idx):\n",
    "            for v in sorted_list:\n",
    "                if v > idx:\n",
    "                    return v\n",
    "            return None\n",
    "\n",
    "        sig_max = []\n",
    "        sig_min = []\n",
    "\n",
    "        # Peak significant only if bracketed by minima on both sides\n",
    "        for p in cand_max:\n",
    "            lmin = _nearest_left(cand_min, p)\n",
    "            rmin = _nearest_right(cand_min, p)\n",
    "            if lmin is None or rmin is None:\n",
    "                continue\n",
    "            baseline = max(float(y_s[lmin]), float(y_s[rmin]))\n",
    "            prom = float(y_s[p]) - baseline\n",
    "            if prom > prom_thr_local:\n",
    "                sig_max.append(p)\n",
    "\n",
    "        # Trough significant only if bracketed by maxima on both sides\n",
    "        for t in cand_min:\n",
    "            lmax = _nearest_left(cand_max, t)\n",
    "            rmax = _nearest_right(cand_max, t)\n",
    "            if lmax is None or rmax is None:\n",
    "                continue\n",
    "            baseline = min(float(y_s[lmax]), float(y_s[rmax]))\n",
    "            prom = baseline - float(y_s[t])\n",
    "            if prom > prom_thr_local:\n",
    "                sig_min.append(t)\n",
    "\n",
    "        return sig_max, sig_min, prom_thr_local\n",
    "\n",
    "    sig_max, sig_min, prom_thr_local = _significant_extrema(y_s)\n",
    "\n",
    "    # ---- multi-extrema veto (only LARGE extrema) ----\n",
    "    if (len(sig_max) > 1) or (len(sig_min) > 1):\n",
    "        return \"complex\", {\n",
    "            \"reason\": \"multi_extrema_veto_significant\",\n",
    "            \"sig_max\": sig_max,\n",
    "            \"sig_min\": sig_min,\n",
    "            \"prom_thr_local\": prom_thr_local,\n",
    "            \"eps_dx\": eps_dx,\n",
    "        }\n",
    "\n",
    "    # ---- global bell/U test (two-sided vs endpoints) ----\n",
    "    y_left = float(np.median(y_s[:eb]))\n",
    "    y_right = float(np.median(y_s[-eb:]))\n",
    "\n",
    "    i_max = int(np.nanargmax(y_s))\n",
    "    i_min = int(np.nanargmin(y_s))\n",
    "\n",
    "    interior_max = (i_max >= eb) and (i_max <= n - eb - 1)\n",
    "    interior_min = (i_min >= eb) and (i_min <= n - eb - 1)\n",
    "\n",
    "    prom_thr = float(prom_factor) * float(sigma_y) if np.isfinite(sigma_y) else np.nan\n",
    "\n",
    "    peak = float(y_s[i_max])\n",
    "    trough = float(y_s[i_min])\n",
    "\n",
    "    prom_max_two_sided = float(min(peak - y_left, peak - y_right))\n",
    "    prom_min_two_sided = float(min(y_left - trough, y_right - trough))\n",
    "\n",
    "    bell_ok = interior_max and np.isfinite(prom_thr) and (prom_max_two_sided > prom_thr)\n",
    "    u_ok = interior_min and np.isfinite(prom_thr) and (prom_min_two_sided > prom_thr)\n",
    "\n",
    "    # If there is any significant opposite-type extremum, this isn't a clean bell/U\n",
    "    # (e.g. if calling bell but we also found a significant trough, treat as complex)\n",
    "    if bell_ok and (len(sig_min) > 0):\n",
    "        bell_ok = False\n",
    "    if u_ok and (len(sig_max) > 0):\n",
    "        u_ok = False\n",
    "\n",
    "    if bell_ok and (not u_ok):\n",
    "        return \"bell\", {\n",
    "            \"i_max\": i_max,\n",
    "            \"prom_thr\": prom_thr,\n",
    "            \"prom_max_two_sided\": prom_max_two_sided,\n",
    "            \"sig_max\": sig_max,\n",
    "            \"sig_min\": sig_min,\n",
    "        }\n",
    "    if u_ok and (not bell_ok):\n",
    "        return \"U\", {\n",
    "            \"i_min\": i_min,\n",
    "            \"prom_thr\": prom_thr,\n",
    "            \"prom_min_two_sided\": prom_min_two_sided,\n",
    "            \"sig_max\": sig_max,\n",
    "            \"sig_min\": sig_min,\n",
    "        }\n",
    "    if bell_ok and u_ok:\n",
    "        return \"complex\", {\"bell_ok\": True, \"u_ok\": True}\n",
    "\n",
    "    # ---- monotone classification (plateau-friendly) ----\n",
    "    frac_pos = float(np.mean(dy > eps_dx)) if dy.size else 0.0\n",
    "    frac_neg = float(np.mean(dy < -eps_dx)) if dy.size else 0.0\n",
    "    frac_flat = float(np.mean(np.abs(dy) <= eps_dx)) if dy.size else 0.0\n",
    "\n",
    "    # robust net change\n",
    "    net_change = float(np.median(y_s[-eb:]) - np.median(y_s[:eb]))\n",
    "    net_thr = float(flat_thr) if np.isfinite(flat_thr) else 0.0\n",
    "\n",
    "    # knobs (chosen to fix your unit 0 debug pattern)\n",
    "    max_opposite_frac = 0.15\n",
    "\n",
    "    # Route A (strongly monotone across curve)\n",
    "    min_trend_frac_strong = 0.20\n",
    "\n",
    "    # Route B (trend then plateau)\n",
    "    min_trend_frac_weak = 0.05\n",
    "\n",
    "    # Require stronger-than-flat net change for plateau route so flat units don't become inc/dec\n",
    "    strong_net_k = 3.0\n",
    "    strong_net_thr = strong_net_k * net_thr\n",
    "\n",
    "    # decreasing\n",
    "    if (frac_pos <= max_opposite_frac) and (\n",
    "        ((frac_neg >= min_trend_frac_strong) and (net_change < -net_thr)) or\n",
    "        ((frac_neg >= min_trend_frac_weak) and (net_change < -strong_net_thr)) or\n",
    "        (net_change < -strong_net_thr)\n",
    "    ):\n",
    "        return \"decreasing\", {\n",
    "            \"frac_pos\": frac_pos,\n",
    "            \"frac_neg\": frac_neg,\n",
    "            \"frac_flat\": frac_flat,\n",
    "            \"eps_dx\": eps_dx,\n",
    "            \"net_change\": net_change,\n",
    "            \"net_thr\": net_thr,\n",
    "            \"strong_net_thr\": strong_net_thr,\n",
    "        }\n",
    "\n",
    "    # increasing\n",
    "    if (frac_neg <= max_opposite_frac) and (\n",
    "        ((frac_pos >= min_trend_frac_strong) and (net_change > net_thr)) or\n",
    "        ((frac_pos >= min_trend_frac_weak) and (net_change > strong_net_thr)) or\n",
    "        (net_change > strong_net_thr)\n",
    "    ):\n",
    "        return \"increasing\", {\n",
    "            \"frac_pos\": frac_pos,\n",
    "            \"frac_neg\": frac_neg,\n",
    "            \"frac_flat\": frac_flat,\n",
    "            \"eps_dx\": eps_dx,\n",
    "            \"net_change\": net_change,\n",
    "            \"net_thr\": net_thr,\n",
    "            \"strong_net_thr\": strong_net_thr,\n",
    "        }\n",
    "\n",
    "    return \"complex\", {\n",
    "        \"sig_max\": sig_max,\n",
    "        \"sig_min\": sig_min,\n",
    "        \"prom_thr_local\": prom_thr_local,\n",
    "        \"frac_pos\": frac_pos,\n",
    "        \"frac_neg\": frac_neg,\n",
    "        \"frac_flat\": frac_flat,\n",
    "        \"eps_dx\": eps_dx,\n",
    "        \"net_change\": net_change,\n",
    "        \"net_thr\": net_thr,\n",
    "        \"strong_net_thr\": strong_net_thr,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def classify_unit_from_rates_boot(\n",
    "    x: np.ndarray,\n",
    "    rates_boot: np.ndarray,\n",
    "    *,\n",
    "    smooth_win: int = 3,\n",
    "    edge_bins: int = 2,\n",
    "    monotone_frac: float = 0.8,\n",
    "    flat_factor: float = 1.5,\n",
    "    prom_factor: float = 2.0,\n",
    "    prom_factor_local: float = 2.0,\n",
    "    dx_factor: float = 1.0,\n",
    "    min_valid_bins: int = 5,\n",
    "):\n",
    "    rb = np.asarray(rates_boot, dtype=float)\n",
    "    sigma_y = _robust_sigma_y_from_boot(rb)\n",
    "\n",
    "    labels = []\n",
    "    for r in range(rb.shape[0]):\n",
    "        label, _dbg = classify_curve_deriv_extrema(\n",
    "            x,\n",
    "            rb[r, :],\n",
    "            sigma_y=sigma_y,\n",
    "            smooth_win=smooth_win,\n",
    "            edge_bins=edge_bins,\n",
    "            monotone_frac=monotone_frac,\n",
    "            flat_factor=flat_factor,\n",
    "            prom_factor=prom_factor,\n",
    "            prom_factor_local=prom_factor_local,\n",
    "            dx_factor=dx_factor,\n",
    "            min_valid_bins=min_valid_bins,\n",
    "        )\n",
    "        if label != \"unusable\":\n",
    "            labels.append(label)\n",
    "\n",
    "    n_usable = len(labels)\n",
    "    if n_usable == 0:\n",
    "        return {\"unusable\": 1.0}, {\"sigma_y\": sigma_y, \"n_usable\": 0}\n",
    "\n",
    "    probs = {k: labels.count(k) / n_usable for k in set(labels)}\n",
    "    for k in [\"increasing\", \"decreasing\", \"bell\", \"U\", \"flat\", \"complex\"]:\n",
    "        probs.setdefault(k, 0.0)\n",
    "\n",
    "    summary = {\"sigma_y\": sigma_y, \"n_usable\": n_usable}\n",
    "    return probs, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "591140ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decreasing</th>\n",
       "      <th>increasing</th>\n",
       "      <th>bell</th>\n",
       "      <th>U</th>\n",
       "      <th>flat</th>\n",
       "      <th>complex</th>\n",
       "      <th>sigma_y</th>\n",
       "      <th>n_usable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.002000000</td>\n",
       "      <td>0.132000000</td>\n",
       "      <td>0.146000000</td>\n",
       "      <td>0.056000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.664000000</td>\n",
       "      <td>0.125904433</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.022000000</td>\n",
       "      <td>0.094000000</td>\n",
       "      <td>0.258000000</td>\n",
       "      <td>0.016000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.610000000</td>\n",
       "      <td>0.092221799</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.232000000</td>\n",
       "      <td>0.004000000</td>\n",
       "      <td>0.134000000</td>\n",
       "      <td>0.038000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.592000000</td>\n",
       "      <td>0.069866652</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.012000000</td>\n",
       "      <td>0.006000000</td>\n",
       "      <td>0.058000000</td>\n",
       "      <td>0.400000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.524000000</td>\n",
       "      <td>0.073984144</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.006000000</td>\n",
       "      <td>0.022000000</td>\n",
       "      <td>0.450000000</td>\n",
       "      <td>0.012000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.510000000</td>\n",
       "      <td>0.139808747</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.226000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.268000000</td>\n",
       "      <td>0.010000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.496000000</td>\n",
       "      <td>0.082320561</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.002000000</td>\n",
       "      <td>0.112000000</td>\n",
       "      <td>0.224000000</td>\n",
       "      <td>0.174000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.488000000</td>\n",
       "      <td>0.079321653</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.078000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.088000000</td>\n",
       "      <td>0.364000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.470000000</td>\n",
       "      <td>0.036805676</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.134000000</td>\n",
       "      <td>0.392000000</td>\n",
       "      <td>0.034000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.440000000</td>\n",
       "      <td>0.105835169</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     decreasing  increasing        bell           U        flat     complex  \\\n",
       "111 0.000000000 0.000000000 0.000000000 0.000000000 0.000000000 1.000000000   \n",
       "262 0.002000000 0.132000000 0.146000000 0.056000000 0.000000000 0.664000000   \n",
       "75  0.022000000 0.094000000 0.258000000 0.016000000 0.000000000 0.610000000   \n",
       "235 0.232000000 0.004000000 0.134000000 0.038000000 0.000000000 0.592000000   \n",
       "250 0.012000000 0.006000000 0.058000000 0.400000000 0.000000000 0.524000000   \n",
       "107 0.006000000 0.022000000 0.450000000 0.012000000 0.000000000 0.510000000   \n",
       "211 0.226000000 0.000000000 0.268000000 0.010000000 0.000000000 0.496000000   \n",
       "188 0.002000000 0.112000000 0.224000000 0.174000000 0.000000000 0.488000000   \n",
       "113 0.078000000 0.000000000 0.088000000 0.364000000 0.000000000 0.470000000   \n",
       "99  0.000000000 0.134000000 0.392000000 0.034000000 0.000000000 0.440000000   \n",
       "\n",
       "        sigma_y  n_usable  \n",
       "111 0.000000000       500  \n",
       "262 0.125904433       500  \n",
       "75  0.092221799       500  \n",
       "235 0.069866652       500  \n",
       "250 0.073984144       500  \n",
       "107 0.139808747       500  \n",
       "211 0.082320561       500  \n",
       "188 0.079321653       500  \n",
       "113 0.036805676       500  \n",
       "99  0.105835169       500  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unit_ids_test = list(range(20))  \n",
    "df = trialized_position.copy()\n",
    "centers, rates_boot_by_unit, meta = _bootstrap_rates_boot_trials_1d(\n",
    "    df,\n",
    "    column=\"speed\",\n",
    "    spikes_list=spikes_list,\n",
    "    mask=base_mask,\n",
    "    trial_column=\"trial_number\",\n",
    "    n_boot=500,\n",
    "    ci=0.95,\n",
    "    random_state=0,\n",
    "    binning=\"sliding\",\n",
    "    window_width=20,\n",
    "    window_step=2,\n",
    "    tuner_min=0,\n",
    "    tuner_max=120,\n",
    "    unit_ids=None,\n",
    "    peak_normalize=True,  \n",
    ")\n",
    "\n",
    "probs_by_unit = {}\n",
    "summary_by_unit = {}\n",
    "for u, rb in rates_boot_by_unit.items():\n",
    "    probs, summary = classify_unit_from_rates_boot(\n",
    "        centers,\n",
    "        rb,\n",
    "        smooth_win=5,\n",
    "        edge_bins=6,\n",
    "        monotone_frac=0.8,\n",
    "        flat_factor=1.0,\n",
    "        prom_factor=2.0,\n",
    "        prom_factor_local= 3.0,\n",
    "        dx_factor=1.0,\n",
    "        min_valid_bins=8,\n",
    "    )\n",
    "    probs_by_unit[u] = probs\n",
    "    summary_by_unit[u] = summary\n",
    "\n",
    "probs_df = pd.DataFrame.from_dict(probs_by_unit, orient=\"index\")\n",
    "summ_df = pd.DataFrame.from_dict(summary_by_unit, orient=\"index\")\n",
    "display(probs_df.join(summ_df).sort_values(\"complex\", ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "285492d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bell 53 U 32 inc 32 dec 55 flat 0 complex 1\n"
     ]
    }
   ],
   "source": [
    "p_thr = 0.8\n",
    "bell_ids = probs_df.index[probs_df[\"bell\"] >= p_thr].tolist()\n",
    "u_ids = probs_df.index[probs_df[\"U\"] >= p_thr].tolist()\n",
    "inc_ids = probs_df.index[probs_df[\"increasing\"] >= p_thr].tolist()\n",
    "dec_ids = probs_df.index[probs_df[\"decreasing\"] >= p_thr].tolist()\n",
    "flat_ids = probs_df.index[probs_df[\"flat\"] >= p_thr].tolist()\n",
    "complex_ids = probs_df.index[probs_df[\"complex\"] >= p_thr].tolist()\n",
    "\n",
    "print(\"bell\", len(bell_ids), \"U\", len(u_ids), \"inc\", len(inc_ids), \"dec\", len(dec_ids), \"flat\", len(flat_ids), \"complex\", len(complex_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "49178b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit=0 rep=0 label=complex\n",
      "{'sig_max': [], 'sig_min': [], 'prom_thr_local': 0.05176446801877383, 'frac_pos': 0.0, 'frac_neg': 0.19607843137254902, 'frac_flat': 0.803921568627451, 'eps_dx': 0.012941117004693458, 'net_change': -0.618043551684949, 'net_thr': 0.038823351014080375}\n",
      "--------------------------------------------------------------------------------\n",
      "unit=0 rep=1 label=complex\n",
      "{'sig_max': [], 'sig_min': [], 'prom_thr_local': 0.05176446801877383, 'frac_pos': 0.0, 'frac_neg': 0.13725490196078433, 'frac_flat': 0.8627450980392157, 'eps_dx': 0.012941117004693458, 'net_change': -0.6051822686574454, 'net_thr': 0.038823351014080375}\n",
      "--------------------------------------------------------------------------------\n",
      "unit=0 rep=2 label=complex\n",
      "{'sig_max': [], 'sig_min': [], 'prom_thr_local': 0.05176446801877383, 'frac_pos': 0.0, 'frac_neg': 0.1568627450980392, 'frac_flat': 0.8431372549019608, 'eps_dx': 0.012941117004693458, 'net_change': -0.6136022921438574, 'net_thr': 0.038823351014080375}\n",
      "--------------------------------------------------------------------------------\n",
      "unit=0 rep=3 label=complex\n",
      "{'sig_max': [], 'sig_min': [], 'prom_thr_local': 0.05176446801877383, 'frac_pos': 0.0, 'frac_neg': 0.09803921568627451, 'frac_flat': 0.9019607843137255, 'eps_dx': 0.012941117004693458, 'net_change': -0.5701998720491801, 'net_thr': 0.038823351014080375}\n",
      "--------------------------------------------------------------------------------\n",
      "unit=0 rep=4 label=complex\n",
      "{'sig_max': [], 'sig_min': [], 'prom_thr_local': 0.05176446801877383, 'frac_pos': 0.0, 'frac_neg': 0.09803921568627451, 'frac_flat': 0.9019607843137255, 'eps_dx': 0.012941117004693458, 'net_change': -0.6012397043973997, 'net_thr': 0.038823351014080375}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "u = 0  # unit id you care about\n",
    "rb = rates_boot_by_unit[u]          # (n_boot, n_bins)\n",
    "sigma_y = _robust_sigma_y_from_boot(rb)\n",
    "\n",
    "for r in [0, 1, 2, 3, 4]:  # pick some reps\n",
    "    label, dbg = classify_curve_deriv_extrema(\n",
    "        centers,\n",
    "        rb[r, :],\n",
    "        sigma_y=sigma_y,\n",
    "        smooth_win=5,\n",
    "        edge_bins=6,\n",
    "        flat_factor=1.5,\n",
    "        prom_factor=2.0,\n",
    "        prom_factor_local=2.0,\n",
    "        dx_factor=1.0,\n",
    "        min_valid_bins=8,\n",
    "    )\n",
    "    print(f\"unit={u} rep={r} label={label}\")\n",
    "    print(dbg)\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b6e21529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot tuning grid\n",
    "plot_tuning_grid_bootstrap(\n",
    "    speed_tuning, lo, hi, speed_centers,\n",
    "    column=\"speed\",\n",
    "    n_units=-1,\n",
    "    s=3,\n",
    "    color=\"tab:blue\",\n",
    "    peak_normalize = True,\n",
    "    linewidth = 2,\n",
    "    indices = bell_ids,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58c1c149",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speed_tuning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m unit_to_plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m      4\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      5\u001b[0m plot_unit_tuning_bootstrap(\n\u001b[1;32m      6\u001b[0m     unit_to_plot,\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mspeed_tuning\u001b[49m, speed_centers, lo, hi,\n\u001b[1;32m      8\u001b[0m     ax\u001b[38;5;241m=\u001b[39max,\n\u001b[1;32m      9\u001b[0m     color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtab:blue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     11\u001b[0m     linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     12\u001b[0m     peak_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,   \n\u001b[1;32m     13\u001b[0m     xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'speed_tuning' is not defined"
     ]
    }
   ],
   "source": [
    "#plot SINGLE UNIT tuning\n",
    "unit_to_plot = 70\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "plot_unit_tuning_bootstrap(\n",
    "    unit_to_plot,\n",
    "    speed_tuning, speed_centers, lo, hi,\n",
    "    ax=ax,\n",
    "    color=\"tab:blue\",\n",
    "    s=3,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,   \n",
    "    xlabel=\"speed\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2551236",
   "metadata": {},
   "source": [
    "##### Stability within an epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7c38e",
   "metadata": {},
   "source": [
    "###### Run for ONE epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "766d908a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: [2.0, 4.0, 6.0, 8.0]\n",
      "epoch [2, 4]: n_trials=95 (early=47, late=48)\n"
     ]
    }
   ],
   "source": [
    "# --- Early vs Late - for PLOTTING one unit\n",
    "df = trialized_position.copy()\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "trial_types = [\"inbound\", \"outbound\"]\n",
    "track_segment_ids = [0, 1, 2, 3, 4]\n",
    "zones = [\"run\"]\n",
    "\n",
    "base_mask = (\n",
    "    df[\"trial_type\"].isin(trial_types)\n",
    "    & df[\"track_segment_id\"].isin(track_segment_ids)\n",
    "    & df[\"zone\"].isin(zones)\n",
    ")\n",
    "\n",
    "epoch_vals = sorted(df.loc[base_mask, \"epoch\"].dropna().unique())\n",
    "print(\"Epochs:\", epoch_vals)\n",
    "# e = epoch_vals[0]  \n",
    "e = [2,4]\n",
    "\n",
    "\n",
    "trials_e = np.sort(df.loc[base_mask & (df[\"epoch\"].isin(e)), \"trial_number\"].dropna().unique())\n",
    "M = len(trials_e)\n",
    "half = M // 2\n",
    "early_trials = trials_e[:half]\n",
    "late_trials  = trials_e[half:]\n",
    "print(f\"epoch {e}: n_trials={M} (early={len(early_trials)}, late={len(late_trials)})\")\n",
    "\n",
    "mask_early = base_mask & (df[\"epoch\"].isin(e)) & (df[\"trial_number\"].isin(early_trials))\n",
    "mask_late  = base_mask & (df[\"epoch\"].isin(e)) & (df[\"trial_number\"].isin(late_trials))\n",
    "\n",
    "\n",
    "column = \"speed\"     \n",
    "tuner_min = 10\n",
    "tuner_max = 120\n",
    "window_width = 20\n",
    "window_step  = 2\n",
    "\n",
    "common_kwargs = dict(\n",
    "    spikes_list=spikes_list,\n",
    "    column=column,\n",
    "    binning=\"sliding\",      \n",
    "    window_width=window_width,\n",
    "    window_step=window_step,\n",
    "    tuner_min=tuner_min,\n",
    "    tuner_max=tuner_max,\n",
    "    trial_column=\"trial_number\",\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    "    peak_normalize=True,        \n",
    ")\n",
    "\n",
    "tun_early, centers, lo_early, hi_early, *_ = compute_tuning_bootstrap_trials(\n",
    "    df, mask=mask_early, **common_kwargs\n",
    ")\n",
    "tun_late, centers2, lo_late, hi_late, *_ = compute_tuning_bootstrap_trials(\n",
    "    df, mask=mask_late, **common_kwargs\n",
    ")\n",
    "\n",
    "if not np.allclose(centers, centers2, equal_nan=True):\n",
    "    raise ValueError(\"Early/Late centers differ; ensure tuner_min/max and window_width/step are identical.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad047eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- plot one unit: overlay early and late on the same axis ----\n",
    "unit_to_plot = 70\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.2*2, 3.5*2))\n",
    "\n",
    "plot_unit_tuning_bootstrap(\n",
    "    unit_to_plot,\n",
    "    tun_early, centers, lo_early, hi_early,\n",
    "    ax=ax,\n",
    "    s=4,\n",
    "    linewidth=2,\n",
    "    peak_normalize=False,    # already normalized in compute_tuning_bootstrap_trials\n",
    "    color = \"tab:blue\",\n",
    "    xlabel=column,\n",
    "    title=None,\n",
    "    ci_alpha=0.18,\n",
    ")\n",
    "\n",
    "plot_unit_tuning_bootstrap(\n",
    "    unit_to_plot,\n",
    "    tun_late, centers, lo_late, hi_late,\n",
    "    ax=ax,\n",
    "    s=4,\n",
    "    linewidth=2,\n",
    "    color = \"tab:red\",\n",
    "    peak_normalize=False,    # already normalized in compute\n",
    "    xlabel=column,\n",
    "    title=None,\n",
    "    ci_alpha=0.18,\n",
    ")\n",
    "\n",
    "# ax.set_title(f\"Unit {unit_to_plot} (epoch {e}): early vs late (continuous bins)\")\n",
    "ax.legend([\"early\", \"early CI\", \"late\", \"late CI\"], frameon=False)  # optional; depends on your function behavior\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21cb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: [2.0, 4.0, 6.0, 8.0]\n",
      "8.0 52\n",
      "n_centers: 41\n"
     ]
    }
   ],
   "source": [
    "# --- compute early and late -- SLIDING WINDOW version\n",
    "\n",
    "df = trialized_position.copy()\n",
    "\n",
    "base_mask = (\n",
    "    (df[\"zone\"] == \"run\")\n",
    "    & (df[\"trial_type\"].isin([\"inbound\", \"outbound\"]))\n",
    ")\n",
    "\n",
    "epoch_vals = sorted(df.loc[base_mask, \"epoch\"].dropna().unique())\n",
    "print(\"Epochs:\", epoch_vals)\n",
    "\n",
    "e = epoch_vals[3]\n",
    "trials_e = np.sort(df.loc[base_mask & (df[\"epoch\"] == e), \"trial_number\"].dropna().unique())\n",
    "\n",
    "M = len(trials_e)\n",
    "print(e, M)\n",
    "half = M // 2\n",
    "contig_A = trials_e[:half]\n",
    "contig_B = trials_e[half:]\n",
    "\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "# --- sliding-window parameters (speed_norm is [0,1]) ---\n",
    "window_width = 0.20   # window size in speed_norm units\n",
    "window_step  = 0.02   # step size; smaller => more bins\n",
    "\n",
    "def tuning_for_trials(epoch_val, trial_subset, n_boot=200, seed=0, spikes_list = spikes_list, peak_normalize = True):\n",
    "    # Returns exactly (tuning, centers) so downstream unpacking works in all sections.\n",
    "    # (n_boot/seed are accepted for API compatibility but unused here.)\n",
    "    m = base_mask & (df[\"epoch\"] == epoch_val) & (df[\"trial_number\"].isin(trial_subset))\n",
    "    tuning, centers = compute_tuning(\n",
    "        df,\n",
    "        column=\"speed_norm\",\n",
    "        spikes_list=spikes_list,\n",
    "        n_bins=8,  # ignored for binning='sliding'\n",
    "        mask=m,\n",
    "        binning=\"sliding\",\n",
    "        window_width=window_width,\n",
    "        window_step=window_step,\n",
    "        tuner_min=0.0,\n",
    "        tuner_max=1.0,\n",
    "        peak_normalize=peak_normalize,\n",
    "    )\n",
    "    return tuning, centers\n",
    "\n",
    "tunA, centers, *_ = tuning_for_trials(e, contig_A)\n",
    "tunB, centersB, *_ = tuning_for_trials(e, contig_B)\n",
    "\n",
    "# sanity check: centers should match\n",
    "if not np.allclose(centers, centersB, equal_nan=True):\n",
    "    raise ValueError(\"Sliding-window centers differ between splits; check your binning params.\")\n",
    "\n",
    "units = sorted(tunA.keys())\n",
    "print(\"n_centers:\", len(centers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09d55835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contiguous split summary:\n",
      "  median corr: 0.7139763043966885\n",
      "  median nrmse: 0.2501487921678058\n",
      "  median peak shift (bins): 4.0\n",
      "  median mean-rate diff: 0.05355886022723155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labuser/miniforge3/envs/spyglass/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/home/labuser/miniforge3/envs/spyglass/lib/python3.10/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# metrics for contigous epoch split\n",
    "\n",
    "contiguous_curve_correlation = {}\n",
    "contiguous_curve_nrmse = {}\n",
    "contiguous_peak_shift_bins = {}\n",
    "contiguous_mean_rate_diff = {}\n",
    "\n",
    "for unit_id in units:\n",
    "    curve_first_half = tunA[unit_id]\n",
    "    curve_second_half = tunB[unit_id]\n",
    "\n",
    "    contiguous_curve_correlation[unit_id] = curve_corr(curve_first_half, curve_second_half)\n",
    "    contiguous_curve_nrmse[unit_id] = nrmse(curve_first_half, curve_second_half)\n",
    "    contiguous_peak_shift_bins[unit_id] = peak_bin_shift(curve_first_half, curve_second_half)\n",
    "    contiguous_mean_rate_diff[unit_id] = mean_rate_diff(curve_first_half, curve_second_half)\n",
    "\n",
    "print(\"Contiguous split summary:\")\n",
    "print(\"  median corr:\", np.nanmedian(list(contiguous_curve_correlation.values())))\n",
    "print(\"  median nrmse:\", np.nanmedian(list(contiguous_curve_nrmse.values())))\n",
    "print(\"  median peak shift (bins):\", np.nanmedian(list(contiguous_peak_shift_bins.values())))\n",
    "print(\"  median mean-rate diff:\", np.nanmedian(list(contiguous_mean_rate_diff.values())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91d2e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_split_runs = 1000\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "null_curve_correlation = {unit_id: [] for unit_id in units}\n",
    "null_curve_nrmse = {unit_id: [] for unit_id in units}\n",
    "null_peak_shift_bins = {unit_id: [] for unit_id in units}\n",
    "null_mean_rate_diff = {unit_id: [] for unit_id in units}\n",
    "\n",
    "for run_idx in range(random_split_runs):\n",
    "    permuted_trials = rng.permutation(trials_e)\n",
    "    trials_split_A = permuted_trials[:half]\n",
    "    trials_split_B = permuted_trials[half:]\n",
    "\n",
    "    tuning_A, _, *_ = tuning_for_trials(e, trials_split_A, n_boot=200, seed=run_idx + 1)\n",
    "    tuning_B, _, *_ = tuning_for_trials(e, trials_split_B, n_boot=200, seed=1000 + run_idx + 1)\n",
    "\n",
    "    for unit_id in units:\n",
    "        curve_A = tuning_A[unit_id]\n",
    "        curve_B = tuning_B[unit_id]\n",
    "\n",
    "        null_curve_correlation[unit_id].append(curve_corr(curve_A, curve_B))\n",
    "        null_curve_nrmse[unit_id].append(nrmse(curve_A, curve_B))\n",
    "        null_peak_shift_bins[unit_id].append(peak_bin_shift(curve_A, curve_B))\n",
    "        null_mean_rate_diff[unit_id].append(mean_rate_diff(curve_A, curve_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f63a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9386693370152308"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit = 70\n",
    "print(contiguous_curve_correlation[unit])\n",
    "print(contiguous_curve_nrmse[unit])\n",
    "print(contiguous_peak_shift_bins[unit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d976c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- per-unit p-values (contiguous vs null) ----------\n",
    "# For corr: low is worse -> p = P(null <= contig)\n",
    "# For others: high is worse -> p = P(null >= contig)\n",
    "p_corr = {}\n",
    "p_nrmse = {}\n",
    "p_peak_shift = {}\n",
    "p_mean_rate_diff = {}\n",
    "\n",
    "for unit_id in units:\n",
    "    null_c = np.asarray(null_curve_correlation[unit_id], float)\n",
    "    null_e = np.asarray(null_curve_nrmse[unit_id], float)\n",
    "    null_p = np.asarray(null_peak_shift_bins[unit_id], float)\n",
    "    null_m = np.asarray(null_mean_rate_diff[unit_id], float)\n",
    "\n",
    "    null_c = null_c[np.isfinite(null_c)]\n",
    "    null_e = null_e[np.isfinite(null_e)]\n",
    "    null_p = null_p[np.isfinite(null_p)]\n",
    "    null_m = null_m[np.isfinite(null_m)]\n",
    "\n",
    "    contig_c = contiguous_curve_correlation[unit_id]\n",
    "    contig_e = contiguous_curve_nrmse[unit_id]\n",
    "    contig_p = contiguous_peak_shift_bins[unit_id]\n",
    "    contig_m = contiguous_mean_rate_diff[unit_id]\n",
    "    p_corr[unit_id] = np.nan if null_c.size == 0 else float(np.mean(null_c <= contig_c))\n",
    "    p_nrmse[unit_id] = np.nan if null_e.size == 0 else float(np.mean(null_e >= contig_e))\n",
    "    p_peak_shift[unit_id] = np.nan if null_p.size == 0 else float(np.mean(null_p >= contig_p))\n",
    "    p_mean_rate_diff[unit_id] = np.nan if null_m.size == 0 else float(np.mean(null_m >= contig_m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b99b3ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Within-epoch labels (alpha=0.05):\n",
      "  stationary: 255\n",
      "  drifting: 7\n",
      "  insufficient: 1\n",
      "\n",
      "Drift type:\n",
      "  shape drift: 4\n",
      "  rate drift: 5\n",
      "\n",
      "Null baseline (median across units of per-unit median):\n",
      "  corr: 0.7060447330243675\n",
      "  nrmse: 0.24652259777444918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3420873/2753853428.py:40: RuntimeWarning: All-NaN slice encountered\n",
      "  median_of_unit_median_null_corr = np.nanmedian([np.nanmedian(null_curve_correlation[u]) for u in units])\n"
     ]
    }
   ],
   "source": [
    "#label units\n",
    "alpha = 0.05\n",
    "\n",
    "within_epoch_shape_drift = {}\n",
    "within_epoch_rate_drift = {}\n",
    "within_epoch_status = {}\n",
    "\n",
    "for unit_id in units:\n",
    "    if (not np.isfinite(p_corr[unit_id]) or\n",
    "        not np.isfinite(p_nrmse[unit_id]) or\n",
    "        not np.isfinite(p_peak_shift[unit_id]) or\n",
    "        not np.isfinite(p_mean_rate_diff[unit_id])):\n",
    "        within_epoch_status[unit_id] = \"insufficient\"\n",
    "        within_epoch_shape_drift[unit_id] = False\n",
    "        within_epoch_rate_drift[unit_id] = False\n",
    "        continue\n",
    "\n",
    "    # shape metrics: correlation and peak shift\n",
    "    shape_drift = (p_corr[unit_id] < alpha) and (p_peak_shift[unit_id] < alpha)\n",
    "    # rate metrics: rate diff and nrmse\n",
    "    rate_drift = (p_nrmse[unit_id] < alpha) and (p_mean_rate_diff[unit_id] < alpha)\n",
    "\n",
    "    within_epoch_shape_drift[unit_id] = shape_drift\n",
    "    within_epoch_rate_drift[unit_id] = rate_drift\n",
    "\n",
    "    if shape_drift or rate_drift:\n",
    "        within_epoch_status[unit_id] = \"drifting\"\n",
    "    else:\n",
    "        within_epoch_status[unit_id] = \"stationary\"\n",
    "\n",
    "print(\"\\nWithin-epoch labels (alpha=0.05):\")\n",
    "print(\"  stationary:\", sum(v == \"stationary\" for v in within_epoch_status.values()))\n",
    "print(\"  drifting:\", sum(v == \"drifting\" for v in within_epoch_status.values()))\n",
    "print(\"  insufficient:\", sum(v == \"insufficient\" for v in within_epoch_status.values()))\n",
    "\n",
    "print(\"\\nDrift type:\")\n",
    "print(\"  shape drift:\", sum(within_epoch_shape_drift.values()))\n",
    "print(\"  rate drift:\", sum(within_epoch_rate_drift.values()))\n",
    "\n",
    "median_of_unit_median_null_corr = np.nanmedian([np.nanmedian(null_curve_correlation[u]) for u in units])\n",
    "median_of_unit_median_null_nrmse = np.nanmedian([np.nanmedian(null_curve_nrmse[u]) for u in units])\n",
    "\n",
    "print(\"\\nNull baseline (median across units of per-unit median):\")\n",
    "print(\"  corr:\", median_of_unit_median_null_corr)\n",
    "print(\"  nrmse:\", median_of_unit_median_null_nrmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f3982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EXAMPLE PLOT for correlation (lower tail) ---\n",
    "unit_to_show = units[70]  # pick unit\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7.52*2.5, 2.82*2.5))\n",
    "illustrate_pvalue_rule_for_unit(\n",
    "    unit_to_show,\n",
    "    null_metric_dict=null_curve_correlation,\n",
    "    contig_metric_dict=contiguous_curve_correlation,\n",
    "    alpha=0.05,\n",
    "    direction=\"lower\",\n",
    "    xlabel=\"null correlation\",\n",
    "    ax=ax,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754047c4",
   "metadata": {},
   "source": [
    "###### Run for ALL epochs together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662b9967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: [2.0, 4.0, 6.0, 8.0]\n",
      "2.0\n",
      "epoch 2.0: stationary=190 drifting=61 insufficient=12\n",
      "4.0\n",
      "epoch 4.0: stationary=198 drifting=60 insufficient=5\n",
      "6.0\n",
      "epoch 6.0: stationary=185 drifting=72 insufficient=6\n",
      "8.0\n",
      "epoch 8.0: stationary=248 drifting=11 insufficient=4\n",
      "Analyzed epochs: [2.0, 4.0, 6.0, 8.0]\n",
      "Overall (>=3/4 rule):\n",
      "  required_stationary: 3 out of 4\n",
      "  stable: 204\n",
      "  drifting: 52\n",
      "  insufficient: 7\n"
     ]
    }
   ],
   "source": [
    "df = trialized_position.copy()\n",
    "df = df.sort_index()  \n",
    "\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "base_mask = (\n",
    "    (df[\"zone\"] == \"run\")\n",
    "    & (df[\"trial_type\"].isin([\"inbound\", \"outbound\"]))\n",
    ")\n",
    "\n",
    "# epochs to analyze\n",
    "epoch_vals = sorted(df.loc[base_mask, \"epoch\"].dropna().unique())\n",
    "print(\"Epochs:\", epoch_vals)\n",
    "\n",
    "column = \"speed_norm\"\n",
    "window_width = 0.20\n",
    "window_step = 0.02\n",
    "tuner_min = 0.0\n",
    "tuner_max = 1.0\n",
    "\n",
    "# stability test parameters\n",
    "alpha = 0.05\n",
    "random_split_runs = 50\n",
    "min_trials_per_epoch = 6  \n",
    "min_units_ok_bins = 3   \n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "\n",
    "def tuning_for_trials(\n",
    "    epoch_val,\n",
    "    trial_subset,\n",
    "    n_boot=200,\n",
    "    seed=0,\n",
    "    spikes_list=spikes_list,\n",
    "    peak_normalize=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Drop-in replacement: `epoch_val` can be a scalar (single epoch) OR any list-like\n",
    "    (list/tuple/set/np.ndarray/pd.Series/pd.Index) of epochs.\n",
    "    \"\"\"\n",
    "    # Normalize numpy 0-d arrays (e.g. np.array(3.0)) into a scalar\n",
    "    if isinstance(epoch_val, np.ndarray) and epoch_val.ndim == 0:\n",
    "        epoch_val = epoch_val.item()\n",
    "\n",
    "    # Decide whether epoch_val is \"list-like\" (multiple epochs) vs scalar (single epoch)\n",
    "    epoch_is_list_like = False\n",
    "    if isinstance(epoch_val, np.ndarray):\n",
    "        epoch_is_list_like = epoch_val.ndim > 0\n",
    "    elif isinstance(epoch_val, (str, bytes)):\n",
    "        epoch_is_list_like = False\n",
    "    elif np.isscalar(epoch_val):\n",
    "        epoch_is_list_like = False\n",
    "    else:\n",
    "        # pandas Index/Series, lists, tuples, sets, etc.\n",
    "        try:\n",
    "            iter(epoch_val)\n",
    "            epoch_is_list_like = True\n",
    "        except TypeError:\n",
    "            epoch_is_list_like = False\n",
    "\n",
    "    if epoch_is_list_like:\n",
    "        epoch_mask = df[\"epoch\"].isin(list(epoch_val))\n",
    "    else:\n",
    "        epoch_mask = df[\"epoch\"] == epoch_val\n",
    "\n",
    "    m = base_mask & epoch_mask & df[\"trial_number\"].isin(trial_subset)\n",
    "\n",
    "    tuning, centers = compute_tuning(\n",
    "        df,\n",
    "        column=column,\n",
    "        spikes_list=spikes_list,\n",
    "        n_bins=8,  # ignored for binning='sliding'\n",
    "        mask=m,\n",
    "        binning=\"sliding\",\n",
    "        window_width=window_width,\n",
    "        window_step=window_step,\n",
    "        tuner_min=tuner_min,\n",
    "        tuner_max=tuner_max,\n",
    "        peak_normalize=peak_normalize,\n",
    "    )\n",
    "    return tuning, centers\n",
    "\n",
    "\n",
    "\n",
    "per_epoch_results = {}   # epoch -> dict with per-unit stats/status\n",
    "\n",
    "for e in epoch_vals:\n",
    "    print(e)\n",
    "    trials_e = np.sort(df.loc[base_mask & (df[\"epoch\"] == e), \"trial_number\"].dropna().unique())\n",
    "    M = len(trials_e)\n",
    "\n",
    "    if M < min_trials_per_epoch:\n",
    "        print(f\"epoch {e}: skipped (only {M} trials)\")\n",
    "        continue\n",
    "\n",
    "    half = M // 2\n",
    "    contig_A = trials_e[:half]\n",
    "    contig_B = trials_e[half:]\n",
    "\n",
    "    # contiguous split tunings (peak-normalized so metrics focus on shape)\n",
    "    tunA, centers = tuning_for_trials(e, contig_A, peak_normalize=True)\n",
    "    tunB, centersB = tuning_for_trials(e, contig_B, peak_normalize=True)\n",
    "\n",
    "    if not np.allclose(centers, centersB, equal_nan=True):\n",
    "        raise ValueError(f\"epoch {e}: centers differ between splits; check sliding bin params.\")\n",
    "\n",
    "    units = sorted(tunA.keys())\n",
    "\n",
    "    # observed contiguous metrics\n",
    "    contig_corr = {}\n",
    "    contig_nrmse = {}\n",
    "    contig_peakx = {}\n",
    "\n",
    "    for u in units:\n",
    "        contig_corr[u] = curve_corr(tunA[u], tunB[u], min_bins=min_units_ok_bins)\n",
    "        contig_nrmse[u] = nrmse(tunA[u], tunB[u], min_bins=min_units_ok_bins)\n",
    "        contig_peakx[u] = peak_bin_shift(tunA[u], tunB[u], centers, min_bins=min_units_ok_bins)\n",
    "\n",
    "    # null distributions per unit\n",
    "    null_corr = {u: [] for u in units}\n",
    "    null_nrmse = {u: [] for u in units}\n",
    "    null_peakx = {u: [] for u in units}\n",
    "\n",
    "    for run_idx in range(random_split_runs):\n",
    "        perm = rng.permutation(trials_e)\n",
    "        A = perm[:half]\n",
    "        B = perm[half:]\n",
    "\n",
    "        tA, cA = tuning_for_trials(e, A, peak_normalize=True)\n",
    "        tB, cB = tuning_for_trials(e, B, peak_normalize=True)\n",
    "\n",
    "        if not np.allclose(cA, centers, equal_nan=True) or not np.allclose(cB, centers, equal_nan=True):\n",
    "            raise ValueError(f\"epoch {e}: centers mismatch inside null loop; check fixed tuner_min/max.\")\n",
    "\n",
    "        for u in units:\n",
    "            null_corr[u].append(curve_corr(tA[u], tB[u], min_bins=min_units_ok_bins))\n",
    "            null_nrmse[u].append(nrmse(tA[u], tB[u], min_bins=min_units_ok_bins))\n",
    "            null_peakx[u].append(peak_bin_shift(tA[u], tB[u], centers, min_bins=min_units_ok_bins))\n",
    "\n",
    "    # p-values (same logic as your original, adapted to peak_bin_shift)\n",
    "    p_corr = {}\n",
    "    p_nrmse = {}\n",
    "    p_peakx = {}\n",
    "\n",
    "    for u in units:\n",
    "        nc = np.asarray(null_corr[u], float);   nc = nc[np.isfinite(nc)]\n",
    "        ne = np.asarray(null_nrmse[u], float);  ne = ne[np.isfinite(ne)]\n",
    "        npk = np.asarray(null_peakx[u], float); npk = npk[np.isfinite(npk)]\n",
    "\n",
    "        oc = contig_corr[u]\n",
    "        oe = contig_nrmse[u]\n",
    "        op = contig_peakx[u]\n",
    "\n",
    "        # corr: low is worse -> p = P(null <= contig)\n",
    "        p_corr[u]  = np.nan if nc.size == 0 or not np.isfinite(oc) else float(np.mean(nc <= oc))\n",
    "        # nrmse: high is worse -> p = P(null >= contig)\n",
    "        p_nrmse[u] = np.nan if ne.size == 0 or not np.isfinite(oe) else float(np.mean(ne >= oe))\n",
    "        # peak shift (x): high is worse -> p = P(null >= contig)\n",
    "        p_peakx[u] = np.nan if npk.size == 0 or not np.isfinite(op) else float(np.mean(npk >= op))\n",
    "\n",
    "    # classify per unit within this epoch\n",
    "    status = {}\n",
    "    shape_drift = {}\n",
    "    rate_drift = {}\n",
    "\n",
    "    for u in units:\n",
    "        if (not np.isfinite(p_corr[u]) or not np.isfinite(p_nrmse[u]) or not np.isfinite(p_peakx[u])):\n",
    "            status[u] = \"insufficient\"\n",
    "            shape_drift[u] = False\n",
    "            rate_drift[u] = False\n",
    "            continue\n",
    "\n",
    "        # shape drift: corr low AND peak shift high\n",
    "        shape_drift[u] = (p_corr[u] < alpha) and (p_peakx[u] < alpha)\n",
    "        # â€œrate driftâ€:\n",
    "        rate_drift[u] = (p_nrmse[u] < alpha)\n",
    "\n",
    "        status[u] = \"drifting\" if (shape_drift[u] or rate_drift[u]) else \"stationary\"\n",
    "\n",
    "    per_epoch_results[e] = dict(\n",
    "        centers=centers,\n",
    "        contig_corr=contig_corr,\n",
    "        contig_nrmse=contig_nrmse,\n",
    "        contig_peakx=contig_peakx,\n",
    "        null_corr=null_corr,\n",
    "        null_nrmse=null_nrmse,\n",
    "        null_peakx=null_peakx,\n",
    "        p_corr=p_corr,\n",
    "        p_nrmse=p_nrmse,\n",
    "        p_peakx=p_peakx,\n",
    "        shape_drift=shape_drift,\n",
    "        rate_drift=rate_drift,\n",
    "        status=status,\n",
    "        n_trials=M,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"epoch {e}: stationary={sum(v=='stationary' for v in status.values())} \"\n",
    "        f\"drifting={sum(v=='drifting' for v in status.values())} \"\n",
    "        f\"insufficient={sum(v=='insufficient' for v in status.values())}\"\n",
    "    )\n",
    "\n",
    "# --- aggregate across epochs: stable if stationary in >=3/4 epochs ---\n",
    "\n",
    "analyzed_epochs = sorted(per_epoch_results.keys())\n",
    "print(\"Analyzed epochs:\", analyzed_epochs)\n",
    "\n",
    "if len(analyzed_epochs) == 0:\n",
    "    raise ValueError(\"No epochs analyzed (maybe too few trials per epoch).\")\n",
    "\n",
    "# units considered = intersection across analyzed epochs\n",
    "unit_sets = [set(per_epoch_results[e][\"status\"].keys()) for e in analyzed_epochs]\n",
    "units_all = sorted(set.intersection(*unit_sets))\n",
    "\n",
    "n_epochs = len(analyzed_epochs)\n",
    "\n",
    "# >=3/4 rule (generalized): require ceil(0.75 * n_epochs) stationary epochs\n",
    "required_stationary = int(np.ceil(0.75 * n_epochs))   # for 4 epochs => 3\n",
    "max_insufficient = n_epochs - required_stationary      # for 4 epochs => 1 (optional policy)\n",
    "\n",
    "overall_status = {}\n",
    "overall_stationary_count = {}\n",
    "\n",
    "for u in units_all:\n",
    "    st = [per_epoch_results[e][\"status\"][u] for e in analyzed_epochs]\n",
    "    n_stationary = sum(x == \"stationary\" for x in st)\n",
    "    n_insufficient = sum(x == \"insufficient\" for x in st)\n",
    "\n",
    "    overall_stationary_count[u] = n_stationary\n",
    "\n",
    "    # policy: if too many insufficient epochs, call overall insufficient\n",
    "    if n_insufficient > max_insufficient:\n",
    "        overall_status[u] = \"insufficient\"\n",
    "    elif n_stationary >= required_stationary:\n",
    "        overall_status[u] = \"stable\"\n",
    "    else:\n",
    "        overall_status[u] = \"drifting\"\n",
    "\n",
    "stable_units = [u for u in units_all if overall_status[u] == \"stable\"]\n",
    "unstable_units = [u for u in units_all if overall_status[u] == \"drifting\"]\n",
    "\n",
    "print(\"Overall (>=3/4 rule):\")\n",
    "print(\"  required_stationary:\", required_stationary, \"out of\", n_epochs)\n",
    "print(\"  stable:\", sum(v == \"stable\" for v in overall_status.values()))\n",
    "print(\"  drifting:\", sum(v == \"drifting\" for v in overall_status.values()))\n",
    "print(\"  insufficient:\", sum(v == \"insufficient\" for v in overall_status.values()))\n",
    "\n",
    "# `overall_status` is your final dict of labels\n",
    "# `stable_units` is the list of units stable in >=3/4 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "670df372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HISTOGRAM\n",
    "\n",
    "labels = list(overall_status.values())\n",
    "cats = [\"stable\", \"drifting\", \"insufficient\"]\n",
    "counts = {c: labels.count(c) for c in cats}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "ax.bar(cats, [counts[c] for c in cats], color=[colors[0], colors[1], colors[2]], alpha=0.9)\n",
    "ax.set_ylabel(\"Number of units\")\n",
    "# ax.set_title(\"Overall stability labels (>=3/4 rule)\")\n",
    "\n",
    "# annotate counts on bars\n",
    "for i, c in enumerate(cats):\n",
    "    ax.text(i, counts[c] + 0.5, str(counts[c]), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7bc188",
   "metadata": {},
   "source": [
    "##### Stability across epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c039608",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_epochs = epoch_vals[:2]\n",
    "last_epochs  = epoch_vals[2:]\n",
    "\n",
    "trials_first = np.sort(df.loc[base_mask & (df[\"epoch\"].isin(first_epochs)), \"trial_number\"].dropna().unique())\n",
    "trials_last  = np.sort(df.loc[base_mask & (df[\"epoch\"].isin(last_epochs)),  \"trial_number\"].dropna().unique())\n",
    "\n",
    "tuning_first, _, *_ = tuning_for_trials(first_epochs, trials_first, n_boot=200, seed=202, spikes_list = spikes_list)\n",
    "tuning_last,  _, *_ = tuning_for_trials(last_epochs,  trials_last,  n_boot=200, seed=808, spikes_list = spikes_list )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac5f6813",
   "metadata": {},
   "outputs": [],
   "source": [
    "between_epoch_corr = {}\n",
    "between_epoch_nrmse = {}\n",
    "between_epoch_peak_shift = {}\n",
    "# between_epoch_mean_rate_diff = {}\n",
    "units = sorted(tuning_first.keys())\n",
    "\n",
    "for unit_id in stable_units:\n",
    "    curve_first = tuning_first[unit_id]\n",
    "    curve_last  = tuning_last[unit_id]\n",
    "\n",
    "    between_epoch_corr[unit_id] = curve_corr(curve_first, curve_last)\n",
    "    between_epoch_nrmse[unit_id] = nrmse(curve_first, curve_last)\n",
    "    between_epoch_peak_shift[unit_id] = peak_bin_shift(curve_first, curve_last)\n",
    "    # between_epoch_mean_rate_diff[unit_id] = mean_rate_diff(curve_first, curve_last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b53d2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_between_corr = {}\n",
    "p_between_nrmse = {}\n",
    "p_between_peak = {}\n",
    "p_between_mean = {}\n",
    "\n",
    "for unit_id in stable_units:\n",
    "    null_c = np.asarray(null_curve_correlation[unit_id], float)\n",
    "    null_e = np.asarray(null_curve_nrmse[unit_id], float)\n",
    "    null_p = np.asarray(null_peak_shift_bins[unit_id], float)\n",
    "    null_m = np.asarray(null_mean_rate_diff[unit_id], float)\n",
    "\n",
    "    null_c = null_c[np.isfinite(null_c)]\n",
    "    null_e = null_e[np.isfinite(null_e)]\n",
    "    null_p = null_p[np.isfinite(null_p)]\n",
    "    null_m = null_m[np.isfinite(null_m)]\n",
    "\n",
    "    obs_c = between_epoch_corr[unit_id]\n",
    "    obs_e = between_epoch_nrmse[unit_id]\n",
    "    obs_p = between_epoch_peak_shift[unit_id]\n",
    "    # obs_m = between_epoch_mean_rate_diff[unit_id]\n",
    "\n",
    "    p_between_corr[unit_id]  = np.nan if null_c.size == 0 else float(np.mean(null_c <= obs_c))\n",
    "    p_between_nrmse[unit_id] = np.nan if null_e.size == 0 else float(np.mean(null_e >= obs_e))\n",
    "    p_between_peak[unit_id]  = np.nan if null_p.size == 0 else float(np.mean(null_p >= obs_p))\n",
    "    # p_between_mean[unit_id]  = np.nan if null_m.size == 0 else float(np.mean(null_m >= obs_m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80d9a4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Across-epoch stable: 180\n",
      "Across-epoch changed: 24\n",
      "Across-epoch insufficient: 0\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "across_epoch_shape_change = {}\n",
    "across_epoch_rate_change = {}\n",
    "across_epoch_status = {}\n",
    "\n",
    "for unit_id in stable_units:\n",
    "    if (not np.isfinite(p_between_corr[unit_id]) or\n",
    "        not np.isfinite(p_between_peak[unit_id]) or\n",
    "        not np.isfinite(p_between_nrmse[unit_id])):\n",
    "        # not np.isfinite(p_between_mean[unit_id])):\n",
    "        across_epoch_status[unit_id] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    shape_change = (p_between_corr[unit_id] < alpha) and (p_between_peak[unit_id] < alpha)\n",
    "    rate_change  = (p_between_nrmse[unit_id] < alpha) \n",
    "\n",
    "    across_epoch_shape_change[unit_id] = shape_change\n",
    "    across_epoch_rate_change[unit_id] = rate_change\n",
    "\n",
    "    across_epoch_status[unit_id] = \"changed\" if (shape_change or rate_change) else \"stable\"\n",
    "\n",
    "print(\"Across-epoch stable:\", sum(v==\"stable\" for v in across_epoch_status.values()))\n",
    "print(\"Across-epoch changed:\", sum(v==\"changed\" for v in across_epoch_status.values()))\n",
    "print(\"Across-epoch insufficient:\", sum(v==\"insufficient\" for v in across_epoch_status.values()))\n",
    "\n",
    "across_stable_units = np.where(np.array([value for value in across_epoch_status.values()]) == 'stable')\n",
    "across_drifting_units = np.where(np.array([value for value in across_epoch_status.values()]) != 'stable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d79f1c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: ([2, 4], [6, 8])\n"
     ]
    }
   ],
   "source": [
    "# --- drop-in: plot for all epochs with CONTINUOUS (sliding-window) bins ---\n",
    "\n",
    "df = trialized_position\n",
    "\n",
    "base_mask = (\n",
    "    (df[\"zone\"] == \"run\")\n",
    "    & (df[\"trial_type\"].isin([\"inbound\", \"outbound\"]))\n",
    "    # & (df[\"epoch\"].isin([2, 8]))\n",
    ")\n",
    "\n",
    "epoch_vals = ([2,4], [6,8])\n",
    "print(\"Epochs:\", epoch_vals)\n",
    "\n",
    "# continuous (sliding-window) binning for speed_norm in [0, 1]\n",
    "window_width = 0.20   # window size in speed_norm units\n",
    "window_step  = 0.02   # step size; smaller => more bins\n",
    "tuner_min = 0.0\n",
    "tuner_max = 1.0\n",
    "\n",
    "results_by_epoch = {}\n",
    "\n",
    "for ind, e in enumerate(epoch_vals):\n",
    "    mask_e = base_mask & (df[\"epoch\"].isin(e))\n",
    "\n",
    "    tuning, centers, lo, hi, slope_boot, curv_boot = compute_tuning_bootstrap_trials(\n",
    "        df,\n",
    "        column=\"speed_norm\",\n",
    "        spikes_list=spikes_list,\n",
    "        n_bins=8,  # ignored when binning='sliding'\n",
    "        mask=mask_e,\n",
    "        trial_column=\"trial_number\",\n",
    "        n_boot=500,\n",
    "        ci=0.95,\n",
    "        random_state=0,\n",
    "        binning=\"sliding\",\n",
    "        window_width=window_width,\n",
    "        window_step=window_step,\n",
    "        tuner_min=tuner_min,\n",
    "        tuner_max=tuner_max,\n",
    "        peak_normalize=True,  \n",
    "    )\n",
    "\n",
    "    results_by_epoch[ind] = dict(\n",
    "        tuning=tuning, centers=centers, lo=lo, hi=hi,\n",
    "        slope_boot=slope_boot, curv_boot=curv_boot,\n",
    "        mask=mask_e,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eff978c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot grids\n",
    "for ind,e in enumerate(epoch_vals):\n",
    "    r = results_by_epoch[ind]\n",
    "    plot_tuning_grid_bootstrap(\n",
    "        r[\"tuning\"], r[\"lo\"], r[\"hi\"], r[\"centers\"],\n",
    "        column=\"speed_norm\",\n",
    "        n_units=50,\n",
    "        label=f\"epoch {e}\",\n",
    "        indices= across_drifting_units[0].tolist(),\n",
    "        s = 5, \n",
    "        linewidth = 2,\n",
    "        peak_normalize = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f243a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAM\n",
    "# (assumed already computed)\n",
    "\n",
    "labels = list(across_epoch_status.values())\n",
    "cats = [\"stable\", \"changed\", \"insufficient\"]\n",
    "counts = {c: labels.count(c) for c in cats}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.2*2.5, 3.2*2.5))\n",
    "\n",
    "ax.bar(cats, [counts[c] for c in cats], color=[colors[0], colors[1], colors[2]], alpha=0.9)\n",
    "ax.set_ylabel(\"Number of units\")\n",
    "# ax.set_title(\"Overall stability labels (>=3/4 rule)\")\n",
    "\n",
    "# annotate counts on bars\n",
    "for i, c in enumerate(cats):\n",
    "    ax.text(i, counts[c] + 0.5, str(counts[c]), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7f0e3",
   "metadata": {},
   "source": [
    "#### Direction tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddee0fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#OUTBOUND VS INBOUND \n",
    "pos_df = trialized_position[(trialized_position[\"zone\"] == \"run\")].copy()\n",
    "arms = [2]\n",
    "last_trial = 1e6\n",
    "\n",
    "pos_mask_outin = (pos_df[\"track_segment_id\"].isin(arms))\n",
    "\n",
    "summary_outin , trial_outin  = compute_trialwise_firing_rates_two_trial_categories_with_pos_mask(\n",
    "    spikes_list=l_mpfc_spikes,\n",
    "    trials_df=trials_df[trials_df[\"trial_number\"] < last_trial],  \n",
    "    position_df=pos_df,\n",
    "    pos_mask=pos_mask_outin,\n",
    "    category_col=\"trial_type\",       \n",
    "    category_a=\"inbound\",\n",
    "    category_b=\"outbound\",\n",
    "    only_correct=True,\n",
    "    min_duration=0.5,              \n",
    ")\n",
    "\n",
    "mw_outin  = test_trialwise_firing_rates_two_trial_categories(\n",
    "    trialwise_df=trial_outin ,\n",
    "    category_a=\"inbound\",\n",
    "    category_b=\"outbound\",\n",
    "    min_trials_a=3,\n",
    "    min_trials_b=3,\n",
    "    alternative=\"two-sided\"\n",
    ")\n",
    "plot_trialwise_fr_two_categories_side_by_side(\n",
    "    summary_df=summary_outin ,\n",
    "    category_a=\"inbound\",\n",
    "    category_b=\"outbound\",\n",
    "    use_sem=True,\n",
    "    title = f\"Trialwise firing rate; inbound vs outbound\",\n",
    "    stats_df = mw_outin ,\n",
    "    alpha = 0.05\n",
    ")\n",
    "\n",
    "display(mw_outin [mw_outin [\"p_value\"]<0.05])\n",
    "print(\"Number of siginificant units: \", len(mw_outin [mw_outin [\"p_value\"]<0.05]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INBOUND LEFT VS RIGHT ONLY IN THE CENTRAL ARM\n",
    "trial_type = \"inbound\"\n",
    "category_a = \"left\"\n",
    "category_b = \"right\"\n",
    "arms = [2]\n",
    "last_trial = 1e6\n",
    "\n",
    "pos_df = trialized_position[(trialized_position[\"trial_type\"] == trial_type) & (trialized_position[\"zone\"] == \"run\")].copy()\n",
    "pos_mask_in_lr   = (pos_df[\"track_segment_id\"].isin(arms)) \n",
    "trials_df_subset = trials_df[(trials_df[\"trial_number\"] < last_trial) & (trials_df[\"trial_type\"]== trial_type)]\n",
    "\n",
    "summary_in_lr  , trial_in_lr   = compute_trialwise_firing_rates_two_trial_categories_with_pos_mask(\n",
    "    spikes_list=l_mpfc_spikes,\n",
    "    trials_df= trials_df_subset,  \n",
    "    position_df= pos_df,\n",
    "    pos_mask=pos_mask_in_lr  ,\n",
    "    category_col=\"left/right\",       \n",
    "    category_a= category_a,\n",
    "    category_b= category_b,\n",
    "    only_correct=True,\n",
    "    min_duration=0.5,                \n",
    ")\n",
    "\n",
    "\n",
    "mw_in_lr   = test_trialwise_firing_rates_two_trial_categories(\n",
    "    trialwise_df=trial_in_lr  ,\n",
    "    category_a= category_a,\n",
    "    category_b= category_b,\n",
    "    min_trials_a=3,\n",
    "    min_trials_b=3,\n",
    "    alternative=\"two-sided\",\n",
    ")\n",
    "\n",
    "plot_trialwise_fr_two_categories_side_by_side(\n",
    "    summary_df=summary_in_lr  ,\n",
    "    category_a= category_a,\n",
    "    category_b= category_b,\n",
    "    use_sem=True,\n",
    "    title = f\"Trialwise firing rate: {trial_type}; {category_a} vs {category_b} (valid arms: {arms})\",\n",
    "    stats_df = mw_in_lr  ,\n",
    "    alpha = 0.05\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "display(mw_in_lr  [mw_in_lr  [\"p_value\"]<0.05])\n",
    "print(\"Number of siginificant units: \", len(mw_in_lr  [mw_in_lr  [\"p_value\"]<0.05]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTBOUND LEFT VS RIGHT ONLY IN THE CENTRAL ARM\n",
    "trial_type = \"outbound\"\n",
    "category_a = \"left\"\n",
    "category_b = \"right\"\n",
    "arms = [2]\n",
    "last_trial = 31\n",
    "\n",
    "pos_df = trialized_position[(trialized_position[\"trial_type\"] == trial_type) & (trialized_position[\"zone\"] == \"run\")].copy()\n",
    "pos_mask_out_lr   = (pos_df[\"track_segment_id\"].isin(arms)) \n",
    "trials_df_subset = trials_df[(trials_df[\"trial_number\"] < last_trial) & (trials_df[\"trial_type\"]== trial_type)]\n",
    "\n",
    "summary_out_lr  , trial_out_lr   = compute_trialwise_firing_rates_two_trial_categories_with_pos_mask(\n",
    "    spikes_list=l_mpfc_spikes,\n",
    "    trials_df= trials_df_subset,  \n",
    "    position_df= pos_df,\n",
    "    pos_mask=pos_mask_out_lr  ,\n",
    "    category_col=\"left/right\",       \n",
    "    category_a= category_a,\n",
    "    category_b= category_b,\n",
    "    only_correct=True,\n",
    "    min_duration=0.5,                \n",
    ")\n",
    "\n",
    "\n",
    "mw_out_lr   = test_trialwise_firing_rates_two_trial_categories(\n",
    "    trialwise_df=trial_out_lr  ,\n",
    "    category_a= category_a,\n",
    "    category_b= category_b,\n",
    "    min_trials_a=3,\n",
    "    min_trials_b=3,\n",
    "    alternative=\"two-sided\",\n",
    ")\n",
    "\n",
    "plot_trialwise_fr_two_categories_side_by_side(\n",
    "    summary_df=summary_out_lr  ,\n",
    "    category_a= category_a,\n",
    "    category_b= category_b,\n",
    "    use_sem=True,\n",
    "    title = f\"Trialwise firing rate: {trial_type}; {category_a} vs {category_b} (valid arms: {arms})\",\n",
    "    stats_df = mw_out_lr  ,\n",
    "    alpha = 0.05\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "display(mw_out_lr  [mw_out_lr  [\"p_value\"]<0.05])\n",
    "print(\"Number of siginificant units: \", len(mw_out_lr  [mw_out_lr  [\"p_value\"]<0.05]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c529a0f4",
   "metadata": {},
   "source": [
    "#### Location tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1fae38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do speeds cluster at certain locations?\n",
    "\n",
    "zones = [\"run\"]\n",
    "trial_types = [\"outbound\"]  \n",
    "\n",
    "mask = (\n",
    "    trialized_position[\"zone\"].isin(zones)\n",
    "    & trialized_position[\"trial_type\"].isin(trial_types)\n",
    ")\n",
    "\n",
    "speed_col = \"speed\"\n",
    "n_bins = 8\n",
    "\n",
    "# Work only on the masked rows for binning\n",
    "speed_vals = trialized_position.loc[mask, speed_col].astype(float)\n",
    "speed_vals = speed_vals.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Guard: nothing to bin\n",
    "if speed_vals.empty:\n",
    "    raise ValueError(\"No finite speed values after applying mask; cannot bin/plot.\")\n",
    "\n",
    "bin_edges = np.linspace(speed_vals.min(), speed_vals.max(), n_bins + 1)\n",
    "speed_bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Assign bins for masked rows (others stay NaN)\n",
    "trialized_position[\"speed_bin\"] = np.nan\n",
    "trialized_position.loc[speed_vals.index, \"speed_bin\"] = pd.cut(\n",
    "    speed_vals,\n",
    "    bins=bin_edges,\n",
    "    labels=False,\n",
    "    include_lowest=True,\n",
    ").astype(int)\n",
    "\n",
    "binned_position_idx = [\n",
    "    trialized_position.index[mask & (trialized_position[\"speed_bin\"] == i)]\n",
    "    for i in range(n_bins)\n",
    "]\n",
    "\n",
    "# arrange on different axes in a 2-column grid\n",
    "n_cols = 2\n",
    "n_rows = int(np.ceil(n_bins / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    n_rows, n_cols,\n",
    "    layout=\"tight\",\n",
    "    figsize=(12, 3 * n_rows),\n",
    "    sharex=True, sharey=True,\n",
    ")\n",
    "\n",
    "axes = np.array(axes).reshape(-1)\n",
    "cmap = plt.get_cmap(\"viridis\", n_bins)\n",
    "\n",
    "# background once-per-axis, but use masked background (faster + consistent)\n",
    "background_df = trialized_position.loc[mask]\n",
    "\n",
    "for i, index in enumerate(binned_position_idx):\n",
    "    ax_i = axes[i]\n",
    "    color = cmap(i)\n",
    "\n",
    "    # background: all positions within mask\n",
    "    background_df.plot.scatter(\n",
    "        x=\"position_x\", y=\"position_y\",\n",
    "        s=4, ax=ax_i, color=\"k\", alpha=0.02,\n",
    "    )\n",
    "\n",
    "    # highlighted: this speed bin (already within mask by construction)\n",
    "    df_bin = trialized_position.loc[index]\n",
    "    df_bin.plot.scatter(\n",
    "        x=\"position_x\", y=\"position_y\",\n",
    "        s=8, ax=ax_i, color=color,\n",
    "        label=int(speed_bin_centers[i]),\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    ax_i.set_title(f\"bin {i} (center {int(speed_bin_centers[i])})\")\n",
    "    ax_i.set_xlabel(\"x position (cm)\")\n",
    "    ax_i.set_ylabel(\"y position (cm)\")\n",
    "\n",
    "# hide any unused axes\n",
    "for j in range(n_bins, len(axes)):\n",
    "    axes[j].axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2b5ed99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: speed_bins_map_outbound.svg (dpi=160, rasterized points)\n"
     ]
    }
   ],
   "source": [
    "# Plot all speed bins on one map (manual bin range 0â€“125 cm/s)\n",
    "# + Square plotting area (axes box is square)\n",
    "# + Save as small SVG with rasterized points\n",
    "\n",
    "from matplotlib import colors\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- user knobs ----------\n",
    "zones = [\"run\"]\n",
    "trial_types = [\"outbound\"]\n",
    "\n",
    "speed_col = \"speed\"\n",
    "n_bins = 8\n",
    "\n",
    "# Manual binning range (cm/s)\n",
    "speed_min = 0.0\n",
    "speed_max = 125.0\n",
    "\n",
    "# Saving\n",
    "save_svg = True\n",
    "out_path = Path(\"speed_bins_map_outbound.svg\")\n",
    "svg_dpi = 160  # lower = smaller file; affects rasterized parts in SVG\n",
    "\n",
    "# Optional downsampling (helps guarantee small files for huge datasets)\n",
    "max_points_background = 120_000\n",
    "max_points_colored = 120_000\n",
    "rng_seed = 0\n",
    "# -------------------------------\n",
    "\n",
    "mask = (\n",
    "    trialized_position[\"zone\"].isin(zones)\n",
    "    & trialized_position[\"trial_type\"].isin(trial_types)\n",
    ")\n",
    "\n",
    "# Background: all positions within mask\n",
    "df_background = trialized_position.loc[mask, [\"position_x\", \"position_y\"]].dropna()\n",
    "\n",
    "# Clean speed values within the mask\n",
    "speed_raw = trialized_position.loc[mask, speed_col].astype(float)\n",
    "speed_raw = speed_raw.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Keep only speeds within the manual range\n",
    "in_range = speed_raw.notna() & (speed_raw >= speed_min) & (speed_raw <= speed_max)\n",
    "\n",
    "if not in_range.any():\n",
    "    raise ValueError(\n",
    "        f\"No finite speed values within [{speed_min}, {speed_max}] cm/s after applying mask.\"\n",
    "    )\n",
    "\n",
    "# Manual bin edges + centers (fixed range regardless of data)\n",
    "bin_edges = np.linspace(speed_min, speed_max, n_bins + 1)\n",
    "speed_bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Assign bins only to in-range rows (others stay NaN)\n",
    "trialized_position[\"speed_bin\"] = np.nan\n",
    "trialized_position.loc[speed_raw.index[in_range], \"speed_bin\"] = pd.cut(\n",
    "    speed_raw.loc[in_range],\n",
    "    bins=bin_edges,\n",
    "    labels=False,\n",
    "    include_lowest=True,\n",
    ").astype(int)\n",
    "\n",
    "# Colored points to plot: only those with an assigned bin\n",
    "df_colored = trialized_position.loc[\n",
    "    speed_raw.index[in_range], [\"position_x\", \"position_y\", \"speed_bin\"]\n",
    "].dropna()\n",
    "\n",
    "# Optional downsampling to keep SVG small\n",
    "if max_points_background is not None and len(df_background) > max_points_background:\n",
    "    df_background = df_background.sample(n=max_points_background, random_state=rng_seed)\n",
    "\n",
    "if max_points_colored is not None and len(df_colored) > max_points_colored:\n",
    "    df_colored = df_colored.sample(n=max_points_colored, random_state=rng_seed)\n",
    "\n",
    "# Make SVG smaller: keep text as text (not vector paths)\n",
    "plt.rcParams[\"svg.fonttype\"] = \"none\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15), layout=\"tight\")\n",
    "\n",
    "# Background points (rasterized inside SVG)\n",
    "ax.scatter(\n",
    "    df_background[\"position_x\"].to_numpy(),\n",
    "    df_background[\"position_y\"].to_numpy(),\n",
    "    s=4,\n",
    "    c=\"k\",\n",
    "    alpha=0.015,\n",
    "    linewidths=0,\n",
    "    rasterized=True,\n",
    "    zorder=1,\n",
    ")\n",
    "\n",
    "# Stepped gradient with strong bin separation\n",
    "cmap = plt.get_cmap(\"turbo\", n_bins)  # try \"plasma\" if you prefer\n",
    "boundaries = np.arange(-0.5, n_bins + 0.5, 1.0)\n",
    "norm = colors.BoundaryNorm(boundaries, ncolors=n_bins)\n",
    "\n",
    "ax.scatter(\n",
    "    df_colored[\"position_x\"].to_numpy(),\n",
    "    df_colored[\"position_y\"].to_numpy(),\n",
    "    c=df_colored[\"speed_bin\"].to_numpy(),\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    s=12,\n",
    "    alpha=1.0,\n",
    "    linewidths=0,\n",
    "    rasterized=True,\n",
    "    zorder=2,\n",
    ")\n",
    "\n",
    "# ax.set_title(\n",
    "#     f\"Speed bins across position ({zones=}, {trial_types=}, range={speed_min:g}â€“{speed_max:g} cm/s, {n_bins} bins)\"\n",
    "# )\n",
    "ax.set_xlabel(\"x position (cm)\")\n",
    "ax.set_ylabel(\"y position (cm)\")\n",
    "\n",
    "# Make the plotting area (axes box) square\n",
    "ax.set_box_aspect(1)\n",
    "\n",
    "# Optional: if you want equal data scaling too (1 cm in x == 1 cm in y), uncomment:\n",
    "# ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "# Colorbar labeled in cm/s using bin centers\n",
    "mappable = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "mappable.set_array([])\n",
    "cbar = fig.colorbar(\n",
    "    mappable,\n",
    "    ax=ax,\n",
    "    ticks=np.arange(n_bins),\n",
    "    boundaries=boundaries,\n",
    "    fraction=0.046,\n",
    "    pad=0.04,\n",
    ")\n",
    "cbar.set_label(f\"{speed_col} (bin centers, cm/s)\")\n",
    "cbar.set_ticklabels([f\"{c:.1f}\" for c in speed_bin_centers])\n",
    "\n",
    "if save_svg:\n",
    "    fig.savefig(out_path, format=\"svg\", dpi=svg_dpi, bbox_inches=\"tight\")\n",
    "    print(f\"Saved: {out_path} (dpi={svg_dpi}, rasterized points)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "549dcf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spikes_list = l_mpfc_spikes.copy()\n",
    "zone = \"run\"\n",
    "trial_type = \"outbound\"\n",
    "mask = (trialized_position[\"trial_type\"] == f\"{trial_type}\") \\\n",
    "          #  & (trialized_position[\"track_segment_id\"]==2) \\\n",
    "           #     | (trialized_position[\"track_segment_id\"]==4))\n",
    "\n",
    "\n",
    "position_tuning, position_bin_centers = compute_tuning(\n",
    "    trialized_position,  # full df\n",
    "    \"linear_position\",\n",
    "    spikes_list,\n",
    "    n_bins=8,\n",
    "    mask=mask,\n",
    ")\n",
    "\n",
    "# plot_speed_tuning_heatmap(speed_tuning)\n",
    "\n",
    "plot_tuning_grid(position_tuning, \"linear_position\", trialized_position, spikes_list, None, n_units = 33, label = f\"({zone}; {trial_type})\")\n",
    "# plot_position_tuning_grid(position_tuning, trialized_position, spikes_list, mask, n_units = -1, label = f\"entire epoch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de29f3a",
   "metadata": {},
   "source": [
    "#### Progress tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f1420da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#progress in time\n",
    "df = e2_trialized_position.copy()\n",
    "\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "# spikes_list = spikes_list[160:200]\n",
    "zones = [\"run\"]\n",
    "trial_types = [\"inbound\", \"outbound\"]\n",
    "track_segment_ids = [0, 1,2,3,4]\n",
    "\n",
    "mask = ( df[\"trial_type\"].isin(trial_types)) & \\\n",
    "            ( df[\"track_segment_id\"].isin(track_segment_ids)) & \\\n",
    "                ( df[\"zone\"].isin(zones))\n",
    "\n",
    "\n",
    "progress_tuning,  progress_centers,  progress_lower,  progress_upper, slope_boot, curvature_boot = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    \"trial_progress\",\n",
    "    spikes_list,\n",
    "    n_bins=6,\n",
    "    mask=mask,\n",
    "    trial_column=\"trial_number\",\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "\n",
    "shape_by_unit, stats_by_unit = classify_tuning_shapes_from_bootstraps(\n",
    "    slope_boot,\n",
    "    curvature_boot,\n",
    "    ci=0.95,\n",
    "    min_valid_boot=200,   # you have lots of trials; you can be strict\n",
    ")\n",
    "unit_shapes = pd.Series(shape_by_unit)\n",
    "progress_bell_unit_ids = unit_shapes[unit_shapes==\"bell\"].index.tolist()\n",
    "progress_increasing_unit_ids = unit_shapes[unit_shapes==\"increasing\"].index.tolist()\n",
    "progress_decreasing_unit_ids = unit_shapes[unit_shapes==\"decreasing\"].index.tolist()\n",
    "progress_u_unit_ids = unit_shapes[unit_shapes==\"U\"].index.tolist()\n",
    "progress_complex_unit_ids = unit_shapes[unit_shapes==\"flat/complex\"].index.tolist()\n",
    "\n",
    "\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    progress_tuning,  progress_lower,  progress_upper,  progress_centers,\n",
    "    column= \"trial_progress\", \n",
    "    n_units=50, \n",
    "    indices = None,\n",
    "    label = \"epoch 2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1ae3c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#progress in distance\n",
    "df = e4_trialized_position.copy()\n",
    "\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "# spikes_list = spikes_list[160:200]\n",
    "zones = [\"run\"]\n",
    "trial_types = [\"inbound\", \"outbound\"]\n",
    "track_segment_ids = [0, 1,2,3,4]\n",
    "\n",
    "mask = ( df[\"trial_type\"].isin(trial_types)) & \\\n",
    "            ( df[\"track_segment_id\"].isin(track_segment_ids)) & \\\n",
    "                ( df[\"zone\"].isin(zones))\n",
    "\n",
    "\n",
    "\n",
    "progress_tuning,  progress_centers,  progress_lower,  progress_upper, slope_boot, curvature_boot = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    \"trial_progress_distance\",\n",
    "    spikes_list,\n",
    "    n_bins=8,\n",
    "    mask=mask,\n",
    "    trial_column=\"trial_number\",\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "\n",
    "shape_by_unit, stats_by_unit = classify_tuning_shapes_from_bootstraps(\n",
    "    slope_boot,\n",
    "    curvature_boot,\n",
    "    ci=0.95,\n",
    "    min_valid_boot=200, \n",
    ")\n",
    "unit_shapes = pd.Series(shape_by_unit)\n",
    "progress_bell_unit_ids = unit_shapes[unit_shapes==\"bell\"].index.tolist()\n",
    "progress_increasing_unit_ids = unit_shapes[unit_shapes==\"increasing\"].index.tolist()\n",
    "progress_decreasing_unit_ids = unit_shapes[unit_shapes==\"decreasing\"].index.tolist()\n",
    "progress_u_unit_ids = unit_shapes[unit_shapes==\"U\"].index.tolist()\n",
    "progress_complex_unit_ids = unit_shapes[unit_shapes==\"flat/complex\"].index.tolist()\n",
    "\n",
    "\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    progress_tuning,  progress_lower,  progress_upper,  progress_centers,\n",
    "    column= \"trial_progress_distance\",\n",
    "    n_units=30, \n",
    "    indices = speed_decreasing_unit_ids,\n",
    "    label = \"epoch 4\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b1ad787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning time shape counts\n",
      "-------------------\n",
      "Shape           Speed   Progress\n",
      "------------ -------- ----------\n",
      "bell               26         24\n",
      "increasing         55         87\n",
      "decreasing         94         76\n",
      "U                  24          8\n",
      "flat/complex       64         68\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuning time shape counts\")\n",
    "print(\"-------------------\")\n",
    "print(f\"{'Shape':<12} {'Speed':>8} {'Progress':>10}\")\n",
    "print(f\"{'-'*12} {'-'*8:>8} {'-'*10:>10}\")\n",
    "print(f\"{'bell':<12} {len(speed_bell_unit_ids):>8} {len(progress_bell_unit_ids):>10}\")\n",
    "print(f\"{'increasing':<12} {len(speed_increasing_unit_ids):>8} {len(progress_increasing_unit_ids):>10}\")\n",
    "print(f\"{'decreasing':<12} {len(speed_decreasing_unit_ids):>8} {len(progress_decreasing_unit_ids):>10}\")\n",
    "print(f\"{'U':<12} {len(speed_u_unit_ids):>8} {len(progress_u_unit_ids):>10}\")\n",
    "print(f\"{'flat/complex':<12} {len(speed_complex_unit_ids):>8} {len(progress_complex_unit_ids):>10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "61fbffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning distance shape counts\n",
      "-------------------\n",
      "Shape           Speed   Progress\n",
      "------------ -------- ----------\n",
      "bell               26         24\n",
      "increasing         55         87\n",
      "decreasing         94         76\n",
      "U                  24          8\n",
      "flat/complex       64         68\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuning distance shape counts\")\n",
    "print(\"-------------------\")\n",
    "print(f\"{'Shape':<12} {'Speed':>8} {'Progress':>10}\")\n",
    "print(f\"{'-'*12} {'-'*8:>8} {'-'*10:>10}\")\n",
    "print(f\"{'bell':<12} {len(speed_bell_unit_ids):>8} {len(progress_bell_unit_ids):>10}\")\n",
    "print(f\"{'increasing':<12} {len(speed_increasing_unit_ids):>8} {len(progress_increasing_unit_ids):>10}\")\n",
    "print(f\"{'decreasing':<12} {len(speed_decreasing_unit_ids):>8} {len(progress_decreasing_unit_ids):>10}\")\n",
    "print(f\"{'U':<12} {len(speed_u_unit_ids):>8} {len(progress_u_unit_ids):>10}\")\n",
    "print(f\"{'flat/complex':<12} {len(speed_complex_unit_ids):>8} {len(progress_complex_unit_ids):>10}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276b0e4",
   "metadata": {},
   "source": [
    "#### Speed vs progress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0629c1df",
   "metadata": {},
   "source": [
    "##### Calculate in various progress segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old method - NOT BALANCING FOR DATA\n",
    "df = trialized_position.copy()\n",
    "\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "# spikes_list = spikes_list[160:200]\n",
    "zones = [\"run\"]\n",
    "trial_types = [\"inbound\", \"outbound\"]\n",
    "track_segment_ids = [0, 1,2,3,4]\n",
    "\n",
    "mask = ( df[\"trial_type\"].isin(trial_types)) & \\\n",
    "            ( df[\"track_segment_id\"].isin(track_segment_ids)) & \\\n",
    "                ( df[\"zone\"].isin(zones)) & \\\n",
    "                    (df[\"trial_progress_distance\"]>0) & (df[\"trial_progress_distance\"]<0.5) # explicit progress bins - for visual examination.\n",
    "\n",
    "\n",
    "n_bins = 6\n",
    "tuner_bins = np.linspace(0, 120, n_bins + 1)\n",
    "tuner_bin_centers = (tuner_bins[:-1] + tuner_bins[1:]) / 2\n",
    "\n",
    "\n",
    "# bootstrap across trials\n",
    "speed_tuning, speed_centers, speed_lower, speed_upper, slope_boot, curvature_boot = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    \"speed\",\n",
    "    spikes_list,\n",
    "    n_bins=6,\n",
    "    mask=mask,\n",
    "    trial_column=\"trial_number\",\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    "    # tuner_bins= tuner_bins,\n",
    "    binning = \"sliding\", # ignores n_bins when \"sliding\"\n",
    "    window_width = 20,\n",
    "    window_step = 2,\n",
    "    tuner_min = 0,\n",
    "    tuner_max = 120,\n",
    "    peak_normalize = True\n",
    ")\n",
    "\n",
    "\n",
    "shape_by_unit, stats_by_unit = classify_tuning_shapes_from_bootstraps(\n",
    "    slope_boot,\n",
    "    curvature_boot,\n",
    "    ci=0.95,\n",
    "    min_valid_boot=200,   \n",
    ")\n",
    "unit_shapes = pd.Series(shape_by_unit)\n",
    "speed_bell_unit_ids = unit_shapes[unit_shapes==\"bell\"].index.tolist()\n",
    "speed_increasing_unit_ids = unit_shapes[unit_shapes==\"increasing\"].index.tolist()\n",
    "speed_decreasing_unit_ids = unit_shapes[unit_shapes==\"decreasing\"].index.tolist()\n",
    "speed_u_unit_ids = unit_shapes[unit_shapes==\"U\"].index.tolist()\n",
    "speed_complex_unit_ids = unit_shapes[unit_shapes==\"flat/complex\"].index.tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tuning_grid_bootstrap(\n",
    "    speed_tuning, speed_lower, speed_upper, speed_centers,\n",
    "    column=\"speed\", \n",
    "    n_units=30, \n",
    "    indices = None,\n",
    "    label = \"all eps\",\n",
    "    peak_normalize = True, \n",
    "    s = 2,\n",
    "    linewidth = 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11c4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid tuning bins/windows: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labuser/miniforge3/envs/spyglass/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n"
     ]
    }
   ],
   "source": [
    "# BALANCING FOR DATA - cpmoute tuning across progress segments!\n",
    "progress_edges = np.array([0.0, 0.5, 1.0])\n",
    "progress_labels = [\"early\", \"late\"]\n",
    "\n",
    "df = trialized_position.sort_index().copy()\n",
    "\n",
    "segment_results, valid_speed_bins_mask, pairwise_metrics = compare_speed_tuning_across_progress_segments(\n",
    "    trialized_position_df=df,\n",
    "    spikes_list=spikes_list,\n",
    "    base_mask=base_mask,\n",
    "    progress_col=\"trial_progress_distance\",\n",
    "    progress_edges=progress_edges,\n",
    "    progress_labels=progress_labels,\n",
    "    speed_col=\"speed\",\n",
    "    trial_col=\"trial_number\",\n",
    "\n",
    "    # keep passing this if you already have it:\n",
    "    # for sliding itâ€™s used for stratification/downsampling (not for the tuning windows)\n",
    "    tuner_bins=tuner_bins,\n",
    "\n",
    "    # sliding-window tuning params (these define the returned x-axis / centers)\n",
    "    binning=\"sliding\",\n",
    "    window_width=30,\n",
    "    window_step=3,\n",
    "    tuner_min=0,\n",
    "    tuner_max=120,\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    "    min_speedbin_occupancy_s=1.0,\n",
    "    stratify_equalize_speedbin_occupancy=True,\n",
    ")\n",
    "\n",
    "print(\"Valid tuning bins/windows:\", np.where(valid_speed_bins_mask)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot across progress levels!\n",
    "for lab in progress_labels:\n",
    "    res = segment_results[lab]\n",
    "    plot_tuning_grid_bootstrap(\n",
    "        res[\"tuning\"], res[\"lo\"], res[\"hi\"], res[\"centers\"],\n",
    "        column=\"speed\", n_units=40, label=f\"{lab} \", peak_normalize = True,\n",
    "        s = 3, linewidth = 2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59123c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corr              0.566060526\n",
       "nrmse             0.474197986\n",
       "peak_shift_bins   1.000000000\n",
       "mean_rate_diff    0.517335128\n",
       "dtype: float64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot median metrics\n",
    "vals = list(pairwise_metrics[('early', 'late')].values())  \n",
    "df = pd.DataFrame(vals)\n",
    "\n",
    "medians = df.median(numeric_only=True)  \n",
    "medians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991cb520",
   "metadata": {},
   "source": [
    "##### Balance progress weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9167bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT progress vs speed along one axis\n",
    "\n",
    "trial_types = [ \"inbound\", \"outbound\"]\n",
    "# trial_types = [\"NA\"]\n",
    "\n",
    "zones = [\"run\"]\n",
    "mask = (\n",
    "    (trialized_position[\"zone\"].isin(zones)) &\n",
    "    (trialized_position[\"trial_type\"].isin(trial_types))\n",
    ")\n",
    "n_bins = 5\n",
    "fig, ax = plt.subplots(figsize = (20, 7.5), layout = \"tight\")\n",
    "plot_speed_vs_progress(trialized_position, mask, n_bins, \"trial_progress\", window_size=0.15, step_size=0.02, recompute_progress=True, ax = ax)\n",
    "# plot_speed_vs_progress(trialized_position, mask, n_bins, \"trial_progress_distance\", window_size=0.15, step_size=0.02, recompute_progress=True, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = trialized_position.copy()\n",
    "# speed_tuning, speed_centers, lo, hi, slope_boot, curv_boot = compute_speed_tuning_progress_balanced_bootstrap_trials(\n",
    "#     df,\n",
    "#     spikes_list=spikes_list,\n",
    "#     mask=mask,\n",
    "#     speed_col=\"speed\",\n",
    "#     progress_col=\"trial_progress_distance\",\n",
    "#     progress_bins=np.linspace(0, 1, 6),  # still discrete along progress\n",
    "#     speed_binning=\"sliding\",\n",
    "#     speed_window_width=20,\n",
    "#     speed_window_step=2,\n",
    "#     speed_min=0.0,\n",
    "#     speed_max=120,\n",
    "#     n_boot=500,\n",
    "#     random_state=0,\n",
    "#     peak_normalize = True,\n",
    "#     progress_weights=\"uniform\"\n",
    "# )\n",
    "\n",
    "# plot_tuning_grid_bootstrap(\n",
    "#     speed_tuning, lo, hi, speed_centers,\n",
    "#     column=\"speed\",\n",
    "#     n_units=60,\n",
    "#     s=1,\n",
    "#     color=\"tab:blue\", \n",
    "#     peak_normalize = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9854581",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (6,) and (51,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 35\u001b[0m\n\u001b[1;32m     30\u001b[0m (speed_tuning_dist, _, lo_dist, hi_dist, slope_dist, curv_dist) \u001b[38;5;241m=\u001b[39m bal_dist\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#  speed only\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mplot_tuning_grid_bootstrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeed_tuning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed_lower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed_upper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed_centers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch 8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpeak_normalize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# with time\u001b[39;00m\n\u001b[1;32m     46\u001b[0m plot_tuning_grid_bootstrap(\n\u001b[1;32m     47\u001b[0m     speed_tuning_time, lo_time, hi_time, speed_centers,\n\u001b[1;32m     48\u001b[0m     column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \n\u001b[1;32m     54\u001b[0m )\n",
      "File \u001b[0;32m/media/labuser/NA_1_2025/spyglass/wilbur/tuning_analysis/spike_analysis.py:3656\u001b[0m, in \u001b[0;36mplot_tuning_grid_bootstrap\u001b[0;34m(tuner_tuning, lower_ci, upper_ci, tuner_bin_centers, column, n_units, label, indices, s, color, ci, stderr, show_stderr, peak_normalize, ylims, linewidth)\u001b[0m\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m color \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3654\u001b[0m     plot_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m color\n\u001b[0;32m-> 3656\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtuner_bin_centers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplot_kwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   3657\u001b[0m fill_color \u001b[38;5;241m=\u001b[39m color \u001b[38;5;28;01mif\u001b[39;00m color \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m line\u001b[38;5;241m.\u001b[39mget_color()\n\u001b[1;32m   3659\u001b[0m \u001b[38;5;66;03m# Always show the bootstrap percentile CI band\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/spyglass/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/miniforge3/envs/spyglass/lib/python3.10/site-packages/matplotlib/axes/_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/spyglass/lib/python3.10/site-packages/matplotlib/axes/_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    491\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (6,) and (51,)"
     ]
    }
   ],
   "source": [
    "# mask = (trialized_position[\"zone\"] == \"run\") & (trialized_position[\"trial_type\"].isin([\"inbound\", \"outbound\"]))\n",
    "# spikes_list = mpfc_spikes.copy()\n",
    "# # Balanced wrt time-progress\n",
    "# bal_time = compute_speed_tuning_progress_balanced_bootstrap_trials(\n",
    "#     trialized_position,\n",
    "#     speed_col=\"speed\",\n",
    "#     progress_col=\"trial_progress_distance\",\n",
    "#     spikes_list=spikes_list,\n",
    "#     n_speed_bins=6,\n",
    "#     n_progress_bins=4,\n",
    "#     mask=mask,\n",
    "#     n_boot=500,\n",
    "#     progress_weights=\"uniform\",\n",
    "#     binning = \"sliding\"\n",
    "# )\n",
    "\n",
    "# # Balanced wrt distance-progress\n",
    "# bal_dist = compute_speed_tuning_progress_balanced_bootstrap_trials(\n",
    "#     trialized_position,\n",
    "#     speed_col=\"speed\",\n",
    "#     progress_col=\"trial_progress_distance\",\n",
    "#     spikes_list=spikes_list,\n",
    "#     n_speed_bins=6,\n",
    "#     n_progress_bins=4,\n",
    "#     mask=mask,\n",
    "#     n_boot=500,\n",
    "#     progress_weights=\"uniform\"n_bin\n",
    "# )\n",
    "\n",
    "# (speed_tuning_time, speed_centers, lo_time, hi_time, slope_time, curv_time) = bal_time\n",
    "# (speed_tuning_dist, _, lo_dist, hi_dist, slope_dist, curv_dist) = bal_dist\n",
    "\n",
    "\n",
    "\n",
    "# #  speed only\n",
    "# plot_tuning_grid_bootstrap(\n",
    "#     speed_tuning, speed_lower, speed_upper, speed_centers,\n",
    "#     column=\"speed\", \n",
    "#     n_units=30, \n",
    "#     indices = None,\n",
    "#     label = \"epoch 8\",\n",
    "#     peak_normalize = True\n",
    "# )\n",
    "\n",
    "\n",
    "# # with time\n",
    "# plot_tuning_grid_bootstrap(\n",
    "#     speed_tuning_time, lo_time, hi_time, speed_centers,\n",
    "#     column=\"speed\", \n",
    "#     n_units=30, \n",
    "#     indices = None,\n",
    "#     label = \"epoch 8 time weighted\",\n",
    "#     peak_normalize = True\n",
    "    \n",
    "# )\n",
    "\n",
    "# # with distance\n",
    "# # plot_tuning_grid_bootstrap(\n",
    "# #     speed_tuning_dist, lo_dist, hi_dist, speed_centers,\n",
    "# #     column=\"speed\", \n",
    "# #     n_units=30, \n",
    "# #     indices = None,\n",
    "# #     label = \"epoch 8 distance weighted\"\n",
    "# # )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ccebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Across-stable units: 180\n",
      "Samples in mask_common: 63566\n",
      "Trials in mask_common: 199\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 1 â€” Select across-stable units + params + progress (recompute progress inside mask so that its only defined in the run period)\n",
    "# =========================\n",
    "\n",
    "# Units to use (across-epoch stable only)\n",
    "# NOTE: `across_stable_units` is an index array; safest is to use the dict keys directly.\n",
    "across_stable_unit_ids = sorted([u for u, s in across_epoch_status.items() if s == \"stable\"])\n",
    "print(\"Across-stable units:\", len(across_stable_unit_ids))\n",
    "\n",
    "if len(across_stable_unit_ids) == 0:\n",
    "    raise ValueError(\"No across-stable units found in across_epoch_status.\")\n",
    "\n",
    "df = trialized_position.copy().sort_index()\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "# ---- analysis mask (match your typical tuning mask) ----\n",
    "base_mask = (\n",
    "    (df[\"zone\"] == \"run\")\n",
    "    & (df[\"trial_type\"].isin([\"inbound\", \"outbound\"]))\n",
    ")\n",
    "\n",
    "# ---- speed column; normalized or not ----\n",
    "speed_col = \"speed\"          \n",
    "\n",
    "# ---- set progress column : in time or in distance? ----\n",
    "progress_col_raw = \"trial_progress\" \n",
    "trial_col = \"trial_number\"\n",
    "\n",
    "# ---- continuous sliding-window binning for speed tuning curves ----\n",
    "window_width = 20 #cm/s\n",
    "window_step = 2 #cm/s\n",
    "tuner_min = 0 #cm/s\n",
    "tuner_max = 120 #cm/s\n",
    "\n",
    "# ---- progress balancing settings ----\n",
    "n_progress_bins = 5\n",
    "progress_weights = \"uniform\"       # \"uniform\" or \"global\"\n",
    "min_occupancy_cell_s = 0.25 #minimum time occupancy (seconds) for a given speed and a given cell\n",
    "min_occupancy_speed_s = 1.0 #minimum time occupancy (seconds) for a given speed bin\n",
    "\n",
    "# ---- metric settings ----\n",
    "min_units_ok_bins = 3\n",
    "\n",
    "# Recompute progress within each trial AFTER masking (matches plot_speed_vs_progress(..., recompute_progress=True))\n",
    "progress_col = \"_progress_norm_for_balance\"\n",
    "df[progress_col] = np.nan\n",
    "\n",
    "sub = df.loc[base_mask, [trial_col, progress_col_raw]].copy()\n",
    "sub = sub.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "per_trial_min = sub.groupby(trial_col)[progress_col_raw].transform(\"min\")\n",
    "per_trial_max = sub.groupby(trial_col)[progress_col_raw].transform(\"max\")\n",
    "denom = per_trial_max - per_trial_min\n",
    "\n",
    "ok = np.isfinite(denom) & (denom > 0)\n",
    "sub = sub.loc[ok].copy()\n",
    "sub[progress_col] = (sub[progress_col_raw] - per_trial_min.loc[ok]) / denom.loc[ok]\n",
    "sub = sub[(sub[progress_col] >= 0) & (sub[progress_col] <= 1)]\n",
    "\n",
    "df.loc[sub.index, progress_col] = sub[progress_col].to_numpy()\n",
    "\n",
    "# Common mask used for BOTH tunings (apples-to-apples)\n",
    "mask_common = (\n",
    "    base_mask\n",
    "    & df[trial_col].notna()\n",
    "    & np.isfinite(df[speed_col].to_numpy())\n",
    "    & np.isfinite(df[progress_col].to_numpy())\n",
    ")\n",
    "\n",
    "print(\"Samples in mask_common:\", int(np.sum(mask_common)))\n",
    "print(\"Trials in mask_common:\", int(df.loc[mask_common, trial_col].nunique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc06df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced units: 180 n_centers: 51\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 2 â€” Unbalanced tuning (BOOTSTRAPPED; sliding windows)\n",
    "# =========================\n",
    "\n",
    "(\n",
    "    tuning_unbal,\n",
    "    centers_unbal,\n",
    "    lo_unbal,\n",
    "    hi_unbal,\n",
    "    slope_boot_unbal,\n",
    "    curv_boot_unbal,\n",
    ") = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    column=speed_col,\n",
    "    spikes_list=spikes_list,\n",
    "    n_bins=8,  # not used for sliding centers; kept for API consistency\n",
    "    mask=mask_common,\n",
    "    trial_column=trial_col,\n",
    "    n_boot=500,\n",
    "    ci=0.95,\n",
    "    random_state=0,\n",
    "    tuner_bins=None,\n",
    "    binning=\"sliding\",\n",
    "    window_width=window_width,\n",
    "    window_step=window_step,\n",
    "    tuner_min=tuner_min,\n",
    "    tuner_max=tuner_max,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Restrict dicts to across-stable unit IDs\n",
    "tuning_unbal = {u: tuning_unbal[u] for u in across_stable_unit_ids if u in tuning_unbal}\n",
    "lo_unbal     = {u: lo_unbal[u]     for u in across_stable_unit_ids if u in lo_unbal}\n",
    "hi_unbal     = {u: hi_unbal[u]     for u in across_stable_unit_ids if u in hi_unbal}\n",
    "\n",
    "# slope_boot_unbal = {u: slope_boot_unbal[u] for u in across_stable_unit_ids if u in slope_boot_unbal}\n",
    "# curv_boot_unbal  = {u: curv_boot_unbal[u]  for u in across_stable_unit_ids if u in curv_boot_unbal}\n",
    "\n",
    "print(\"Unbalanced units:\", len(tuning_unbal), \"n_centers:\", len(centers_unbal))\n",
    "\n",
    "\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_unbal,\n",
    "    lo_unbal,\n",
    "    hi_unbal,\n",
    "    centers_unbal,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"UNBALANCED (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580daab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced units: 180 n_centers: 51\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 3 â€” Progress-balanced tuning (sliding window binning)\n",
    "# =========================\n",
    "\n",
    "(\n",
    "    tuning_bal,\n",
    "    centers_bal,\n",
    "    lo_bal,\n",
    "    hi_bal,\n",
    "    slope_boot_bal,\n",
    "    curv_boot_bal,\n",
    ") = compute_speed_tuning_progress_balanced_bootstrap_trials(\n",
    "    df,\n",
    "    speed_col=speed_col,\n",
    "    progress_col=progress_col,\n",
    "    spikes_list=spikes_list,\n",
    "    n_speed_bins=8,                 # ignored for sliding; API compat\n",
    "    n_progress_bins=n_progress_bins,\n",
    "    mask=mask_common,\n",
    "    trial_column=trial_col,\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    "    progress_weights=progress_weights,\n",
    "    progress_bins=None,\n",
    "    min_occupancy_cell_s=min_occupancy_cell_s,\n",
    "    min_occupancy_speed_s=min_occupancy_speed_s,\n",
    "    speed_binning=\"sliding\",\n",
    "    speed_window_width=window_width,\n",
    "    speed_window_step=window_step,\n",
    "    speed_min=tuner_min,\n",
    "    speed_max=tuner_max,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Restrict dicts to across-stable units\n",
    "tuning_bal = {u: tuning_bal[u] for u in across_stable_unit_ids if u in tuning_bal}\n",
    "lo_bal = {u: lo_bal[u] for u in tuning_bal.keys() if u in lo_bal}\n",
    "hi_bal = {u: hi_bal[u] for u in tuning_bal.keys() if u in hi_bal}\n",
    "\n",
    "print(\"Balanced units:\", len(tuning_bal), \"n_centers:\", len(centers_bal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d817895f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units available for plotting/metrics: 180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>peak_shift_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.881521164</td>\n",
       "      <td>0.133676185</td>\n",
       "      <td>0.040000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.969673781</td>\n",
       "      <td>0.106119397</td>\n",
       "      <td>0.020000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.833617127</td>\n",
       "      <td>0.156788137</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.950536664</td>\n",
       "      <td>0.133743223</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.668368827</td>\n",
       "      <td>0.224883558</td>\n",
       "      <td>0.060000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         corr       nrmse  peak_shift_x\n",
       "0 0.881521164 0.133676185   0.040000000\n",
       "2 0.969673781 0.106119397   0.020000000\n",
       "3 0.833617127 0.156788137   0.000000000\n",
       "4 0.950536664 0.133743223   0.000000000\n",
       "5 0.668368827 0.224883558   0.060000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>peak_shift_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000000</td>\n",
       "      <td>180.000000000</td>\n",
       "      <td>180.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.722469378</td>\n",
       "      <td>0.280225346</td>\n",
       "      <td>0.182111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.312901809</td>\n",
       "      <td>0.237002670</td>\n",
       "      <td>0.273095209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.386724781</td>\n",
       "      <td>0.009805332</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.651276554</td>\n",
       "      <td>0.123859924</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.832810933</td>\n",
       "      <td>0.206014901</td>\n",
       "      <td>0.020000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.935006989</td>\n",
       "      <td>0.362739329</td>\n",
       "      <td>0.245000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999283180</td>\n",
       "      <td>1.166825201</td>\n",
       "      <td>0.800000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               corr         nrmse  peak_shift_x\n",
       "count 180.000000000 180.000000000 180.000000000\n",
       "mean    0.722469378   0.280225346   0.182111111\n",
       "std     0.312901809   0.237002670   0.273095209\n",
       "min    -0.386724781   0.009805332   0.000000000\n",
       "25%     0.651276554   0.123859924   0.000000000\n",
       "50%     0.832810933   0.206014901   0.020000000\n",
       "75%     0.935006989   0.362739329   0.245000000\n",
       "max     0.999283180   1.166825201   0.800000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median corr: 0.8328109327329712\n",
      "Median nrmse: 0.2060149007577469\n",
      "Median peak_shift_x: 0.020000000000000018\n"
     ]
    }
   ],
   "source": [
    "# compare using metrics and plot\n",
    "\n",
    "def _interp_curve_to_centers(curve, from_centers, to_centers):\n",
    "    curve = np.asarray(curve, float)\n",
    "    from_centers = np.asarray(from_centers, float)\n",
    "    to_centers = np.asarray(to_centers, float)\n",
    "\n",
    "    finite = np.isfinite(curve) & np.isfinite(from_centers)\n",
    "    if finite.sum() < 2:\n",
    "        return np.full_like(to_centers, np.nan, dtype=float)\n",
    "\n",
    "    x = from_centers[finite]\n",
    "    y = curve[finite]\n",
    "    order = np.argsort(x)\n",
    "    x = x[order]\n",
    "    y = y[order]\n",
    "\n",
    "    out = np.interp(to_centers, x, y)\n",
    "    out[(to_centers < x.min()) | (to_centers > x.max())] = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "# Use UNBALANCED centers as the common x-axis\n",
    "centers = np.asarray(centers_unbal, float)\n",
    "\n",
    "# Align balanced tuning + CI onto unbalanced centers if needed\n",
    "if not np.allclose(centers_unbal, centers_bal, equal_nan=True):\n",
    "    print(\"Center mismatch: interpolating balanced tuning + CI onto unbalanced centers.\")\n",
    "    tuning_bal_aligned = {u: _interp_curve_to_centers(tuning_bal[u], centers_bal, centers) for u in tuning_bal.keys()}\n",
    "    lo_bal_aligned = {u: _interp_curve_to_centers(lo_bal[u], centers_bal, centers) for u in lo_bal.keys()}\n",
    "    hi_bal_aligned = {u: _interp_curve_to_centers(hi_bal[u], centers_bal, centers) for u in hi_bal.keys()}\n",
    "else:\n",
    "    tuning_bal_aligned = tuning_bal\n",
    "    lo_bal_aligned = lo_bal\n",
    "    hi_bal_aligned = hi_bal\n",
    "\n",
    "# Units available in BOTH methods (unbalanced + balanced)\n",
    "units_compared = sorted(set(tuning_unbal.keys()) & set(tuning_bal_aligned.keys()))\n",
    "print(\"Units available for plotting/metrics:\", len(units_compared))\n",
    "\n",
    "# Restrict to across-stable unit IDs if present (recommended)\n",
    "plot_units = units_compared\n",
    "if \"across_stable_unit_ids\" in globals():\n",
    "    stable_set = set(across_stable_unit_ids)\n",
    "    plot_units = [u for u in plot_units if u in stable_set]\n",
    "\n",
    "if len(plot_units) == 0:\n",
    "    raise ValueError(\"No units to plot after restricting to across_stable_unit_ids âˆ© units_compared.\")\n",
    "\n",
    "# Subset dicts so plotting funcs only see the units you want\n",
    "tuning_unbal_plot = {u: tuning_unbal[u] for u in plot_units}\n",
    "lo_unbal_plot     = {u: lo_unbal[u]     for u in plot_units}\n",
    "hi_unbal_plot     = {u: hi_unbal[u]     for u in plot_units}\n",
    "\n",
    "tuning_bal_plot = {u: tuning_bal_aligned[u] for u in plot_units}\n",
    "lo_bal_plot     = {u: lo_bal_aligned[u]     for u in plot_units}\n",
    "hi_bal_plot     = {u: hi_bal_aligned[u]     for u in plot_units}\n",
    "\n",
    "# -------------------------\n",
    "# Plot: unbalanced vs balanced (both bootstrapped)\n",
    "# -------------------------\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_unbal_plot,\n",
    "    lo_unbal_plot,\n",
    "    hi_unbal_plot,\n",
    "    centers,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"UNBALANCED (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_bal_plot,\n",
    "    lo_bal_plot,\n",
    "    hi_bal_plot,\n",
    "    centers,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"PROGRESS-BALANCED (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Metrics:\n",
    "# -------------------------\n",
    "metrics = {}\n",
    "for u in plot_units:\n",
    "    a = np.asarray(tuning_unbal_plot[u], float)\n",
    "    b = np.asarray(tuning_bal_plot[u], float)\n",
    "    metrics[u] = dict(\n",
    "        corr=curve_corr(a, b, min_bins=min_units_ok_bins),\n",
    "        nrmse=nrmse(a, b, min_bins=min_units_ok_bins),\n",
    "        peak_bin_shift=peak_bin_shift(a, b, centers, min_bins=min_units_ok_bins),\n",
    "    )\n",
    "\n",
    "metrics_df_progress = pd.DataFrame.from_dict(metrics, orient=\"index\")\n",
    "display(metrics_df_progress.head())\n",
    "display(metrics_df_progress.describe())\n",
    "\n",
    "print(\"Median corr:\", float(metrics_df_progress[\"corr\"].median(skipna=True)))\n",
    "print(\"Median nrmse:\", float(metrics_df_progress[\"nrmse\"].median(skipna=True)))\n",
    "print(\"Median peak_bin_shift:\", float(metrics_df_progress[\"peak_bin_shift\"].median(skipna=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d5dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT single unit, balanced vs unbalanced\n",
    "\n",
    "unit_to_plot = 3  # set to an int unit id, or leave None to auto-pick\n",
    "\n",
    "# Choose available units\n",
    "if \"across_stable_unit_ids\" in globals():\n",
    "    candidate_units = [u for u in across_stable_unit_ids if (u in tuning_unbal and u in tuning_bal_aligned)]\n",
    "else:\n",
    "    candidate_units = [u for u in units_compared if (u in tuning_unbal and u in tuning_bal_aligned)]\n",
    "\n",
    "if len(candidate_units) == 0:\n",
    "    raise ValueError(\"No units available for overlay (check tuning_unbal/tuning_bal_aligned and stable-unit filtering).\")\n",
    "\n",
    "if unit_to_plot is None:\n",
    "    unit_to_plot = candidate_units[0]\n",
    "\n",
    "a = np.asarray(tuning_unbal[unit_to_plot], float)\n",
    "b = np.asarray(tuning_bal_aligned[unit_to_plot], float)\n",
    "x = np.asarray(centers, float)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.5, 4.5), layout=\"tight\")\n",
    "\n",
    "ax.plot(x, a, \"-o\", linewidth=2.0, markersize=4, label=\"unbalanced (sliding)\")\n",
    "ax.plot(x, b, \"-o\", linewidth=2.0, markersize=4, label=\"progress-balanced (sliding)\")\n",
    "\n",
    "# Optional: show balanced CI band if you have it aligned\n",
    "if \"lo_bal_aligned\" in globals() and \"hi_bal_aligned\" in globals():\n",
    "    if unit_to_plot in lo_bal_aligned and unit_to_plot in hi_bal_aligned:\n",
    "        lo = np.asarray(lo_bal_aligned[unit_to_plot], float)\n",
    "        hi = np.asarray(hi_bal_aligned[unit_to_plot], float)\n",
    "        ax.fill_between(x, lo, hi, alpha=0.25, label=\"balanced CI\")\n",
    "\n",
    "# Your 3 metrics, printed on-plot\n",
    "cc = curve_corr(a, b, min_bins=min_units_ok_bins)\n",
    "ee = nrmse(a, b, min_bins=min_units_ok_bins)\n",
    "pp = peak_bin_shift(a, b, x, min_bins=min_units_ok_bins)\n",
    "\n",
    "ax.set_title(f\"Unit {unit_to_plot} | corr={cc:.3f} | nrmse={ee:.3f} | peak_bin_shift={pp:.3f}\")\n",
    "ax.set_xlabel(speed_col)\n",
    "ax.set_ylabel(\"Peak-normalized firing rate\")\n",
    "ax.set_ylim([-0.05, 1.05])\n",
    "ax.grid(True, alpha=0.25)\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609e9be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts: {'stable': 109, 'unstable': 71, 'insufficient': 0}\n",
      "Thresholds: {'corr_thresh': 0.3, 'nrmse_thresh': 0.5, 'peak_shift_thresh': 0.1}\n",
      "N evaluated (across_stable_unit_ids): 180\n"
     ]
    }
   ],
   "source": [
    "# BARPLOT; stable, unstable, and `insufficient data`\n",
    "if \"across_stable_unit_ids\" not in globals():\n",
    "    raise ValueError(\"Expected `across_stable_unit_ids` to exist.\")\n",
    "\n",
    "# Prefer a dedicated snapshot if you made one\n",
    "if \"metrics_df_progress\" in globals():\n",
    "    metrics_df_use = metrics_df_progress\n",
    "elif \"metrics_df\" in globals():\n",
    "    metrics_df_use = metrics_df\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Could not find `metrics_df_progress` or `metrics_df`.\\n\"\n",
    "        \"Run this right after the progress-balancing comparison cell, or save:\\n\"\n",
    "        \"  metrics_df_progress = metrics_df.copy()\"\n",
    "    )\n",
    "\n",
    "need_cols = {\"corr\", \"nrmse\", \"peak_bin_shift\"}\n",
    "if not need_cols.issubset(set(metrics_df_use.columns)):\n",
    "    raise ValueError(f\"Progress metrics table missing columns {need_cols}; got {list(metrics_df_use.columns)}\")\n",
    "\n",
    "# ---- thresholds (same style as your inbound/outbound barplot) ----\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh = 0.10  # in speed_norm units if your centers are speed_norm\n",
    "\n",
    "labels_progress = {}\n",
    "for u in across_stable_unit_ids:\n",
    "    if u not in metrics_df_use.index:\n",
    "        labels_progress[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    c = metrics_df_use.loc[u, \"corr\"]\n",
    "    e = metrics_df_use.loc[u, \"nrmse\"]\n",
    "    p = metrics_df_use.loc[u, \"peak_bin_shift\"]\n",
    "\n",
    "    if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "        labels_progress[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    # Here \"stable\" means: progress balancing does NOT change the tuning curve much\n",
    "    is_stable = (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh)\n",
    "    labels_progress[u] = \"stable\" if is_stable else \"unstable\"\n",
    "\n",
    "cats = [\"stable\", \"unstable\", \"insufficient\"]\n",
    "counts = {c: list(labels_progress.values()).count(c) for c in cats}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.2 * 2.2, 3.2 * 2.2), layout=\"tight\")\n",
    "\n",
    "# Reuse your existing `colors` list if you have it; otherwise default palette\n",
    "if \"colors\" in globals() and isinstance(colors, (list, tuple)) and len(colors) >= 3:\n",
    "    bar_colors = [colors[0], colors[1], colors[2]]\n",
    "else:\n",
    "    bar_colors = [\"tab:green\", \"tab:orange\", \"tab:gray\"]\n",
    "\n",
    "ax.bar(cats, [counts[c] for c in cats], color=bar_colors, alpha=0.9)\n",
    "ax.set_ylabel(\"Number of units\")\n",
    "ax.set_title(\"Progress balancing robustness (across-stable units)\")\n",
    "\n",
    "# annotate counts\n",
    "for i, c in enumerate(cats):\n",
    "    ax.text(i, counts[c] + 0.5, str(counts[c]), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Counts:\", {c: counts[c] for c in cats})\n",
    "print(\"Thresholds:\", dict(corr_thresh=corr_thresh, nrmse_thresh=nrmse_thresh, peak_shift_thresh=peak_shift_thresh))\n",
    "print(\"N evaluated (across_stable_unit_ids):\", len(across_stable_unit_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da847a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable units across unbalanced vs balanced: 145\n"
     ]
    }
   ],
   "source": [
    "# Plot ROBUST units - tuning grid\n",
    "\n",
    "if \"metrics_df_progress\" in globals():\n",
    "    metrics_df_use = metrics_df_progress\n",
    "elif \"metrics_df\" in globals():\n",
    "    metrics_df_use = metrics_df\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Could not find progress metrics (`metrics_df_progress` or `metrics_df`).\\n\"\n",
    "        \"If you overwrote metrics_df later, rerun the progress comparison cell and do:\\n\"\n",
    "        \"  metrics_df_progress = metrics_df.copy()\"\n",
    "    )\n",
    "\n",
    "need_cols = {\"corr\", \"nrmse\", \"peak_bin_shift\"}\n",
    "if not need_cols.issubset(set(metrics_df_use.columns)):\n",
    "    raise ValueError(f\"Progress metrics table missing columns {need_cols}; got {list(metrics_df_use.columns)}\")\n",
    "\n",
    "# thresholds\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh = 10  # in speed_norm units\n",
    "\n",
    "# make sure we have aligned balanced dicts; if not, fall back to raw balanced dicts\n",
    "# (assumes centers_unbal is the shared axis)\n",
    "centers = np.asarray(centers_unbal, float)\n",
    "\n",
    "# if \"tuning_bal_aligned\" not in globals():\n",
    "#     if not (\"tuning_bal\" in globals() and \"centers_bal\" in globals()):\n",
    "#         raise ValueError(\"Missing `tuning_bal_aligned` (or `tuning_bal` + `centers_bal`). Run your alignment cell first.\")\n",
    "#     tuning_bal_aligned = tuning_bal\n",
    "#     lo_bal_aligned = lo_bal\n",
    "#     hi_bal_aligned = hi_bal\n",
    "\n",
    "tuning_bal_aligned = tuning_bal\n",
    "lo_bal_aligned = lo_bal\n",
    "hi_bal_aligned = hi_bal\n",
    "\n",
    "\n",
    "# optional restriction: if you already restricted tunings to across_stable_unit_ids earlier,\n",
    "# this wonâ€™t change anything. If not, it keeps consistency with your workflow.\n",
    "unit_pool = list(metrics_df_use.index)\n",
    "if \"across_stable_unit_ids\" in globals():\n",
    "    unit_pool = [u for u in unit_pool if u in set(across_stable_unit_ids)]\n",
    "\n",
    "stable_units_progress = []\n",
    "for u in unit_pool:\n",
    "    if u not in metrics_df_use.index:\n",
    "        continue\n",
    "    c = metrics_df_use.loc[u, \"corr\"]\n",
    "    e = metrics_df_use.loc[u, \"nrmse\"]\n",
    "    p = metrics_df_use.loc[u, \"peak_bin_shift\"]\n",
    "\n",
    "    if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "        continue\n",
    "\n",
    "    is_stable = (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh)\n",
    "    # is_stable = (c <= corr_thresh) or (e >= nrmse_thresh) or (p >= peak_shift_thresh)\n",
    "\n",
    "    if is_stable:\n",
    "        stable_units_progress.append(u)\n",
    "\n",
    "# also ensure unit exists in BOTH tuning dicts + CIs\n",
    "stable_units_progress = [\n",
    "    u for u in stable_units_progress\n",
    "    if (u in tuning_unbal) and (u in lo_unbal) and (u in hi_unbal)\n",
    "    and (u in tuning_bal_aligned) and (u in lo_bal_aligned) and (u in hi_bal_aligned)\n",
    "]\n",
    "\n",
    "print(\"Stable units across unbalanced vs balanced:\", len(stable_units_progress))\n",
    "if len(stable_units_progress) == 0:\n",
    "    raise ValueError(\"No progress-stable units found under these thresholds (or missing tuning/CI entries).\")\n",
    "\n",
    "# subset dicts so plot_tuning_grid_bootstrap only sees the units you want\n",
    "tun_unbal_stable = {u: tuning_unbal[u] for u in stable_units_progress}\n",
    "lo_unbal_stable  = {u: lo_unbal[u]     for u in stable_units_progress}\n",
    "hi_unbal_stable  = {u: hi_unbal[u]     for u in stable_units_progress}\n",
    "\n",
    "tun_bal_stable = {u: tuning_bal_aligned[u] for u in stable_units_progress}\n",
    "lo_bal_stable  = {u: lo_bal_aligned[u]     for u in stable_units_progress}\n",
    "hi_bal_stable  = {u: hi_bal_aligned[u]     for u in stable_units_progress}\n",
    "\n",
    "# column label (keep consistent with your analysis)\n",
    "col_label = speed_col if \"speed_col\" in globals() else \"speed_norm\"\n",
    "\n",
    "# Figure 1: UNBALANCED\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tun_unbal_stable,\n",
    "    lo_unbal_stable,\n",
    "    hi_unbal_stable,\n",
    "    centers,\n",
    "    column=col_label,\n",
    "    n_units=30,\n",
    "    label=\"UNBALANCED (progress-stable units; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Figure 2: PROGRESS-BALANCED\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tun_bal_stable,\n",
    "    lo_bal_stable,\n",
    "    hi_bal_stable,\n",
    "    centers,\n",
    "    column=col_label,\n",
    "    n_units=30,\n",
    "    label=\"PROGRESS-BALANCED (progress-stable units; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68166b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant early/late units (q_max<0.05): 0\n"
     ]
    }
   ],
   "source": [
    "mask_early = segment_results[\"early\"][\"mask\"]\n",
    "mask_late  = segment_results[\"late\"][\"mask\"]\n",
    "\n",
    "df = trialized_position.copy().sort_index()\n",
    "\n",
    "res_earlylate = paired_permutation_test_tuning_difference_masks(\n",
    "    df,\n",
    "    spikes_list=spikes_list,\n",
    "    base_mask=base_mask,          # use the same base_mask you used to build segment masks\n",
    "    column=\"speed\",\n",
    "    trial_column=\"trial_number\",\n",
    "    mask_a=mask_early,\n",
    "    mask_b=mask_late,\n",
    "    label_a=\"early\",\n",
    "    label_b=\"late\",\n",
    "    binning=\"sliding\",\n",
    "    window_width=0.20,\n",
    "    window_step=0.02,\n",
    "    tuner_min=0.0,\n",
    "    tuner_max=1.0,\n",
    "    n_perm=2000,\n",
    "    random_state=0,\n",
    "    units=across_stable_unit_ids,  # optional\n",
    ")\n",
    "\n",
    "sig_units_earlylate = res_earlylate[\"q_max\"][res_earlylate[\"q_max\"] < 0.05].index.to_numpy()\n",
    "print(\"Significant early/late units (q_max<0.05):\", len(sig_units_earlylate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de37ceb",
   "metadata": {},
   "source": [
    "#### Outbound vs Inbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9e65d390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials inbound: 107\n",
      "Trials outbound: 92\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 1 â€” Setup masks (INBOUND vs OUTBOUND) using across_stable_unit_ids only\n",
    "# =========================\n",
    "\n",
    "if \"across_stable_unit_ids\" not in globals():\n",
    "    raise ValueError(\"Expected `across_stable_unit_ids` to already exist.\")\n",
    "\n",
    "df = trialized_position.copy().sort_index()\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "# Tuning x-axis\n",
    "speed_col = \"speed\"     # keep consistent with your other tuning (0..1)\n",
    "trial_col = \"trial_number\"\n",
    "\n",
    "# Sliding-window (continuous) binning params\n",
    "window_width = 20\n",
    "window_step = 2\n",
    "tuner_min = 0\n",
    "tuner_max = 120\n",
    "\n",
    "# Bootstrap params\n",
    "n_boot = 500\n",
    "random_state = 0\n",
    "\n",
    "# Metric params\n",
    "min_units_ok_bins = 3\n",
    "\n",
    "# Common inclusion mask (so you only differ by trial_type)\n",
    "base_mask = (\n",
    "    (df[\"zone\"] == \"run\")\n",
    "    & (df[\"trial_type\"].isin([\"inbound\", \"outbound\"]))\n",
    ")\n",
    "\n",
    "mask_common = (\n",
    "    base_mask\n",
    "    & df[trial_col].notna()\n",
    "    & np.isfinite(df[speed_col].to_numpy())\n",
    ")\n",
    "\n",
    "mask_inbound = mask_common & (df[\"trial_type\"] == \"inbound\")\n",
    "mask_outbound = mask_common & (df[\"trial_type\"] == \"outbound\")\n",
    "\n",
    "n_trials_in = int(df.loc[mask_inbound, trial_col].nunique())\n",
    "n_trials_out = int(df.loc[mask_outbound, trial_col].nunique())\n",
    "print(\"Trials inbound:\", n_trials_in)\n",
    "print(\"Trials outbound:\", n_trials_out)\n",
    "\n",
    "if n_trials_in < 2 or n_trials_out < 2:\n",
    "    raise ValueError(\"Need >=2 trials in BOTH inbound and outbound for trial bootstrap.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "38ab23d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inbound units: 180 n_centers: 51\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 2 â€” INBOUND tuning (BOOTSTRAPPED; sliding windows)\n",
    "# =========================\n",
    "\n",
    "(\n",
    "    tuning_in,\n",
    "    centers_in,\n",
    "    lo_in,\n",
    "    hi_in,\n",
    "    slope_boot_in,\n",
    "    curv_boot_in,\n",
    ") = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    column=speed_col,\n",
    "    spikes_list=spikes_list,\n",
    "    n_bins=8,  # ignored for sliding; kept for API compatibility\n",
    "    mask=mask_inbound,\n",
    "    trial_column=trial_col,\n",
    "    n_boot=n_boot,\n",
    "    ci=0.95,\n",
    "    random_state=random_state,\n",
    "    tuner_bins=None,\n",
    "    binning=\"sliding\",\n",
    "    window_width=window_width,\n",
    "    window_step=window_step,\n",
    "    tuner_min=tuner_min,\n",
    "    tuner_max=tuner_max,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Restrict to across-stable units only\n",
    "tuning_in = {u: tuning_in[u] for u in across_stable_unit_ids if u in tuning_in}\n",
    "lo_in = {u: lo_in[u] for u in across_stable_unit_ids if u in lo_in}\n",
    "hi_in = {u: hi_in[u] for u in across_stable_unit_ids if u in hi_in}\n",
    "\n",
    "print(\"Inbound units:\", len(tuning_in), \"n_centers:\", len(centers_in))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6c54432e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outbound units: 180 n_centers: 51\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 3 â€” OUTBOUND tuning (BOOTSTRAPPED; sliding windows)\n",
    "# =========================\n",
    "\n",
    "(\n",
    "    tuning_out,\n",
    "    centers_out,\n",
    "    lo_out,\n",
    "    hi_out,\n",
    "    slope_boot_out,\n",
    "    curv_boot_out,\n",
    ") = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    column=speed_col,\n",
    "    spikes_list=spikes_list,\n",
    "    n_bins=8,  # ignored for sliding; kept for API compatibility\n",
    "    mask=mask_outbound,\n",
    "    trial_column=trial_col,\n",
    "    n_boot=n_boot,\n",
    "    ci=0.95,\n",
    "    random_state=random_state,\n",
    "    tuner_bins=None,\n",
    "    binning=\"sliding\",\n",
    "    window_width=window_width,\n",
    "    window_step=window_step,\n",
    "    tuner_min=tuner_min,\n",
    "    tuner_max=tuner_max,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Restrict to across-stable units only\n",
    "tuning_out = {u: tuning_out[u] for u in across_stable_unit_ids if u in tuning_out}\n",
    "lo_out = {u: lo_out[u] for u in across_stable_unit_ids if u in lo_out}\n",
    "hi_out = {u: hi_out[u] for u in across_stable_unit_ids if u in hi_out}\n",
    "\n",
    "print(\"Outbound units:\", len(tuning_out), \"n_centers:\", len(centers_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units compared: 180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>peak_shift_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950374768</td>\n",
       "      <td>0.125525721</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.975467967</td>\n",
       "      <td>0.113496839</td>\n",
       "      <td>12.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.953669226</td>\n",
       "      <td>0.103240512</td>\n",
       "      <td>8.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.429299723</td>\n",
       "      <td>0.353061589</td>\n",
       "      <td>10.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.946508243</td>\n",
       "      <td>0.120272524</td>\n",
       "      <td>10.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         corr       nrmse  peak_shift_x\n",
       "0 0.950374768 0.125525721   0.000000000\n",
       "2 0.975467967 0.113496839  12.000000000\n",
       "3 0.953669226 0.103240512   8.000000000\n",
       "4 0.429299723 0.353061589  10.000000000\n",
       "5 0.946508243 0.120272524  10.000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>peak_shift_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000000</td>\n",
       "      <td>180.000000000</td>\n",
       "      <td>180.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.545007758</td>\n",
       "      <td>0.277565903</td>\n",
       "      <td>27.722222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.455855669</td>\n",
       "      <td>0.142825482</td>\n",
       "      <td>33.040867797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.802616845</td>\n",
       "      <td>0.038192540</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.348024170</td>\n",
       "      <td>0.179014905</td>\n",
       "      <td>2.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.710251413</td>\n",
       "      <td>0.246393597</td>\n",
       "      <td>11.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.890051259</td>\n",
       "      <td>0.354414358</td>\n",
       "      <td>54.500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.993106946</td>\n",
       "      <td>0.717068595</td>\n",
       "      <td>100.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               corr         nrmse  peak_shift_x\n",
       "count 180.000000000 180.000000000 180.000000000\n",
       "mean    0.545007758   0.277565903  27.722222222\n",
       "std     0.455855669   0.142825482  33.040867797\n",
       "min    -0.802616845   0.038192540   0.000000000\n",
       "25%     0.348024170   0.179014905   2.000000000\n",
       "50%     0.710251413   0.246393597  11.000000000\n",
       "75%     0.890051259   0.354414358  54.500000000\n",
       "max     0.993106946   0.717068595 100.000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median corr: 0.710251413291781\n",
      "Median nrmse: 0.24639359745350561\n",
      "Median peak_shift_x: 11.0\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 4 â€” Compare + plot (INBOUND vs OUTBOUND)\n",
    "# =========================\n",
    "\n",
    "def _interp_curve_to_centers(curve, from_centers, to_centers):\n",
    "    curve = np.asarray(curve, float)\n",
    "    from_centers = np.asarray(from_centers, float)\n",
    "    to_centers = np.asarray(to_centers, float)\n",
    "\n",
    "    finite = np.isfinite(curve) & np.isfinite(from_centers)\n",
    "    if finite.sum() < 2:\n",
    "        return np.full_like(to_centers, np.nan, dtype=float)\n",
    "\n",
    "    x = from_centers[finite]\n",
    "    y = curve[finite]\n",
    "    order = np.argsort(x)\n",
    "    x = x[order]\n",
    "    y = y[order]\n",
    "\n",
    "    out = np.interp(to_centers, x, y)\n",
    "    out[(to_centers < x.min()) | (to_centers > x.max())] = np.nan\n",
    "    return out\n",
    "\n",
    "# Use inbound centers as the shared x-axis (either is fine)\n",
    "centers = np.asarray(centers_in, float)\n",
    "\n",
    "# Align OUTBOUND onto inbound centers if needed (should usually match if tuner_min/max are fixed)\n",
    "if not np.allclose(centers_in, centers_out, equal_nan=True):\n",
    "    print(\"Center mismatch: interpolating OUTBOUND tuning + CI onto INBOUND centers.\")\n",
    "    tuning_out_aligned = {u: _interp_curve_to_centers(tuning_out[u], centers_out, centers) for u in tuning_out.keys()}\n",
    "    lo_out_aligned = {u: _interp_curve_to_centers(lo_out[u], centers_out, centers) for u in lo_out.keys()}\n",
    "    hi_out_aligned = {u: _interp_curve_to_centers(hi_out[u], centers_out, centers) for u in hi_out.keys()}\n",
    "else:\n",
    "    tuning_out_aligned = tuning_out\n",
    "    lo_out_aligned = lo_out\n",
    "    hi_out_aligned = hi_out\n",
    "\n",
    "# Units to compare: across-stable AND present in both curves\n",
    "plot_units = [u for u in across_stable_unit_ids if (u in tuning_in) and (u in tuning_out_aligned)]\n",
    "print(\"Units compared:\", len(plot_units))\n",
    "if len(plot_units) == 0:\n",
    "    raise ValueError(\"No units left after restricting to across_stable_unit_ids âˆ© (inboundâˆ©outbound).\")\n",
    "\n",
    "# Subset dicts so plotting funcs only see the units you want\n",
    "tuning_in_plot = {u: tuning_in[u] for u in plot_units}\n",
    "lo_in_plot = {u: lo_in[u] for u in plot_units}\n",
    "hi_in_plot = {u: hi_in[u] for u in plot_units}\n",
    "\n",
    "tuning_out_plot = {u: tuning_out_aligned[u] for u in plot_units}\n",
    "lo_out_plot = {u: lo_out_aligned[u] for u in plot_units}\n",
    "hi_out_plot = {u: hi_out_aligned[u] for u in plot_units}\n",
    "\n",
    "# Plot (both bootstrapped; sliding-window bins)\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_in_plot,\n",
    "    lo_in_plot,\n",
    "    hi_in_plot,\n",
    "    centers,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"INBOUND (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_out_plot,\n",
    "    lo_out_plot,\n",
    "    hi_out_plot,\n",
    "    centers,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"OUTBOUND (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Metrics (your 3)\n",
    "metrics = {}\n",
    "for u in plot_units:\n",
    "    a = np.asarray(tuning_in_plot[u], float)\n",
    "    b = np.asarray(tuning_out_plot[u], float)\n",
    "    metrics[u] = dict(\n",
    "        corr=curve_corr(a, b, min_bins=min_units_ok_bins),\n",
    "        nrmse=nrmse(a, b, min_bins=min_units_ok_bins),\n",
    "        peak_bin_shift=peak_bin_shift(a, b, centers, min_bins=min_units_ok_bins),\n",
    "    )\n",
    "\n",
    "metrics_df_inout = pd.DataFrame.from_dict(metrics, orient=\"index\")\n",
    "display(metrics_df_inout.head())\n",
    "display(metrics_df_inout.describe())\n",
    "\n",
    "print(\"Median corr:\", float(metrics_df_inout[\"corr\"].median(skipna=True)))\n",
    "print(\"Median nrmse:\", float(metrics_df_inout[\"nrmse\"].median(skipna=True)))\n",
    "print(\"Median peak_bin_shift:\", float(metrics_df_inout[\"peak_bin_shift\"].median(skipna=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell â€” Single-unit overlay: INBOUND vs OUTBOUND (across_stable_unit_ids only)\n",
    "# Requires from the inbound/outbound pipeline:\n",
    "#   - tuning_in_plot, lo_in_plot, hi_in_plot\n",
    "#   - tuning_out_plot, lo_out_plot, hi_out_plot\n",
    "#   - centers\n",
    "#   - plot_units\n",
    "# =========================\n",
    "\n",
    "unit_to_plot = 3  # set to an int unit id, or leave None to auto-pick\n",
    "\n",
    "if \"plot_units\" not in globals() or len(plot_units) == 0:\n",
    "    raise ValueError(\"Expected `plot_units` from the inbound/outbound comparison cell.\")\n",
    "\n",
    "if unit_to_plot is None:\n",
    "    unit_to_plot = plot_units[0]\n",
    "\n",
    "if unit_to_plot not in tuning_in_plot or unit_to_plot not in tuning_out_plot:\n",
    "    raise ValueError(\"unit_to_plot not available in both inbound and outbound tunings.\")\n",
    "\n",
    "x = np.asarray(centers, float)\n",
    "\n",
    "yin = np.asarray(tuning_in_plot[unit_to_plot], float)\n",
    "yout = np.asarray(tuning_out_plot[unit_to_plot], float)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 4.5), layout=\"tight\")\n",
    "\n",
    "ax.plot(x, yin, \"-o\", linewidth=2.0, markersize=4, label=\"INBOUND\")\n",
    "ax.plot(x, yout, \"-o\", linewidth=2.0, markersize=4, label=\"OUTBOUND\")\n",
    "\n",
    "# CI bands (if present)\n",
    "if unit_to_plot in lo_in_plot and unit_to_plot in hi_in_plot:\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        np.asarray(lo_in_plot[unit_to_plot], float),\n",
    "        np.asarray(hi_in_plot[unit_to_plot], float),\n",
    "        alpha=0.20,\n",
    "        label=\"INBOUND CI\",\n",
    "    )\n",
    "if unit_to_plot in lo_out_plot and unit_to_plot in hi_out_plot:\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        np.asarray(lo_out_plot[unit_to_plot], float),\n",
    "        np.asarray(hi_out_plot[unit_to_plot], float),\n",
    "        alpha=0.20,\n",
    "        label=\"OUTBOUND CI\",\n",
    "    )\n",
    "\n",
    "# Your 3 metrics\n",
    "cc = curve_corr(yin, yout, min_bins=min_units_ok_bins)\n",
    "ee = nrmse(yin, yout, min_bins=min_units_ok_bins)\n",
    "pp = peak_bin_shift(yin, yout, x, min_bins=min_units_ok_bins)\n",
    "\n",
    "ax.set_title(f\"Unit {unit_to_plot} | corr={cc:.3f} | nrmse={ee:.3f} | peak_bin_shift={pp:.3f}\")\n",
    "ax.set_xlabel(speed_col)\n",
    "ax.set_ylabel(\"Peak-normalized firing rate\")\n",
    "ax.set_ylim([-0.05, 1.05])\n",
    "ax.grid(True, alpha=0.25)\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909023fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts: {'stable': 29, 'unstable': 151, 'insufficient': 0}\n",
      "Thresholds: {'corr_thresh': 0.3, 'nrmse_thresh': 0.5, 'peak_shift_thresh': 0.1}\n",
      "N evaluated (across_stable_unit_ids): 180\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell â€” Barplot for INBOUND vs OUTBOUND comparison (across-stable units)\n",
    "if \"across_stable_unit_ids\" not in globals():\n",
    "    raise ValueError(\"Expected `across_stable_unit_ids` to exist.\")\n",
    "\n",
    "# Prefer a dedicated snapshot if you made one\n",
    "if \"metrics_df_inout\" in globals():\n",
    "    metrics_df_use = metrics_df_inout\n",
    "elif \"metrics_df\" in globals():\n",
    "    metrics_df_use = metrics_df\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Could not find `metrics_df_inout` or `metrics_df`.\\n\"\n",
    "        \"Run this right after the inbound/outbound comparison cell, or save:\\n\"\n",
    "        \"  metrics_df_inout = metrics_df.copy()\"\n",
    "    )\n",
    "\n",
    "need_cols = {\"corr\", \"nrmse\", \"peak_bin_shift\"}\n",
    "if not need_cols.issubset(set(metrics_df_use.columns)):\n",
    "    raise ValueError(f\"In/out metrics table missing columns {need_cols}; got {list(metrics_df_use.columns)}\")\n",
    "\n",
    "# ---- thresholds (keep same across comparisons unless you intend otherwise) ----\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh = 0.10  # in speed_norm units if your centers are speed_norm\n",
    "\n",
    "labels_inout = {}\n",
    "for u in across_stable_unit_ids:\n",
    "    if u not in metrics_df_use.index:\n",
    "        labels_inout[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    c = metrics_df_use.loc[u, \"corr\"]\n",
    "    e = metrics_df_use.loc[u, \"nrmse\"]\n",
    "    p = metrics_df_use.loc[u, \"peak_bin_shift\"]\n",
    "\n",
    "    if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "        labels_inout[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    # \"stable\" here means: inbound and outbound tuning curves are similar\n",
    "    is_stable = (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh)\n",
    "    labels_inout[u] = \"stable\" if is_stable else \"unstable\"\n",
    "\n",
    "cats = [\"stable\", \"unstable\", \"insufficient\"]\n",
    "counts = {c: list(labels_inout.values()).count(c) for c in cats}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.2 * 2.2, 3.2 * 2.2), layout=\"tight\")\n",
    "\n",
    "# Reuse your existing `colors` list if you have it; otherwise default palette\n",
    "if \"colors\" in globals() and isinstance(colors, (list, tuple)) and len(colors) >= 3:\n",
    "    bar_colors = [colors[0], colors[1], colors[2]]\n",
    "else:\n",
    "    bar_colors = [\"tab:green\", \"tab:orange\", \"tab:gray\"]\n",
    "\n",
    "ax.bar(cats, [counts[c] for c in cats], color=bar_colors, alpha=0.9)\n",
    "ax.set_ylabel(\"Number of units\")\n",
    "ax.set_title(\"Inbound vs Outbound robustness (across-stable units)\")\n",
    "\n",
    "# annotate counts\n",
    "for i, c in enumerate(cats):\n",
    "    ax.text(i, counts[c] + 0.5, str(counts[c]), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Counts:\", {c: counts[c] for c in cats})\n",
    "print(\"Thresholds:\", dict(corr_thresh=corr_thresh, nrmse_thresh=nrmse_thresh, peak_shift_thresh=peak_shift_thresh))\n",
    "print(\"N evaluated (across_stable_unit_ids):\", len(across_stable_unit_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba5aa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable units across INBOUND vs OUTBOUND: 98\n",
      "First 30 in/out-stable unit IDs: [2, 4, 5, 9, 10, 16, 18, 19, 21, 23, 29, 30, 31, 32, 35, 42, 46, 49, 60, 65, 67, 69, 73, 75, 82, 84, 85, 86, 87, 90]\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell â€” Plot IN/OUT-ROBUST units (INBOUND vs OUTBOUND)\n",
    "\n",
    "if \"across_stable_unit_ids\" not in globals():\n",
    "    raise ValueError(\"Expected `across_stable_unit_ids` to exist.\")\n",
    "\n",
    "# Pick the correct metrics table for inbound/outbound\n",
    "if \"metrics_df_inout\" in globals():\n",
    "    metrics_df_use = metrics_df_inout\n",
    "elif \"metrics_df\" in globals():\n",
    "    metrics_df_use = metrics_df\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Could not find inbound/outbound metrics (`metrics_df_inout` or `metrics_df`).\\n\"\n",
    "        \"If metrics_df got overwritten later, rerun the in/out comparison cell and do:\\n\"\n",
    "        \"  metrics_df_inout = metrics_df.copy()\"\n",
    "    )\n",
    "\n",
    "need_cols = {\"corr\", \"nrmse\", \"peak_bin_shift\"}\n",
    "if not need_cols.issubset(set(metrics_df_use.columns)):\n",
    "    raise ValueError(f\"In/out metrics table missing columns {need_cols}; got {list(metrics_df_use.columns)}\")\n",
    "\n",
    "# thresholds (edit to match your other sections)\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh = 10  # in speed_norm units\n",
    "\n",
    "# Ensure outbound-aligned dicts exist; if not, fall back\n",
    "if \"tuning_out_aligned\" not in globals():\n",
    "    if not (\"tuning_out\" in globals() and \"centers_out\" in globals()):\n",
    "        raise ValueError(\"Missing `tuning_out_aligned` (or `tuning_out` + `centers_out`). Run your alignment cell first.\")\n",
    "    tuning_out_aligned = tuning_out\n",
    "    lo_out_aligned = lo_out\n",
    "    hi_out_aligned = hi_out\n",
    "\n",
    "# Use inbound centers as the shared x-axis\n",
    "centers = np.asarray(centers_in, float)\n",
    "\n",
    "# Compute the stable (robust) unit set: across_stable_unit_ids + finite metrics + passes thresholds\n",
    "stable_units_inout = []\n",
    "for u in across_stable_unit_ids:\n",
    "    if u not in metrics_df_use.index:\n",
    "        continue\n",
    "\n",
    "    c = metrics_df_use.loc[u, \"corr\"]\n",
    "    e = metrics_df_use.loc[u, \"nrmse\"]\n",
    "    p = metrics_df_use.loc[u, \"peak_bin_shift\"]\n",
    "\n",
    "    if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "        continue\n",
    "\n",
    "    # is_stable = (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh)\n",
    "    is_stable = (c <= corr_thresh) or (e >= nrmse_thresh) or (p >= peak_shift_thresh)\n",
    "    if is_stable:\n",
    "        stable_units_inout.append(u)\n",
    "\n",
    "# Also ensure each unit exists in BOTH tuning dicts + CI dicts\n",
    "stable_units_inout = [\n",
    "    u for u in stable_units_inout\n",
    "    if (u in tuning_in) and (u in lo_in) and (u in hi_in)\n",
    "    and (u in tuning_out_aligned) and (u in lo_out_aligned) and (u in hi_out_aligned)\n",
    "]\n",
    "\n",
    "print(\"Stable units across INBOUND vs OUTBOUND:\", len(stable_units_inout))\n",
    "if len(stable_units_inout) == 0:\n",
    "    raise ValueError(\"No in/out-stable units found under these thresholds (or missing tuning/CI entries).\")\n",
    "\n",
    "# Subset dicts so the plotting function only sees the units you want\n",
    "tun_in_stable = {u: tuning_in[u] for u in stable_units_inout}\n",
    "lo_in_stable  = {u: lo_in[u]     for u in stable_units_inout}\n",
    "hi_in_stable  = {u: hi_in[u]     for u in stable_units_inout}\n",
    "\n",
    "tun_out_stable = {u: tuning_out_aligned[u] for u in stable_units_inout}\n",
    "lo_out_stable  = {u: lo_out_aligned[u]     for u in stable_units_inout}\n",
    "hi_out_stable  = {u: hi_out_aligned[u]     for u in stable_units_inout}\n",
    "\n",
    "col_label = speed_col if \"speed_col\" in globals() else \"speed_norm\"\n",
    "\n",
    "# Figure 1: INBOUND\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tun_in_stable,\n",
    "    lo_in_stable,\n",
    "    hi_in_stable,\n",
    "    centers,\n",
    "    column=col_label,\n",
    "    n_units=30,\n",
    "    label=\"INBOUND (in/out-unstable units; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Figure 2: OUTBOUND\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tun_out_stable,\n",
    "    lo_out_stable,\n",
    "    hi_out_stable,\n",
    "    centers,\n",
    "    column=col_label,\n",
    "    n_units=30,\n",
    "    label=\"OUTBOUND (in/out-unstable units; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "print(\"First 30 in/out-stable unit IDs:\", stable_units_inout[:30])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ab744",
   "metadata": {},
   "source": [
    "#### Retrieve firing properties of each unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce986f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_mpfc_recording, l_mpfc_sorting = get_si_recording_and_sorting({\"sorted_spikes_group_name\": \"left mPFC\"})\n",
    "mpfc_recording, mpfc_sorting =  get_si_recording_and_sorting({\"sorted_spikes_group_name\": \"mPFC\", **session_restrict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f88c613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34486/2250251112.py:3: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  mpfc_we = si.extract_waveforms(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e415418050294bc39115b83f81c5932f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms shared_memory multi buffer:   0%|          | 0/3637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd96c6e4a244d0eb21ccdc86a17ed21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms shared_memory multi buffer:   0%|          | 0/3637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd7f1e3d97c474c8fcd4a5dcea25443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/3637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "waveform_folder = \"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/waveforms_mpfc/\" # always add to base dir!\n",
    "\n",
    "mpfc_we = si.extract_waveforms(\n",
    "    mpfc_recording,\n",
    "    mpfc_sorting,\n",
    "    folder=waveform_folder,\n",
    "    load_if_exists=True,         \n",
    "    overwrite=False,             \n",
    "    max_spikes_per_unit=300,     \n",
    "    ms_before=0.75,               \n",
    "    ms_after=1.5,                \n",
    "    n_jobs= 5,                    \n",
    "    chunk_duration=\"1s\",         \n",
    "    progress_bar=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c8621dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unit_spike_waveform_grid(\n",
    "    waveform_extractor,\n",
    "    recording,\n",
    "    unit_ids=None,\n",
    "    *,\n",
    "    n_units=6,\n",
    "    n_spikes=6,                 # spikes PER unit\n",
    "    segment_index=0,\n",
    "    seed=0,\n",
    "    ncols=3,                    # 6 units -> 2 rows x 3 cols by default\n",
    "    y_unit=\"uV\",                # \"uV\" or \"V\"\n",
    "    show_template=True,\n",
    "    alpha=0.35,\n",
    "    spike_lw=0.8,\n",
    "    template_lw=2.5,\n",
    "    unit_label_offset=0,        # set to 1 if you want to display 1-based unit numbers\n",
    "    figsize=None,\n",
    "    spike_indices_by_unit=None, # optional dict: {unit_id: array/list of spike indices}\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot waveforms for 6 units in a grid, each subplot overlays N spike waveforms\n",
    "    (N must be even; default N=6). Uses each unit's \"best channel\" (max template PTP).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    waveform_extractor : spikeinterface WaveformExtractor (or compatible)\n",
    "        Must support .get_waveforms(unit_id, ...) and .get_template(unit_id).\n",
    "    recording : spikeinterface Recording (or compatible)\n",
    "        Used for sampling frequency to compute time axis.\n",
    "    unit_ids : list[int] | None\n",
    "        Which units to plot. If None, uses the first `n_units` units from the extractor.\n",
    "    n_units : int\n",
    "        Number of units/subplots. Default 6.\n",
    "    n_spikes : int (even)\n",
    "        Number of spikes PER unit to overlay. Default 6.\n",
    "    spike_indices_by_unit : dict | None\n",
    "        If provided, choose these spike indices per unit (overrides random sampling).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig, axes, chosen_spike_indices_by_unit\n",
    "    \"\"\"\n",
    "    if n_spikes <= 0:\n",
    "        raise ValueError(\"n_spikes must be >= 1\")\n",
    "    if n_spikes % 2 != 0:\n",
    "        raise ValueError(f\"n_spikes must be even (got {n_spikes})\")\n",
    "\n",
    "    # Get unit list (default: first n_units available)\n",
    "    if unit_ids is None:\n",
    "        if hasattr(waveform_extractor, \"sorting\"):\n",
    "            unit_ids = list(waveform_extractor.sorting.get_unit_ids())\n",
    "        elif hasattr(waveform_extractor, \"unit_ids\"):\n",
    "            unit_ids = list(waveform_extractor.unit_ids)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Couldn't infer unit_ids from waveform_extractor; pass unit_ids=[...] explicitly.\"\n",
    "            )\n",
    "    unit_ids = list(unit_ids)[:n_units]\n",
    "    if len(unit_ids) != n_units:\n",
    "        raise ValueError(f\"Need {n_units} unit_ids, got {len(unit_ids)}\")\n",
    "\n",
    "    # y scaling\n",
    "    if y_unit == \"uV\":\n",
    "        scale = 1.0\n",
    "        ylabel = \"amplitude (ÂµV)\"\n",
    "    elif y_unit == \"V\":\n",
    "        scale = 1e-6\n",
    "        ylabel = \"amplitude (V)\"\n",
    "    else:\n",
    "        raise ValueError(\"y_unit must be 'uV' or 'V'\")\n",
    "\n",
    "    # Robust helper for older/newer spikeinterface signatures\n",
    "    def _we_get_waveforms(we, unit_id, segment_index=0):\n",
    "        try:\n",
    "            return we.get_waveforms(unit_id, segment_index=segment_index)\n",
    "        except TypeError:\n",
    "            try:\n",
    "                return we.get_waveforms(unit_id, segment_index)\n",
    "            except TypeError:\n",
    "                return we.get_waveforms(unit_id)\n",
    "\n",
    "    fs = float(recording.get_sampling_frequency())\n",
    "    t_ms = (\n",
    "        (np.arange(waveform_extractor.nbefore + waveform_extractor.nafter) - waveform_extractor.nbefore)\n",
    "        / fs\n",
    "        * 1000.0\n",
    "    )\n",
    "\n",
    "    nrows = int(np.ceil(n_units / ncols))\n",
    "    if figsize is None:\n",
    "        figsize = (4.2 * ncols, 2.8 * nrows)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        figsize=figsize,\n",
    "        layout=\"tight\",\n",
    "    )\n",
    "    axes = np.atleast_1d(axes).ravel()\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    chosen = {}\n",
    "\n",
    "    for ax_i, unit_id in enumerate(unit_ids):\n",
    "        ax = axes[ax_i]\n",
    "\n",
    "        wfs = _we_get_waveforms(waveform_extractor, unit_id, segment_index=segment_index)\n",
    "        # wfs shape: (n_spikes_available, n_samples, n_channels)\n",
    "        if wfs is None or wfs.size == 0:\n",
    "            ax.set_title(f\"unit {unit_id + unit_label_offset} (no waveforms)\")\n",
    "            ax.axis(\"off\")\n",
    "            chosen[unit_id] = np.array([], dtype=int)\n",
    "            continue\n",
    "\n",
    "        template = waveform_extractor.get_template(unit_id)  # (n_samples, n_chans)\n",
    "        best_chan = int(np.argmax(template.ptp(axis=0)))\n",
    "\n",
    "        n_available = wfs.shape[0]\n",
    "        if spike_indices_by_unit is not None and unit_id in spike_indices_by_unit:\n",
    "            idx = np.asarray(spike_indices_by_unit[unit_id], dtype=int)\n",
    "            idx = idx[(idx >= 0) & (idx < n_available)]\n",
    "            if idx.size == 0:\n",
    "                raise ValueError(f\"spike_indices_by_unit[{unit_id}] had no valid indices in [0, {n_available})\")\n",
    "            if idx.size > n_spikes:\n",
    "                idx = idx[:n_spikes]\n",
    "        else:\n",
    "            n_show = min(n_spikes, n_available)\n",
    "            idx = rng.choice(n_available, size=n_show, replace=False) if n_available > n_show else np.arange(n_available)\n",
    "\n",
    "        chosen[unit_id] = idx\n",
    "\n",
    "        # plot spike waveforms on best channel\n",
    "        y = wfs[idx, :, best_chan] * scale\n",
    "        ax.plot(t_ms, y.T, color=\"k\", alpha=alpha, linewidth=spike_lw)\n",
    "\n",
    "        # optional: overlay template thicker\n",
    "        if show_template:\n",
    "            ax.plot(t_ms, template[:, best_chan] * scale, color=\"tab:blue\", linewidth=template_lw)\n",
    "\n",
    "        ax.axvline(0, color=\"k\", linewidth=1.2, alpha=0.35, linestyle=\"--\")\n",
    "        # ax.set_title(f\"unit {unit_id + unit_label_offset}  (n={len(idx)})\")\n",
    "\n",
    "    # Turn off any unused axes\n",
    "    for j in range(n_units, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    # Axis labels (outer)\n",
    "    for ax in axes[:n_units]:\n",
    "        ax.set_xlabel(\"time (ms)\")\n",
    "    axes[0].set_ylabel(ylabel)\n",
    "\n",
    "    return fig, axes.reshape(nrows, ncols), chosen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "363b0961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 1260x560 with 6 Axes>,\n",
       " array([[<Axes: xlabel='time (ms)', ylabel='amplitude (ÂµV)'>,\n",
       "         <Axes: xlabel='time (ms)'>, <Axes: xlabel='time (ms)'>],\n",
       "        [<Axes: xlabel='time (ms)'>, <Axes: xlabel='time (ms)'>,\n",
       "         <Axes: xlabel='time (ms)'>]], dtype=object),\n",
       " {0: array([141, 153]),\n",
       "  7: array([ 10, 284]),\n",
       "  12: array([284, 246]),\n",
       "  23: array([260,  93]),\n",
       "  31: array([248,  81]),\n",
       "  44: array([122, 193])})"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default: first 6 units, 6 spikes/unit, 2x3 grid\n",
    "plot_unit_spike_waveform_grid(mpfc_we, mpfc_recording)\n",
    "\n",
    "# choose exactly which units (6 of them)\n",
    "plot_unit_spike_waveform_grid(\n",
    "    mpfc_we,\n",
    "    mpfc_recording,\n",
    "    unit_ids=[0, 7, 12, 23, 31, 44],  # <-- your chosen units\n",
    "    n_spikes=2,\n",
    "    seed=1,\n",
    "    unit_label_offset=1,             # if you want titles to show 1-based indexing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mask = (trialized_position[\"zone\"] == \"run\") #& (trialized_position[\"trial_type\"]==\"inbound\")\n",
    "outbound_mask = (trialized_position[\"zone\"] == \"run\") & (trialized_position[\"trial_type\"]==\"outbound\")\n",
    "inbound_mask = (trialized_position[\"zone\"] == \"run\") & (trialized_position[\"trial_type\"]==\"inbound\") \n",
    "\n",
    "mpfc_sorting_run = restrict_sorting_by_position_mask(\n",
    "    sorting=mpfc_sorting,\n",
    "    recording=mpfc_recording,\n",
    "    position_df=trialized_position,\n",
    "    mask=run_mask,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "mpfc_sorting_outbound = restrict_sorting_by_position_mask(\n",
    "    sorting=mpfc_sorting,\n",
    "    recording=mpfc_recording,\n",
    "    position_df=trialized_position,\n",
    "    mask=outbound_mask,\n",
    ")\n",
    "\n",
    "mpfc_sorting_inbound = restrict_sorting_by_position_mask(\n",
    "    sorting=mpfc_sorting,\n",
    "    recording=mpfc_recording,\n",
    "    position_df=trialized_position,\n",
    "    mask=inbound_mask,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "e6014824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 900x440 with 6 Axes>,\n",
       " array([[<Axes: ylabel='unit 23 (1.40 Hz)'>, <Axes: >, <Axes: >],\n",
       "        [<Axes: xlabel='Speed (cm/s)', ylabel='unit 8 (2.80 Hz)'>,\n",
       "         <Axes: xlabel='Lag (ms)'>, <Axes: xlabel='Time (ms)'>]],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_type = \"inbound\"\n",
    "\n",
    "\n",
    "if trial_type == \"inbound\":\n",
    "    sorting = l_mpfc_sorting_inbound\n",
    "elif trial_type == \"outbound\":\n",
    "    sorting = l_mpfc_sorting_outbound\n",
    "\n",
    "plot_unit_speed_acg_template_grid(\n",
    "    # unit_ids=[2, 8, 13, 16, 17, 18, 32, 28], # the \"interesting\" units\n",
    "    unit_ids = [23, 8], # left vs right tuned on the inboud trials\n",
    "    spikes_list=l_mpfc_spikes,\n",
    "    speed_tuning=speed_tuning,\n",
    "    speed_bin_centers=speed_bin_centers,\n",
    "    sorting=sorting,               \n",
    "    waveform_extractor=l_mpfc_we,\n",
    "    position_df=trialized_position[(trialized_position[\"trial_type\"]==trial_type)],     \n",
    "    mask=None,\n",
    "    plot_speed=True,\n",
    "    plot_acg=True,\n",
    "    plot_template=True,\n",
    "    bin_ms=20.0,\n",
    "    window_ms=1000.0,\n",
    "    suptitle = \"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad926318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n"
     ]
    }
   ],
   "source": [
    "# Plot ALL waveforms overlapped (first 5 units), all the same color\n",
    "\n",
    "unit_ids_5 = list(mpfc_sorting.get_unit_ids()[:5])\n",
    "mpfc_sorting_5 = mpfc_sorting.select_units(unit_ids_5)\n",
    "\n",
    "we_folder_5 = Path(base_dir) / \"waveforms\" / \"mpfc_first5_units\"\n",
    "\n",
    "if \"mpfc_we_5\" in globals():\n",
    "    we_5 = mpfc_we_5\n",
    "elif we_folder_5.exists():\n",
    "    we_5 = sc.WaveformExtractor.load(we_folder_5)\n",
    "else:\n",
    "    we_5 = sc.extract_waveforms(\n",
    "        mpfc_recording,\n",
    "        mpfc_sorting_5,\n",
    "        folder=we_folder_5,\n",
    "        ms_before=1.0,\n",
    "        ms_after=2.0,\n",
    "        max_spikes_per_unit=200,\n",
    "        n_jobs=16,\n",
    "        overwrite=False,\n",
    "    )\n",
    "    mpfc_we_5 = we_5\n",
    "\n",
    "\n",
    "def _we_get_waveforms(we, unit_id, segment_index=0):\n",
    "    try:\n",
    "        return we.get_waveforms(unit_id, segment_index=segment_index)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            return we.get_waveforms(unit_id, segment_index)\n",
    "        except TypeError:\n",
    "            return we.get_waveforms(unit_id)\n",
    "\n",
    "\n",
    "color = \"#1188d8\"\n",
    "segment_index = 0\n",
    "max_spikes_to_plot_per_unit = 400  # increase/decrease depending on how dense you want it\n",
    "alpha = 0.1\n",
    "single_lw = 1.5\n",
    "\n",
    "fs = mpfc_recording.get_sampling_frequency()\n",
    "t_ms = (np.arange(we_5.nbefore + we_5.nafter) - we_5.nbefore) / fs * 1000\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10), layout=\"tight\")\n",
    "\n",
    "for unit_id in unit_ids_5:\n",
    "    wfs = _we_get_waveforms(we_5, unit_id, segment_index=segment_index)   # (n_spikes, n_samples, n_chans)\n",
    "    template = we_5.get_template(unit_id)                                 # (n_samples, n_chans)\n",
    "\n",
    "    best_chan = int(np.argmax(template.ptp(axis=0)))\n",
    "    w = wfs[:, :, best_chan]  # (n_spikes, n_samples)\n",
    "\n",
    "    if w.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    n_show = min(w.shape[0], max_spikes_to_plot_per_unit)\n",
    "    idx = (\n",
    "        np.random.choice(w.shape[0], size=n_show, replace=False)\n",
    "        if w.shape[0] > n_show\n",
    "        else np.arange(w.shape[0])\n",
    "    )\n",
    "\n",
    "    # plot all selected waveforms for this unit, overlaid onto the SAME axis\n",
    "    ax.plot(t_ms, w[idx].T, color='k', alpha=alpha, linewidth=single_lw)\n",
    "\n",
    "ax.axvline(0, color=\"k\", linewidth=1.5, alpha=0.4, linestyle = \"--\")\n",
    "# ax.set_title(f\"Overlaid waveforms (first {len(unit_ids_5)} units)\", fontsize=12)\n",
    "ax.set_xlabel(\"time (ms)\")\n",
    "ax.set_ylabel(\"amplitude\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67674e3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'we_5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 56\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fig\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Example (uses your notebook-defined `colors` automatically):\u001b[39;00m\n\u001b[1;32m     55\u001b[0m plot_unit_templates_overlaid_colored(\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mwe_5\u001b[49m,\n\u001b[1;32m     57\u001b[0m     mpfc_recording,\n\u001b[1;32m     58\u001b[0m     unit_ids_5,\n\u001b[1;32m     59\u001b[0m     y_unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     60\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'we_5' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_unit_templates_overlaid_colored(\n",
    "    waveform_extractor,\n",
    "    recording,\n",
    "    unit_ids,\n",
    "    colors=None,             # pass your existing `colors` list; defaults to global `colors` if present\n",
    "    y_unit=\"V\",              # \"uV\" or \"V\"\n",
    "    lw=2.0,\n",
    "    alpha=0.95,\n",
    "):\n",
    "    \"\"\"\n",
    "    Overlay per-unit templates on a single axis, one color per unit,\n",
    "    using each unit's best channel (max peak-to-peak on template).\n",
    "    \"\"\"\n",
    "    unit_ids = list(unit_ids)\n",
    "\n",
    "    if colors is None:\n",
    "        colors = globals().get(\"colors\", None)\n",
    "    if colors is None:\n",
    "        raise ValueError(\"No colors provided and global `colors` not found. Pass colors=colors.\")\n",
    "\n",
    "    if len(colors) < len(unit_ids):\n",
    "        raise ValueError(f\"Need at least {len(unit_ids)} colors, got {len(colors)}\")\n",
    "\n",
    "    if y_unit == \"uV\":\n",
    "        scale = 1.0\n",
    "        ylabel = \"amplitude (ÂµV)\"\n",
    "    elif y_unit == \"V\":\n",
    "        scale = 1e-6\n",
    "        ylabel = \"amplitude (V)\"\n",
    "    else:\n",
    "        raise ValueError(\"y_unit must be 'uV' or 'V'\")\n",
    "\n",
    "    fs = recording.get_sampling_frequency()\n",
    "    t_ms = (np.arange(waveform_extractor.nbefore + waveform_extractor.nafter) - waveform_extractor.nbefore) / fs * 1000\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10), layout=\"tight\")\n",
    "\n",
    "    for i, unit_id in enumerate(unit_ids):\n",
    "        template = waveform_extractor.get_template(unit_id)  # (n_samples, n_chans)\n",
    "        best_chan = int(np.argmax(template.ptp(axis=0)))\n",
    "        y = template[:, best_chan] * scale\n",
    "\n",
    "        ax.plot(t_ms, y, color=colors[i], alpha=alpha, linewidth=5, label=str(unit_id+1))\n",
    "\n",
    "    ax.axvline(0, color=\"k\", linewidth=1.5, alpha=0.4, linestyle = \"--\")\n",
    "    # ax.set_title(\"Overlaid templates\", fontsize=12)\n",
    "    ax.set_xlabel(\"time (ms)\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.legend(title=\"Unit\", frameon=False, fontsize=16, title_fontsize=18)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Example (uses your notebook-defined `colors` automatically):\n",
    "plot_unit_templates_overlaid_colored(\n",
    "    we_5,\n",
    "    mpfc_recording,\n",
    "    unit_ids_5,\n",
    "    y_unit=\"V\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de28db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n"
     ]
    }
   ],
   "source": [
    "# Plot 100 ms of raw data from ONE channel, bandpass filtered 300â€“6000 Hz\n",
    "\n",
    "fs = mpfc_recording.get_sampling_frequency()\n",
    "duration_s = 0.100\n",
    "n_frames = int(round(duration_s * fs))\n",
    "\n",
    "t_start_s = 0.0  # change this to move the window\n",
    "start_frame = int(round(t_start_s * fs))\n",
    "end_frame = start_frame + n_frames\n",
    "\n",
    "# choose a single channel (change index or set chan_id explicitly)\n",
    "chan_id = mpfc_recording.channel_ids[0]\n",
    "\n",
    "rec_bp = si.preprocessing.bandpass_filter(\n",
    "    mpfc_recording,\n",
    "    freq_min=300.0,\n",
    "    freq_max=6000.0,\n",
    ")\n",
    "\n",
    "get_traces_kwargs = dict(start_frame=start_frame, end_frame=end_frame, channel_ids=[chan_id])\n",
    "if getattr(mpfc_recording, \"get_num_segments\", lambda: 1)() > 1:\n",
    "    get_traces_kwargs[\"segment_index\"] = 0\n",
    "\n",
    "try:\n",
    "    trace = rec_bp.get_traces(**get_traces_kwargs)[:, 0]  # (n_frames,)\n",
    "except TypeError:\n",
    "    get_traces_kwargs.pop(\"segment_index\", None)\n",
    "    trace = rec_bp.get_traces(**get_traces_kwargs)[:, 0]\n",
    "\n",
    "t_ms = (np.arange(trace.shape[0]) / fs) * 1000\n",
    "\n",
    "# your recording appears to already be in ÂµV; switch to Volts by setting scale=1e-6\n",
    "scale = 1.0\n",
    "ylabel = \"amplitude (ÂµV)\"\n",
    "trace = trace * scale\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10), layout=\"tight\")\n",
    "ax.plot(t_ms, trace, color=\"k\", linewidth=2)\n",
    "ax.set_title(f\"Channel {chan_id} bandpass 300â€“6000 Hz (100 ms)\")\n",
    "ax.set_xlabel(\"time (ms)\")\n",
    "ax.set_ylabel(ylabel)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "59ac6c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 900x440 with 6 Axes>,\n",
       " array([[<Axes: ylabel='unit 21 (2.94 Hz)'>, <Axes: >, <Axes: >],\n",
       "        [<Axes: xlabel='Speed (cm/s)', ylabel='unit 70 (3.06 Hz)'>,\n",
       "         <Axes: xlabel='Lag (ms)'>, <Axes: xlabel='Time (ms)'>]],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_unit_speed_acg_template_grid([21, 70], mpfc_spikes, speed_tuning, speed_centers, mpfc_sorting, mpfc_we, trialized_position, base_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef702712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trialized_position.copy().sort_index()\n",
    "\n",
    "base_mask = (df[\"zone\"] == \"run\") & df[\"trial_type\"].isin([\"inbound\", \"outbound\"])\n",
    "\n",
    "res_inout = permutation_test_tuning_difference_trial_labels(\n",
    "    df,\n",
    "    column=\"speed\",\n",
    "    spikes_list=mpfc_spikes,\n",
    "    base_mask=base_mask,\n",
    "    trial_column=\"trial_number\",\n",
    "    label_column=\"trial_type\",\n",
    "    label_a=\"inbound\",\n",
    "    label_b=\"outbound\",\n",
    "    binning=\"sliding\",\n",
    "    window_width=0.20,\n",
    "    window_step=0.02,\n",
    "    tuner_min=0.0,\n",
    "    tuner_max=1.0,\n",
    "    n_perm=2000,\n",
    "    random_state=0,\n",
    "    strata_column=\"epoch\",              # recommended if epochs differ\n",
    "    units=across_stable_unit_ids,       # optional\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40120340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_corr</th>\n",
       "      <th>p_nrmse</th>\n",
       "      <th>p_peak_shift_x</th>\n",
       "      <th>p_mean_rate_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.442278861</td>\n",
       "      <td>0.221389305</td>\n",
       "      <td>0.999000500</td>\n",
       "      <td>0.095452274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.890269151</td>\n",
       "      <td>0.581709145</td>\n",
       "      <td>0.529735132</td>\n",
       "      <td>0.528235882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.123938031</td>\n",
       "      <td>0.026486757</td>\n",
       "      <td>0.031984008</td>\n",
       "      <td>0.044977511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.355322339</td>\n",
       "      <td>0.042478761</td>\n",
       "      <td>0.663168416</td>\n",
       "      <td>0.306346827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.198900550</td>\n",
       "      <td>0.238880560</td>\n",
       "      <td>0.412293853</td>\n",
       "      <td>0.472263868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       p_corr     p_nrmse  p_peak_shift_x  p_mean_rate_diff\n",
       "0 0.442278861 0.221389305     0.999000500       0.095452274\n",
       "2 0.890269151 0.581709145     0.529735132       0.528235882\n",
       "3 0.123938031 0.026486757     0.031984008       0.044977511\n",
       "4 0.355322339 0.042478761     0.663168416       0.306346827\n",
       "5 0.198900550 0.238880560     0.412293853       0.472263868"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_corr</th>\n",
       "      <th>q_nrmse</th>\n",
       "      <th>q_peak_shift_x</th>\n",
       "      <th>q_mean_rate_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.582752102</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.373508898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.943312128</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.748680778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.339830085</td>\n",
       "      <td>0.605151969</td>\n",
       "      <td>0.307087835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.348086826</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.624631504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.605612687</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.735382309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       q_corr     q_nrmse  q_peak_shift_x  q_mean_rate_diff\n",
       "0 1.000000000 0.582752102     1.000000000       0.373508898\n",
       "2 1.000000000 0.943312128     1.000000000       0.748680778\n",
       "3 1.000000000 0.339830085     0.605151969       0.307087835\n",
       "4 1.000000000 0.348086826     1.000000000       0.624631504\n",
       "5 1.000000000 0.605612687     1.000000000       0.735382309"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sig units (q_max<0.05): 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "display(res_inout[\"p_values\"].head())\n",
    "display(res_inout[\"q_values\"].head())\n",
    "sig_units = res_inout[\"q_max\"][res_inout[\"q_max\"] < 0.05].index.to_numpy()\n",
    "print(\"sig units (q_max<0.05):\", len(sig_units))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d74d5",
   "metadata": {},
   "source": [
    "#### Figurl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "7ca658a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trialized_position\n",
    "# speed (bootstrap)\n",
    "speed_tuning, speed_centers, speed_lower, speed_upper, slope_boot_s, curvature_boot_s = compute_tuning_bootstrap_trials(\n",
    "    df, \"speed\", spikes_list, n_bins=8, mask=mask, trial_column=\"trial_number\", n_boot=500, random_state=0\n",
    ")\n",
    "speed_shape_by_unit, _ = classify_tuning_shapes_from_bootstraps(slope_boot_s, curvature_boot_s, ci=0.95, min_valid_boot=200)\n",
    "\n",
    "# progress (bootstrap)\n",
    "progress_tuning, progress_centers, progress_lower, progress_upper, slope_boot_p, curvature_boot_p = compute_tuning_bootstrap_trials(\n",
    "    df, \"trial_progress\", spikes_list, n_bins=8, mask=mask, trial_column=\"trial_number\", n_boot=500, random_state=0\n",
    ")\n",
    "progress_shape_by_unit, _ = classify_tuning_shapes_from_bootstraps(slope_boot_p, curvature_boot_p, ci=0.95, min_valid_boot=200)\n",
    "\n",
    "# location (non-bootstrap example)\n",
    "location_tuning, location_centers = compute_tuning(\n",
    "    trialized_position, \"trial_progress_distance\", spikes_list, n_bins=8, mask=mask\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "50664301",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_ids = select_units_by_shape(speed_shape_by_unit, include_shapes=[\"decreasing\"])\n",
    "# unit_ids = unit_ids[:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bde235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n"
     ]
    }
   ],
   "source": [
    "df = trialized_position.copy()\n",
    "speed_tuning, speed_centers, lo, hi, slope_boot, curv_boot = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    spikes_list=spikes_list,\n",
    "    mask=mask,\n",
    "    column =\"speed_norm\",\n",
    "    # progress_col=\"trial_progress_distance\",\n",
    "    # progress_bins=np.linspace(0, 1, 6),  # still discrete along progress\n",
    "    binning=\"sliding\",\n",
    "    window_width=0.20,\n",
    "    window_step=0.04,\n",
    "    tuner_min=0.0,\n",
    "    tuner_max=1.0,\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    "    peak_normalize = True\n",
    ")\n",
    "\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    speed_tuning, lo, hi, speed_centers,\n",
    "    column=\"speed_norm\",\n",
    "    n_units=60,\n",
    "    s=1,\n",
    "    color=\"tab:blue\",\n",
    "    ylims = (0,1),\n",
    "    peak_normalize = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4d81d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_by_unit, stats_by_unit = classify_tuning_shapes_from_bootstraps(\n",
    "    slope_boot,\n",
    "    curv_boot,\n",
    "    bin_centers=speed_centers,\n",
    "    ci=0.95,\n",
    "    min_valid_boot=200,\n",
    "    normalize_x=False #is fine for speed_norm in [0,1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d08d28",
   "metadata": {},
   "source": [
    "#### Left vs right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b590528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "across_stable_unit_ids = sorted([u for u, s in across_epoch_status.items() if s == \"stable\"])\n",
    "\n",
    "# =========================\n",
    "# Cell 1 â€” Setup masks (OUTBOUND LEFT vs OUTBOUND RIGHT) using across_stable_unit_ids only\n",
    "# =========================\n",
    "\n",
    "if \"across_stable_unit_ids\" not in globals():\n",
    "    raise ValueError(\"Expected `across_stable_unit_ids` to already exist.\")\n",
    "\n",
    "df = trialized_position.copy().sort_index()\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "# Column defining choice on outbound trials\n",
    "choice_col = \"left/right\"   # values: \"left\" or \"right\"\n",
    "choice_left = \"left\"\n",
    "choice_right = \"right\"\n",
    "\n",
    "# Tuning x-axis\n",
    "speed_col = \"speed\"    # keep consistent with your other pipelines (0..1)\n",
    "trial_col = \"trial_number\"\n",
    "\n",
    "# Sliding-window (continuous) binning params\n",
    "window_width = 20\n",
    "window_step = 2\n",
    "tuner_min = 0\n",
    "tuner_max = 120\n",
    "\n",
    "# Bootstrap params\n",
    "n_boot = 500\n",
    "random_state = 0\n",
    "\n",
    "# Metric params\n",
    "min_units_ok_bins = 3\n",
    "\n",
    "# Common inclusion mask (so only the choice differs)\n",
    "base_mask = (\n",
    "    (df[\"zone\"] == \"run\")\n",
    "    & (df[\"trial_type\"] == \"outbound\")\n",
    ")\n",
    "\n",
    "mask_common = (\n",
    "    base_mask\n",
    "    & df[trial_col].notna()\n",
    "    & np.isfinite(df[speed_col].to_numpy())\n",
    "    & df[choice_col].notna()\n",
    ")\n",
    "\n",
    "mask_left = mask_common & (df[choice_col] == choice_left)\n",
    "mask_right = mask_common & (df[choice_col] == choice_right)\n",
    "\n",
    "n_trials_left = int(df.loc[mask_left, trial_col].nunique())\n",
    "n_trials_right = int(df.loc[mask_right, trial_col].nunique())\n",
    "print(\"Trials LEFT:\", n_trials_left)\n",
    "print(\"Trials RIGHT:\", n_trials_right)\n",
    "\n",
    "if n_trials_left < 2 or n_trials_right < 2:\n",
    "    raise ValueError(\"Need >=2 trials in BOTH left and right for trial bootstrap.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e7ba3dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left units: 180 n_centers: 51\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 2 â€” LEFT tuning (BOOTSTRAPPED; sliding windows)\n",
    "# =========================\n",
    "\n",
    "(\n",
    "    tuning_left,\n",
    "    centers_left,\n",
    "    lo_left,\n",
    "    hi_left,\n",
    "    slope_boot_left,\n",
    "    curv_boot_left,\n",
    ") = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    column=speed_col,\n",
    "    spikes_list=spikes_list,\n",
    "    n_bins=8,  # ignored for sliding; kept for API compatibility\n",
    "    mask=mask_left,\n",
    "    trial_column=trial_col,\n",
    "    n_boot=n_boot,\n",
    "    ci=0.95,\n",
    "    random_state=random_state,\n",
    "    tuner_bins=None,\n",
    "    binning=\"sliding\",\n",
    "    window_width=window_width,\n",
    "    window_step=window_step,\n",
    "    tuner_min=tuner_min,\n",
    "    tuner_max=tuner_max,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Restrict to across-stable units only\n",
    "tuning_left = {u: tuning_left[u] for u in across_stable_unit_ids if u in tuning_left}\n",
    "lo_left = {u: lo_left[u] for u in across_stable_unit_ids if u in lo_left}\n",
    "hi_left = {u: hi_left[u] for u in across_stable_unit_ids if u in hi_left}\n",
    "\n",
    "print(\"Left units:\", len(tuning_left), \"n_centers:\", len(centers_left))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e461b754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right units: 180 n_centers: 51\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 3 â€” RIGHT tuning (BOOTSTRAPPED; sliding windows)\n",
    "# =========================\n",
    "\n",
    "(\n",
    "    tuning_right,\n",
    "    centers_right,\n",
    "    lo_right,\n",
    "    hi_right,\n",
    "    slope_boot_right,\n",
    "    curv_boot_right,\n",
    ") = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    column=speed_col,\n",
    "    spikes_list=spikes_list,\n",
    "    n_bins=8,  # ignored for sliding; kept for API compatibility\n",
    "    mask=mask_right,\n",
    "    trial_column=trial_col,\n",
    "    n_boot=n_boot,\n",
    "    ci=0.95,\n",
    "    random_state=random_state,\n",
    "    tuner_bins=None,\n",
    "    binning=\"sliding\",\n",
    "    window_width=window_width,\n",
    "    window_step=window_step,\n",
    "    tuner_min=tuner_min,\n",
    "    tuner_max=tuner_max,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Restrict to across-stable units only\n",
    "tuning_right = {u: tuning_right[u] for u in across_stable_unit_ids if u in tuning_right}\n",
    "lo_right = {u: lo_right[u] for u in across_stable_unit_ids if u in lo_right}\n",
    "hi_right = {u: hi_right[u] for u in across_stable_unit_ids if u in hi_right}\n",
    "\n",
    "print(\"Right units:\", len(tuning_right), \"n_centers:\", len(centers_right))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8020cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 4 â€” Compare + plot (LEFT vs RIGHT) using 3 metrics (across_stable_unit_ids only)\n",
    "# =========================\n",
    "\n",
    "def _interp_curve_to_centers(curve, from_centers, to_centers):\n",
    "    curve = np.asarray(curve, float)\n",
    "    from_centers = np.asarray(from_centers, float)\n",
    "    to_centers = np.asarray(to_centers, float)\n",
    "\n",
    "    finite = np.isfinite(curve) & np.isfinite(from_centers)\n",
    "    if finite.sum() < 2:\n",
    "        return np.full_like(to_centers, np.nan, dtype=float)\n",
    "\n",
    "    x = from_centers[finite]\n",
    "    y = curve[finite]\n",
    "    order = np.argsort(x)\n",
    "    x = x[order]\n",
    "    y = y[order]\n",
    "\n",
    "    out = np.interp(to_centers, x, y)\n",
    "    out[(to_centers < x.min()) | (to_centers > x.max())] = np.nan\n",
    "    return out\n",
    "\n",
    "# Use LEFT centers as the common x-axis\n",
    "centers = np.asarray(centers_left, float)\n",
    "\n",
    "# Align RIGHT onto LEFT centers if needed\n",
    "if not np.allclose(centers_left, centers_right, equal_nan=True):\n",
    "    print(\"Center mismatch: interpolating RIGHT tuning + CI onto LEFT centers.\")\n",
    "    tuning_right_aligned = {u: _interp_curve_to_centers(tuning_right[u], centers_right, centers) for u in tuning_right.keys()}\n",
    "    lo_right_aligned = {u: _interp_curve_to_centers(lo_right[u], centers_right, centers) for u in lo_right.keys()}\n",
    "    hi_right_aligned = {u: _interp_curve_to_centers(hi_right[u], centers_right, centers) for u in hi_right.keys()}\n",
    "else:\n",
    "    tuning_right_aligned = tuning_right\n",
    "    lo_right_aligned = lo_right\n",
    "    hi_right_aligned = hi_right\n",
    "\n",
    "# Units to compare: across-stable AND present in both curves\n",
    "plot_units = [u for u in across_stable_unit_ids if (u in tuning_left) and (u in tuning_right_aligned)]\n",
    "print(\"Units compared:\", len(plot_units))\n",
    "if len(plot_units) == 0:\n",
    "    raise ValueError(\"No units left after restricting to across_stable_unit_ids âˆ© (leftâˆ©right).\")\n",
    "\n",
    "# Subset dicts so plotting funcs only see the units you want\n",
    "tuning_left_plot = {u: tuning_left[u] for u in plot_units}\n",
    "lo_left_plot = {u: lo_left[u] for u in plot_units}\n",
    "hi_left_plot = {u: hi_left[u] for u in plot_units}\n",
    "\n",
    "tuning_right_plot = {u: tuning_right_aligned[u] for u in plot_units}\n",
    "lo_right_plot = {u: lo_right_aligned[u] for u in plot_units}\n",
    "hi_right_plot = {u: hi_right_aligned[u] for u in plot_units}\n",
    "\n",
    "# Plot (both bootstrapped; sliding-window bins)\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_left_plot,\n",
    "    lo_left_plot,\n",
    "    hi_left_plot,\n",
    "    centers,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"OUTBOUND LEFT (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_right_plot,\n",
    "    lo_right_plot,\n",
    "    hi_right_plot,\n",
    "    centers,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"OUTBOUND RIGHT (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Metrics \n",
    "metrics_lr = {}\n",
    "for u in plot_units:\n",
    "    a = np.asarray(tuning_left_plot[u], float)\n",
    "    b = np.asarray(tuning_right_plot[u], float)\n",
    "    metrics_lr[u] = dict(\n",
    "        corr=curve_corr(a, b, min_bins=min_units_ok_bins),\n",
    "        nrmse=nrmse(a, b, min_bins=min_units_ok_bins),\n",
    "        peak_bin_shift=peak_bin_shift(a, b, centers, min_bins=min_units_ok_bins),\n",
    "    )\n",
    "\n",
    "metrics_df_lr = pd.DataFrame.from_dict(metrics_lr, orient=\"index\")\n",
    "display(metrics_df_lr.head())\n",
    "display(metrics_df_lr.describe())\n",
    "\n",
    "print(\"Median corr:\", float(metrics_df_lr[\"corr\"].median(skipna=True)))\n",
    "print(\"Median nrmse:\", float(metrics_df_lr[\"nrmse\"].median(skipna=True)))\n",
    "print(\"Median peak_bin_shift:\", float(metrics_df_lr[\"peak_bin_shift\"].median(skipna=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b8115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts: {'stable': 62, 'unstable': 118, 'insufficient': 0}\n",
      "Thresholds: {'corr_thresh': 0.3, 'nrmse_thresh': 0.5, 'peak_shift_thresh': 10}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 5 â€” Bar plot: stable vs unstable vs insufficient (across_stable_unit_ids only)\n",
    "# (Threshold-based classification from metrics_df_lr; mirrors the structure of your earlier barplots.)\n",
    "# =========================\n",
    "\n",
    "# Choose thresholds\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh =10\n",
    "\n",
    "if \"metrics_df_lr\" not in globals():\n",
    "    raise ValueError(\"Expected `metrics_df_lr` from the left/right comparison cell.\")\n",
    "\n",
    "labels_lr = {}\n",
    "for u in across_stable_unit_ids:\n",
    "    if u not in metrics_df_lr.index:\n",
    "        labels_lr[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    row = metrics_df_lr.loc[u]\n",
    "    c = float(row[\"corr\"]) if np.isfinite(row[\"corr\"]) else np.nan\n",
    "    e = float(row[\"nrmse\"]) if np.isfinite(row[\"nrmse\"]) else np.nan\n",
    "    p = float(row[\"peak_bin_shift\"]) if np.isfinite(row[\"peak_bin_shift\"]) else np.nan\n",
    "\n",
    "    if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "        labels_lr[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    is_stable = (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh)\n",
    "    labels_lr[u] = \"stable\" if is_stable else \"unstable\"\n",
    "\n",
    "cats = [\"stable\", \"unstable\", \"insufficient\"]\n",
    "counts = {c: list(labels_lr.values()).count(c) for c in cats}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.2*2.2, 3.2*2.2), layout=\"tight\")\n",
    "\n",
    "if \"colors\" in globals() and isinstance(colors, (list, tuple)) and len(colors) >= 3:\n",
    "    bar_colors = [colors[0], colors[1], colors[2]]\n",
    "else:\n",
    "    bar_colors = [\"tab:green\", \"tab:orange\", \"tab:gray\"]\n",
    "\n",
    "ax.bar(cats, [counts[c] for c in cats], color=bar_colors, alpha=0.9)\n",
    "ax.set_ylabel(\"Number of units\")\n",
    "ax.set_title(\"Outbound Left vs Right: across-stable units\")\n",
    "\n",
    "for i, c in enumerate(cats):\n",
    "    ax.text(i, counts[c] + 0.5, str(counts[c]), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Counts:\", counts)\n",
    "print(\"Thresholds:\", dict(corr_thresh=corr_thresh, nrmse_thresh=nrmse_thresh, peak_shift_thresh=peak_shift_thresh))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae2b0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unstable units across LEFT vs RIGHT: 125\n",
      "First 30 L/R-unstable unit IDs: [0, 2, 4, 5, 6, 9, 10, 13, 18, 19, 23, 30, 31, 32, 34, 40, 41, 42, 43, 46, 49, 62, 64, 65, 67, 68, 69, 72, 73, 75]\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell â€” Plot L/R-ROBUST units (OUTBOUND LEFT vs OUTBOUND RIGHT)\n",
    "\n",
    "\n",
    "if \"across_stable_unit_ids\" not in globals():\n",
    "    raise ValueError(\"Expected `across_stable_unit_ids` to exist.\")\n",
    "\n",
    "# metrics table for left/right\n",
    "if \"metrics_df_lr\" in globals():\n",
    "    metrics_df_use = metrics_df_lr\n",
    "elif \"metrics_df_leftright\" in globals():\n",
    "    metrics_df_use = metrics_df_leftright\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Could not find left/right metrics table (`metrics_df_lr` or `metrics_df_leftright`).\\n\"\n",
    "        \"Make sure you ran the L/R comparison cell that creates `metrics_df_lr`.\"\n",
    "    )\n",
    "\n",
    "need_cols = {\"corr\", \"nrmse\", \"peak_bin_shift\"}\n",
    "if not need_cols.issubset(set(metrics_df_use.columns)):\n",
    "    raise ValueError(f\"L/R metrics table missing columns {need_cols}; got {list(metrics_df_use.columns)}\")\n",
    "\n",
    "# thresholds (edit to match other sections)\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh = 10  \n",
    "\n",
    "# Ensure right-aligned dicts exist; if not, fall back\n",
    "if \"tuning_right_aligned\" not in globals():\n",
    "    if \"tuning_right\" not in globals():\n",
    "        raise ValueError(\"Missing `tuning_right_aligned` (or `tuning_right`). Run your L/R alignment cell first.\")\n",
    "    tuning_right_aligned = tuning_right\n",
    "    lo_right_aligned = lo_right\n",
    "    hi_right_aligned = hi_right\n",
    "\n",
    "# Use LEFT centers as the shared x-axis\n",
    "centers = np.asarray(centers_left, float)\n",
    "\n",
    "# Compute the stable (robust) unit set: across_stable_unit_ids + finite metrics + passes thresholds\n",
    "stable_units_lr = []\n",
    "for u in across_stable_unit_ids:\n",
    "    if u not in metrics_df_use.index:\n",
    "        continue\n",
    "\n",
    "    c = metrics_df_use.loc[u, \"corr\"]\n",
    "    e = metrics_df_use.loc[u, \"nrmse\"]\n",
    "    p = metrics_df_use.loc[u, \"peak_bin_shift\"]\n",
    "\n",
    "    if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "        continue\n",
    "\n",
    "    # is_stable = (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh)\n",
    "    is_stable = (c <= corr_thresh) or (e >= nrmse_thresh) or (p >= peak_shift_thresh)\n",
    "    if is_stable:\n",
    "        stable_units_lr.append(u)\n",
    "\n",
    "# Ensure each unit exists in BOTH tuning dicts + CI dicts\n",
    "stable_units_lr = [\n",
    "    u for u in stable_units_lr\n",
    "    if (u in tuning_left) and (u in lo_left) and (u in hi_left)\n",
    "    and (u in tuning_right_aligned) and (u in lo_right_aligned) and (u in hi_right_aligned)\n",
    "]\n",
    "\n",
    "print(\"Unstable units across LEFT vs RIGHT:\", len(stable_units_lr))\n",
    "if len(stable_units_lr) == 0:\n",
    "    raise ValueError(\"No L/R-stable units found under these thresholds (or missing tuning/CI entries).\")\n",
    "\n",
    "# Subset dicts so the plotting function only sees the units you want\n",
    "tun_left_stable = {u: tuning_left[u] for u in stable_units_lr}\n",
    "lo_left_stable  = {u: lo_left[u]     for u in stable_units_lr}\n",
    "hi_left_stable  = {u: hi_left[u]     for u in stable_units_lr}\n",
    "\n",
    "tun_right_stable = {u: tuning_right_aligned[u] for u in stable_units_lr}\n",
    "lo_right_stable  = {u: lo_right_aligned[u]     for u in stable_units_lr}\n",
    "hi_right_stable  = {u: hi_right_aligned[u]     for u in stable_units_lr}\n",
    "\n",
    "col_label = speed_col if \"speed_col\" in globals() else \"speed_norm\"\n",
    "\n",
    "# Figure 1: OUTBOUND LEFT\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tun_left_stable,\n",
    "    lo_left_stable,\n",
    "    hi_left_stable,\n",
    "    centers,\n",
    "    column=col_label,\n",
    "    n_units=30,\n",
    "    label=\"OUTBOUND LEFT (L/R-unstable units; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Figure 2: OUTBOUND RIGHT\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tun_right_stable,\n",
    "    lo_right_stable,\n",
    "    hi_right_stable,\n",
    "    centers,\n",
    "    column=col_label,\n",
    "    n_units=30,\n",
    "    label=\"OUTBOUND RIGHT (L/R-unstable units; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "print(\"First 30 L/R-unstable unit IDs:\", stable_units_lr[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0da5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a48aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyglass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
