{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc5767d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run common_imports.py\n",
    "import seaborn as sns\n",
    "%matplotlib qt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "pd.options.display.max_rows = 600\n",
    "pd.set_option('display.float_format', lambda x: '%.9f' % x)\n",
    "\n",
    "dj.config['display.limit'] = 10**3  \n",
    "\n",
    "os.environ[\"SPYGLASS_USE_TRANSACTIONS\"] = \"1\"  \n",
    "os.environ['KACHERY_API_KEY'] = \"RhysjLwgmBAt2ObCyXXaDnqAv2kTdYRa\"\n",
    "\n",
    "import sys\n",
    "import tuning_analysis.sorting_multiprocessing as smp\n",
    "import spyglass.spikesorting.v1 as sgs\n",
    "import spikeinterface as si\n",
    "import spikeinterface.widgets as sw\n",
    "import spikeinterface.core as sc\n",
    "import spyglass.position.v1 as sgp\n",
    "import spyglass.linearization.v1 as sgpl\n",
    "\n",
    "from spyglass.position import PositionOutput\n",
    "from spyglass.spikesorting.analysis.v1.group import UnitSelectionParams\n",
    "from spyglass.spikesorting.analysis.v1.group import SortedSpikesGroup\n",
    "from tuning_analysis.trial_extraction import *\n",
    "from spyglass.spikesorting.spikesorting_merge import SpikeSortingOutput\n",
    "from tuning_analysis.spike_analysis import *\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d236b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFHRFWHRUaXRsZQB0YWIyMCBjb2xvcm1hcM5rFwoAAAAadEVYdERlc2NyaXB0aW9uAHRhYjIwIGNvbG9ybWFwMDS+7AAAADF0RVh0QXV0aG9yAE1hdHBsb3RsaWIgdjMuMTAuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZxYcXggAAAAzdEVYdFNvZnR3YXJlAE1hdHBsb3RsaWIgdjMuMTAuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ7M4TfwAAAHGSURBVHic7dYxStYBHIfxr56gQcIhfDelwSBoaBCFBnndbA46gEngokewzanVsa3NoRuIUwdojI6ga53i9yf4fj4XeNZnY3V19zcLuDl9s0Qm73/szkcOzuYbSfb/3I03zo8+jjeS5HB9O954efF5vJEkX3/ujTden2yPN5Lk/tvlIp23xyfjjdWvV+ONJNk6ejbe+PLwfbyRJOv1erzx+PRhvJEkq51P442D3+/GG0ly/eL5Ip3NRSoAwH/FAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIX+AfjSGNwLVnItAAAAAElFTkSuQmCC",
      "text/html": [
       "<div style=\"vertical-align: middle;\"><strong>tab20</strong> </div><div class=\"cmap\"><img alt=\"tab20 colormap\" title=\"tab20\" style=\"border: 1px solid #555;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFHRFWHRUaXRsZQB0YWIyMCBjb2xvcm1hcM5rFwoAAAAadEVYdERlc2NyaXB0aW9uAHRhYjIwIGNvbG9ybWFwMDS+7AAAADF0RVh0QXV0aG9yAE1hdHBsb3RsaWIgdjMuMTAuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZxYcXggAAAAzdEVYdFNvZnR3YXJlAE1hdHBsb3RsaWIgdjMuMTAuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ7M4TfwAAAHGSURBVHic7dYxStYBHIfxr56gQcIhfDelwSBoaBCFBnndbA46gEngokewzanVsa3NoRuIUwdojI6ga53i9yf4fj4XeNZnY3V19zcLuDl9s0Qm73/szkcOzuYbSfb/3I03zo8+jjeS5HB9O954efF5vJEkX3/ujTden2yPN5Lk/tvlIp23xyfjjdWvV+ONJNk6ejbe+PLwfbyRJOv1erzx+PRhvJEkq51P442D3+/GG0ly/eL5Ip3NRSoAwH/FAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIUMAAAUMgAAUMgAAEAhAwAAhQwAABQyAABQyAAAQCEDAACFDAAAFDIAAFDIAABAIQMAAIX+AfjSGNwLVnItAAAAAElFTkSuQmCC\"></div><div style=\"vertical-align: middle; max-width: 514px; display: flex; justify-content: space-between;\"><div style=\"float: left;\"><div title=\"#1f77b4ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #1f77b4ff;\"></div> under</div><div style=\"margin: 0 auto; display: inline-block;\">bad <div title=\"#00000000\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00000000;\"></div></div><div style=\"float: right;\">over <div title=\"#9edae5ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #9edae5ff;\"></div></div></div>"
      ],
      "text/plain": [
       "<matplotlib.colors.ListedColormap at 0x77195c657be0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cycler import cycler\n",
    "cmap = 'tab20'\n",
    "n_colors = 6\n",
    "cmap = plt.get_cmap(cmap)\n",
    "colors = [cmap(i) for i in np.linspace(0,1,n_colors)]\n",
    "plt.rcParams[\"axes.prop_cycle\"] = cycler(color = colors)\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['font.family'] = 'Sans'/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb7e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = sgpl.TrackGraph() & {\"track_graph_name\":\"Wtrack_wilbur20210512\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328fb55",
   "metadata": {},
   "source": [
    "### Plot unit-wise spiking locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eff9f01",
   "metadata": {},
   "source": [
    "#### Fetch spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d1f8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:17:59][WARNING] Spyglass: V0 requires artifact restrict. Ignoring \"restrict_by_artifact\" flag.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    <style type=\"text/css\">\n",
       "        .Table{\n",
       "            border-collapse:collapse;\n",
       "        }\n",
       "        .Table th{\n",
       "            background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "            font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "        }\n",
       "        .Table td{\n",
       "            padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "        }\n",
       "        .Table tr:nth-child(odd){\n",
       "            background: #ffffff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        .Table tr:nth-child(even){\n",
       "            background: #f3f1ff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        /* Tooltip container */\n",
       "        .djtooltip {\n",
       "        }\n",
       "        /* Tooltip text */\n",
       "        .djtooltip .djtooltiptext {\n",
       "            visibility: hidden;\n",
       "            width: 120px;\n",
       "            background-color: black;\n",
       "            color: #fff;\n",
       "            text-align: center;\n",
       "            padding: 5px 0;\n",
       "            border-radius: 6px;\n",
       "            /* Position the tooltip text - see examples below! */\n",
       "            position: absolute;\n",
       "            z-index: 1;\n",
       "        }\n",
       "        #primary {\n",
       "            font-weight: bold;\n",
       "            color: black;\n",
       "        }\n",
       "        #nonprimary {\n",
       "            font-weight: normal;\n",
       "            color: white;\n",
       "        }\n",
       "\n",
       "        /* Show the tooltip text when you mouse over the tooltip container */\n",
       "        .djtooltip:hover .djtooltiptext {\n",
       "            visibility: visible;\n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "    <b></b>\n",
       "        <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "        <table border=\"1\" class=\"Table\">\n",
       "            <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">merge_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">sorting_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">curation_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div> </th> </tr> </thead>\n",
       "            <tbody> <tr> <td>047f4da5-c1d4-ca9e-f923-cdb63c0d04e7</td>\n",
       "<td>d14d9669-4f3e-47c8-bed9-e0cc90be7a71</td>\n",
       "<td>2</td></tr><tr><td>0a29f32c-7036-e6bb-fd45-dc7ac35137fe</td>\n",
       "<td>45539c29-3436-4633-b63d-f499fe8e4073</td>\n",
       "<td>2</td></tr><tr><td>1a818a97-6f62-8d75-565f-7be81c6961c3</td>\n",
       "<td>ee34cd1e-e742-4c73-bdae-9974c2b1d74a</td>\n",
       "<td>2</td></tr><tr><td>3b2a05fa-9642-5ef4-58d7-1f8e9bf3e217</td>\n",
       "<td>76904362-d49e-4883-98d1-442822ebb9a1</td>\n",
       "<td>2</td></tr><tr><td>4db00acd-003c-de9a-b640-fb78fb276985</td>\n",
       "<td>df857aaa-ccd8-4abf-82e2-e9b97706c162</td>\n",
       "<td>2</td></tr><tr><td>6e499686-18c3-ef61-e344-d4e7d7c5e773</td>\n",
       "<td>bae249c1-f797-4e38-83ee-a21f51684a20</td>\n",
       "<td>2</td></tr><tr><td>70ca787c-23b6-feb6-84af-6e3ba338fdf3</td>\n",
       "<td>1dd1e911-c185-4488-b607-83502ac5225f</td>\n",
       "<td>2</td></tr><tr><td>d4644925-b88e-850f-36a2-291d1e1b99f7</td>\n",
       "<td>48a2c037-f872-4a63-9ccb-1bd14cb727e4</td>\n",
       "<td>2</td></tr><tr><td>e7eb99a4-da0e-a1ca-3be6-36e6037f9275</td>\n",
       "<td>6868b312-14db-473b-ae34-ce1bd193055d</td>\n",
       "<td>2</td></tr><tr><td>e9df24a9-9413-0623-2987-3064c50394ed</td>\n",
       "<td>0c0d6f10-5af6-4add-beac-67f101ecb017</td>\n",
       "<td>2</td></tr><tr><td>f04678f5-4b56-818c-3865-95449b8721d8</td>\n",
       "<td>f3df9cb1-5729-4521-8624-1dd556b3adb2</td>\n",
       "<td>2</td></tr><tr><td>fae2cacf-00d2-891f-441e-abf3f51a5206</td>\n",
       "<td>103990e9-2063-4541-906e-5c69fdf42339</td>\n",
       "<td>2</td> </tr> </tbody>\n",
       "        </table>\n",
       "        \n",
       "        <p>Total: 12</p></div>\n",
       "        "
      ],
      "text/plain": [
       "*merge_id      sorting_id     curation_id   \n",
       "+------------+ +------------+ +------------+\n",
       "047f4da5-c1d4- d14d9669-4f3e- 2             \n",
       "0a29f32c-7036- 45539c29-3436- 2             \n",
       "1a818a97-6f62- ee34cd1e-e742- 2             \n",
       "3b2a05fa-9642- 76904362-d49e- 2             \n",
       "4db00acd-003c- df857aaa-ccd8- 2             \n",
       "6e499686-18c3- bae249c1-f797- 2             \n",
       "70ca787c-23b6- 1dd1e911-c185- 2             \n",
       "d4644925-b88e- 48a2c037-f872- 2             \n",
       "e7eb99a4-da0e- 6868b312-14db- 2             \n",
       "e9df24a9-9413- 0c0d6f10-5af6- 2             \n",
       "f04678f5-4b56- f3df9cb1-5729- 2             \n",
       "fae2cacf-00d2- 103990e9-2063- 2             \n",
       " (Total: 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorter_keys = {\n",
    "    \"nwb_file_name\": nwb_copy_file_name,\n",
    "    \"sorter\": \"mountainsort4\",\n",
    "    \"curation_id\": 2,\n",
    "}\n",
    "\n",
    "pfc_merge_ids = SpikeSortingOutput().get_restricted_merge_ids(sorter_keys, restrict_by_artifact = True)\n",
    "\n",
    "keys = [{\"merge_id\": merge_id} for merge_id in pfc_merge_ids]\n",
    "(SpikeSortingOutput.CurationV1 & keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9dd263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spikes from a specific group\n",
    "group_key = {\n",
    "    \"nwb_file_name\": nwb_copy_file_name,\n",
    "    \"sorted_spikes_group_name\": \"left mPFC\",\n",
    "}\n",
    "\n",
    "SortedSpikesGroup().Units & group_key\n",
    "group_key = (SortedSpikesGroup & group_key).fetch1(\"KEY\")\n",
    "\n",
    "l_mpfc_spikes = SortedSpikesGroup().fetch_spike_data(group_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ccab3",
   "metadata": {},
   "source": [
    "#### Fetch position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca47a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 2\n",
    "dlc_centroid_params_name = \"four_paw_centroid\"\n",
    "pos_key = {\n",
    "    \"nwb_file_name\": nwb_copy_file_name,\n",
    "    \"epoch\": f\"{epoch}\", \n",
    "    \"dlc_model_params_name\": \"WtrackSep5\",\n",
    "    \"dlc_centroid_params_name\": dlc_centroid_params_name  \n",
    "}\n",
    "\n",
    "merge_id = (PositionOutput.DLCPosV1() & pos_key).fetch1(\"merge_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cc9a61",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "998f4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_position = (PositionOutput() & {\"merge_id\": merge_id}).fetch1_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7dd9f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single unit firing across all positions\n",
    "unit = 4\n",
    "spike_times = l_mpfc_spikes[unit]\n",
    "spike_times = spike_times\n",
    "spike_times = pd.Series([spike_time if spike_time < centroid_position.index[-1] else np.nan for spike_time in spike_times]).dropna().to_list()\n",
    "spike_positions = np.searchsorted(centroid_position.index.tolist(), spike_times)\n",
    "fig,ax = plt.subplots(layout = \"tight\")\n",
    "ax.scatter(centroid_position.position_x, centroid_position.position_y, s = 4, color = 'k', alpha = 0.03)\n",
    "ax.scatter(centroid_position.position_x.iloc[spike_positions], centroid_position.position_y.iloc[spike_positions], color = \"#1188d8\", s = 4, label = \"spikes\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa4ecd",
   "metadata": {},
   "source": [
    "### Extract trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all poisition data\n",
    "epoch2_centroid_df, epoch2_linear_df = get_centroid_and_linear_position(epoch=2,)\n",
    "epoch4_centroid_df, epoch4_linear_df = get_centroid_and_linear_position(epoch=4, )\n",
    "epoch6_centroid_df, epoch6_linear_df = get_centroid_and_linear_position(epoch=6,)\n",
    "epoch8_centroid_df, epoch8_linear_df = get_centroid_and_linear_position(epoch=8,)\n",
    "\n",
    "#get lick evenets and trial events\n",
    "lick_events_df = prepare_DIO_data(session_restriction=session_restrict, lick_event_threshold=2)\n",
    "trials_df = prepare_trial_data(lick_events_df)\n",
    "# merge position information with all trials\n",
    "target = pd.concat([epoch2_centroid_df, epoch2_linear_df], axis = 1)\n",
    "e2_trialized_position = merge_trial_df_with_target(target, trials_df)\n",
    "\n",
    "target = pd.concat([epoch4_centroid_df, epoch4_linear_df], axis = 1)\n",
    "e4_trialized_position = merge_trial_df_with_target(target, trials_df)\n",
    "\n",
    "target = pd.concat([epoch6_centroid_df, epoch6_linear_df], axis = 1)\n",
    "e6_trialized_position = merge_trial_df_with_target(target, trials_df)\n",
    "\n",
    "target = pd.concat([epoch8_centroid_df, epoch8_linear_df], axis = 1)\n",
    "e8_trialized_position = merge_trial_df_with_target(target, trials_df)\n",
    "\n",
    "\n",
    "trialized_position = pd.concat([e2_trialized_position, e4_trialized_position, e6_trialized_position, e8_trialized_position], axis = 0)\n",
    "\n",
    "maximum_trial_number_epoch_2 = e2_trialized_position[\"trial_number\"].max()\n",
    "maximum_trial_number_epoch_4 = e4_trialized_position[\"trial_number\"].max()\n",
    "maximum_trial_number_epoch_6 = e6_trialized_position[\"trial_number\"].max()\n",
    "maximum_trial_number_epoch_8 = e8_trialized_position[\"trial_number\"].max()\n",
    "\n",
    "trial_number_is_in_epoch_2 = (\n",
    "    trialized_position[\"trial_number\"] <= maximum_trial_number_epoch_2\n",
    ")\n",
    "\n",
    "trial_number_is_in_epoch_4 = (\n",
    "    (trialized_position[\"trial_number\"] > maximum_trial_number_epoch_2)\n",
    "    & (trialized_position[\"trial_number\"] <= maximum_trial_number_epoch_4)\n",
    ")\n",
    "\n",
    "trial_number_is_in_epoch_6 = (\n",
    "    (trialized_position[\"trial_number\"] > maximum_trial_number_epoch_4)\n",
    "    & (trialized_position[\"trial_number\"] <= maximum_trial_number_epoch_6)\n",
    ")\n",
    "\n",
    "trial_number_is_in_epoch_8 = (\n",
    "    (trialized_position[\"trial_number\"] > maximum_trial_number_epoch_6)\n",
    "    & (trialized_position[\"trial_number\"] <= maximum_trial_number_epoch_8)\n",
    ")\n",
    "\n",
    "trialized_position[\"epoch\"] = np.select(\n",
    "    condlist=[\n",
    "        trial_number_is_in_epoch_2,\n",
    "        trial_number_is_in_epoch_4,\n",
    "        trial_number_is_in_epoch_6,\n",
    "        trial_number_is_in_epoch_8,\n",
    "    ],\n",
    "    choicelist=[2, 4, 6, 8],\n",
    "    default=np.nan,\n",
    ")\n",
    "\n",
    "rows_with_unassigned_epoch = trialized_position[\"epoch\"].isna()\n",
    "print(\n",
    "    \"error: \",\n",
    "    trialized_position.loc[rows_with_unassigned_epoch, \"trial_number\"].unique(),\n",
    ")\n",
    "\n",
    "trialized_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save position data\n",
    "# out_dir = Path(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/position/\") \n",
    "# out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# dataframes = [e2_trialized_position, e4_trialized_position, e6_trialized_position, e8_trialized_position, trialized_position]\n",
    "# names = [\"e2_trialized_position\", \"e4_trialized_position\", \"e6_trialized_position\", \"e8_trialized_position\", \"trialized_position\"]\n",
    "\n",
    "# for name, df in zip(names, dataframes):\n",
    "#     df.to_csv(out_dir / f\"{name}.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16706d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from csv\n",
    "e2_trialized_position = pd.read_csv(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/position/e2_trialized_position.csv\", index_col = \"time\")\n",
    "e4_trialized_position = pd.read_csv(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/position/e4_trialized_position.csv\", index_col = \"time\")\n",
    "e6_trialized_position = pd.read_csv(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/position/e6_trialized_position.csv\", index_col = \"time\")\n",
    "e8_trialized_position = pd.read_csv(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/position/e8_trialized_position.csv\", index_col = \"time\")\n",
    "trialized_position = pd.read_csv(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/position/trialized_position.csv\", index_col = \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68610b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_frame_ind</th>\n",
       "      <th>position_x</th>\n",
       "      <th>position_y</th>\n",
       "      <th>orientation</th>\n",
       "      <th>velocity_x</th>\n",
       "      <th>velocity_y</th>\n",
       "      <th>speed</th>\n",
       "      <th>linear_position</th>\n",
       "      <th>track_segment_id</th>\n",
       "      <th>projected_x_position</th>\n",
       "      <th>...</th>\n",
       "      <th>trial_duration (s)</th>\n",
       "      <th>trial_label</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>trial_direction (previous, current, next)</th>\n",
       "      <th>left/right</th>\n",
       "      <th>speed_norm</th>\n",
       "      <th>trial_progress</th>\n",
       "      <th>trial_progress_distance</th>\n",
       "      <th>zone</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1620843475.612429380</th>\n",
       "      <td>83.000000000</td>\n",
       "      <td>130.841658279</td>\n",
       "      <td>64.731790850</td>\n",
       "      <td>-0.053658240</td>\n",
       "      <td>6.960407628</td>\n",
       "      <td>-0.472843676</td>\n",
       "      <td>6.976450064</td>\n",
       "      <td>316.186089589</td>\n",
       "      <td>2</td>\n",
       "      <td>130.840792016</td>\n",
       "      <td>...</td>\n",
       "      <td>31.147236824</td>\n",
       "      <td>error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('middle', 'left')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061862556</td>\n",
       "      <td>0.000412091</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>reward</td>\n",
       "      <td>2.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620843475.627006292</th>\n",
       "      <td>84.000000000</td>\n",
       "      <td>130.978969045</td>\n",
       "      <td>64.705678785</td>\n",
       "      <td>-0.042659516</td>\n",
       "      <td>6.028157129</td>\n",
       "      <td>-0.518424175</td>\n",
       "      <td>6.050408415</td>\n",
       "      <td>316.323341727</td>\n",
       "      <td>2</td>\n",
       "      <td>130.978043812</td>\n",
       "      <td>...</td>\n",
       "      <td>31.147236824</td>\n",
       "      <td>error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('middle', 'left')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053651030</td>\n",
       "      <td>0.000880091</td>\n",
       "      <td>0.000199549</td>\n",
       "      <td>reward</td>\n",
       "      <td>2.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      video_frame_ind    position_x   position_y  orientation  \\\n",
       "time                                                                            \n",
       "1620843475.612429380     83.000000000 130.841658279 64.731790850 -0.053658240   \n",
       "1620843475.627006292     84.000000000 130.978969045 64.705678785 -0.042659516   \n",
       "\n",
       "                      velocity_x   velocity_y       speed  linear_position  \\\n",
       "time                                                                         \n",
       "1620843475.612429380 6.960407628 -0.472843676 6.976450064    316.186089589   \n",
       "1620843475.627006292 6.028157129 -0.518424175 6.050408415    316.323341727   \n",
       "\n",
       "                      track_segment_id  projected_x_position  ...  \\\n",
       "time                                                          ...   \n",
       "1620843475.612429380                 2         130.840792016  ...   \n",
       "1620843475.627006292                 2         130.978043812  ...   \n",
       "\n",
       "                      trial_duration (s)  trial_label  trial_type  \\\n",
       "time                                                                \n",
       "1620843475.612429380        31.147236824        error         NaN   \n",
       "1620843475.627006292        31.147236824        error         NaN   \n",
       "\n",
       "                      trial_direction (previous, current, next)  left/right  \\\n",
       "time                                                                          \n",
       "1620843475.612429380                         ('middle', 'left')         NaN   \n",
       "1620843475.627006292                         ('middle', 'left')         NaN   \n",
       "\n",
       "                      speed_norm trial_progress trial_progress_distance  \\\n",
       "time                                                                      \n",
       "1620843475.612429380 0.061862556    0.000412091             0.000000000   \n",
       "1620843475.627006292 0.053651030    0.000880091             0.000199549   \n",
       "\n",
       "                        zone       epoch  \n",
       "time                                      \n",
       "1620843475.612429380  reward 2.000000000  \n",
       "1620843475.627006292  reward 2.000000000  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trialized_position.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trajectory for a single trial\n",
    "trial = 12\n",
    "\n",
    "t_start = trials_df.loc[trials_df[\"trial_number\"] == trial, \"trial_start\"].iloc[0]\n",
    "t_end = trials_df.loc[trials_df[\"trial_number\"] == trial, \"trial_end\"].iloc[0]\n",
    "\n",
    "# build boolean mask and select rows between the timestamps\n",
    "mask = (l_centroid_df.index > t_start) & (l_centroid_df.index < t_end)\n",
    "fig, ax = plt.subplots(layout = 'tight')\n",
    "plot_background_position(l_centroid_df, ax)\n",
    "l_centroid_df.loc[mask].plot.scatter(x = \"position_x\", y = \"position_y\", s = 8, ax = ax, c = l_centroid_df.loc[mask].index, cmap = \"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b08fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot various phases of a task\n",
    "trial = 10\n",
    "\n",
    "\n",
    "mask_reward = ( trialized_position[\"trial_number\"] == trial) & ( trialized_position[\"zone\"] == \"reward\")\n",
    "mask_run = ( trialized_position[\"trial_number\"] == trial) & ( trialized_position[\"zone\"] == \"run\")\n",
    "mask_turn = ( trialized_position[\"trial_number\"] == trial) & ( trialized_position[\"zone\"] == \"turn\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 15), layout = \"tight\")\n",
    "plot_background_position( trialized_position.iloc[::20], ax)\n",
    "# graph.plot_track_graph()\n",
    "s = 40\n",
    "trialized_position[mask_reward].plot.scatter(x = \"position_x\", y = \"position_y\", ax = ax,s = s )\n",
    "trialized_position[mask_turn].plot.scatter(x = \"position_x\", y = \"position_y\", ax = ax, s=s)\n",
    "trialized_position[mask_run].plot.scatter(x = \"position_x\", y = \"position_y\", ax = ax, s=s);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f312e61f",
   "metadata": {},
   "source": [
    "### Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "511ef193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of trials per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bd84ae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num trials in epoch 2:  50\n",
      "num trials in epoch 4:  56\n",
      "num trials in epoch 6:  59\n",
      "num trials in epoch 8:  56\n"
     ]
    }
   ],
   "source": [
    "print(\"num trials in epoch 2: \", (len(pd.unique(trialized_position[trialized_position[\"epoch\"]==2][\"trial_number\"]))))\n",
    "print(\"num trials in epoch 4: \", (len(pd.unique(trialized_position[trialized_position[\"epoch\"]==4][\"trial_number\"]))))\n",
    "print(\"num trials in epoch 6: \", (len(pd.unique(trialized_position[trialized_position[\"epoch\"]==6][\"trial_number\"]))))\n",
    "print(\"num trials in epoch 8: \", (len(pd.unique(trialized_position[trialized_position[\"epoch\"]==8][\"trial_number\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e27c67a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   3   4  53  54  56  64  98 104 122 124 126 136 154 156 168 170\n",
      " 173 186 204]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "#Incorrect trial numbers\n",
    "print(pd.unique(trialized_position[trialized_position[\"trial_label\"]==\"error\"][\"trial_number\"]))\n",
    "print(len(pd.unique(trialized_position[trialized_position[\"trial_label\"]==\"error\"][\"trial_number\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afc1d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot single trial trajectory and speed \n",
    "trial = 106\n",
    "mask = (trialized_position[\"trial_number\"]==trial) &( trialized_position[\"zone\"]==\"run\")\n",
    "timestamps = trialized_position[mask].index - trialized_position[mask].index.tolist()[0]\n",
    "with plt.style.context(\"dark_background\"):\n",
    "    fig, ax = plt.subplots(1, 2, layout = \"tight\", figsize = (20, 10))\n",
    "    plot_background_position(trialized_position, ax[0], background_color=\"white\")\n",
    "    trialized_position[mask].plot.scatter(x = \"position_x\", y = \"position_y\", ax = ax[0], c = \"speed\", s = 20, vmin = 0, vmax = 80)\n",
    "    ax[1].plot(timestamps, trialized_position[mask][\"speed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e6625",
   "metadata": {},
   "source": [
    "### Spingle unit spikes/behavior tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff3fca5",
   "metadata": {},
   "source": [
    "#### Fetch spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "778e4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_single_epoch_spikes(nwb_file_name: str,\n",
    "                              sorted_spikes_group_nane: str):\n",
    "    group_key = {\n",
    "        \"nwb_file_name\": nwb_file_name,\n",
    "        \"sorted_spikes_group_name\": sorted_spikes_group_nane\n",
    "    }\n",
    "    \n",
    "    SortedSpikesGroup.Units & group_key\n",
    "    \n",
    "    group_key = (SortedSpikesGroup & group_key).fetch1(\"KEY\")\n",
    "    return SortedSpikesGroup().fetch_spike_data(group_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01e57ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpfc_spikes = fetch_single_epoch_spikes(nwb_file_name=nwb_copy_file_name, sorted_spikes_group_nane=\"mPFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519fc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as .npz\n",
    "# out_dir = Path(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/final_spikes/\")\n",
    "# out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# np.savez_compressed(out_dir / \"mfpc_spikes.npz\", *mpfc_spikes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8913500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved spikes\n",
    "data = np.load(\"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/final_spikes/mfpc_spikes.npz\", allow_pickle=True)\n",
    "mpfc_spikes = [data[f\"arr_{i}\"] for i in range(len(data.files))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532ec1ec",
   "metadata": {},
   "source": [
    "#### Speed tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc228e",
   "metadata": {},
   "source": [
    "##### Compute tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fcd8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed y limits to fulfill fixed data aspect with adjustable data limits.\n",
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n"
     ]
    }
   ],
   "source": [
    "#rest vs run single unit comparison\n",
    "mean_fr_df = rest_vs_run_firing_rates(mpfc_spikes, trialized_position[(trialized_position[\"track_segment_id\"]==2)]\n",
    "                                      , speed_threshold=5, segment_threshold=3)\n",
    "plot_rest_vs_run_fr(mean_fr_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2772ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute tuning\n",
    "df = trialized_position.copy()\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "zones = [\"run\"]\n",
    "trial_types = [\"inbound\", \"outbound\"]\n",
    "track_segment_ids = [0, 1,2,3,4]\n",
    "epochs = [2,4]\n",
    "\n",
    "mask = ( df[\"trial_type\"].isin(trial_types)) & \\\n",
    "            ( df[\"track_segment_id\"].isin(track_segment_ids)) & \\\n",
    "                ( df[\"zone\"].isin(zones)) & \\\n",
    "                    df[\"epoch\"].isin(epochs)\n",
    "\n",
    "\n",
    "speed_tuning, speed_centers, lo, hi, slope_boot, curv_boot = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    spikes_list=spikes_list,\n",
    "    mask=mask,\n",
    "    column =\"speed\",\n",
    "    binning=\"sliding\",\n",
    "    window_width=20,\n",
    "    window_step=2,\n",
    "    tuner_min=0,\n",
    "    tuner_max=120,\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    "    peak_normalize = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "shape_by_unit, stats_by_unit = classify_tuning_shapes_from_bootstraps(\n",
    "    slope_boot,\n",
    "    curv_boot,\n",
    "    ci=0.95,\n",
    "    min_valid_boot=200,   \n",
    ")\n",
    "unit_shapes = pd.Series(shape_by_unit)\n",
    "speed_bell_unit_ids = unit_shapes[unit_shapes==\"bell\"].index.tolist()\n",
    "speed_increasing_unit_ids = unit_shapes[unit_shapes==\"increasing\"].index.tolist()\n",
    "speed_decreasing_unit_ids = unit_shapes[unit_shapes==\"decreasing\"].index.tolist()\n",
    "speed_u_unit_ids = unit_shapes[unit_shapes==\"U\"].index.tolist()\n",
    "speed_complex_unit_ids = unit_shapes[unit_shapes==\"flat/complex\"].index.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9ca8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot tuning grid\n",
    "plot_tuning_grid_bootstrap(\n",
    "    speed_tuning, lo, hi, speed_centers,\n",
    "    column=\"speed\",\n",
    "    n_units=80,\n",
    "    s=3,\n",
    "    color=\"tab:blue\",\n",
    "    peak_normalize = True,\n",
    "    linewidth = 2,\n",
    "    indices = None,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c1c149",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speed_tuning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 126\u001b[0m\n\u001b[1;32m    121\u001b[0m unit_to_plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    123\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    124\u001b[0m plot_unit_tuning_bootstrap(\n\u001b[1;32m    125\u001b[0m     unit_to_plot,\n\u001b[0;32m--> 126\u001b[0m     \u001b[43mspeed_tuning\u001b[49m, speed_centers, lo, hi,\n\u001b[1;32m    127\u001b[0m     ax\u001b[38;5;241m=\u001b[39max,\n\u001b[1;32m    128\u001b[0m     color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtab:blue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m     s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    130\u001b[0m     linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    131\u001b[0m     peak_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,   \n\u001b[1;32m    132\u001b[0m     xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    134\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m    135\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'speed_tuning' is not defined"
     ]
    }
   ],
   "source": [
    "#plot SINGLE UNIT tuning\n",
    "unit_to_plot = 70\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "plot_unit_tuning_bootstrap(\n",
    "    unit_to_plot,\n",
    "    speed_tuning, speed_centers, lo, hi,\n",
    "    ax=ax,\n",
    "    color=\"tab:blue\",\n",
    "    s=3,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,   \n",
    "    xlabel=\"speed\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2551236",
   "metadata": {},
   "source": [
    "##### Stability within an epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "766d908a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: [2.0, 4.0, 6.0, 8.0]\n",
      "epoch [2, 4]: n_trials=95 (early=47, late=48)\n"
     ]
    }
   ],
   "source": [
    "# --- Early vs Late - for PLOTTING one unit\n",
    "df = trialized_position.copy()\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "trial_types = [\"inbound\", \"outbound\"]\n",
    "track_segment_ids = [0, 1, 2, 3, 4]\n",
    "zones = [\"run\"]\n",
    "\n",
    "base_mask = (\n",
    "    df[\"trial_type\"].isin(trial_types)\n",
    "    & df[\"track_segment_id\"].isin(track_segment_ids)\n",
    "    & df[\"zone\"].isin(zones)\n",
    ")\n",
    "\n",
    "epoch_vals = sorted(df.loc[base_mask, \"epoch\"].dropna().unique())\n",
    "print(\"Epochs:\", epoch_vals)\n",
    "# e = epoch_vals[0]  \n",
    "e = [2,4]\n",
    "\n",
    "\n",
    "trials_e = np.sort(df.loc[base_mask & (df[\"epoch\"].isin(e)), \"trial_number\"].dropna().unique())\n",
    "M = len(trials_e)\n",
    "half = M // 2\n",
    "early_trials = trials_e[:half]\n",
    "late_trials  = trials_e[half:]\n",
    "print(f\"epoch {e}: n_trials={M} (early={len(early_trials)}, late={len(late_trials)})\")\n",
    "\n",
    "mask_early = base_mask & (df[\"epoch\"].isin(e)) & (df[\"trial_number\"].isin(early_trials))\n",
    "mask_late  = base_mask & (df[\"epoch\"].isin(e)) & (df[\"trial_number\"].isin(late_trials))\n",
    "\n",
    "\n",
    "column = \"speed\"     \n",
    "tuner_min = 10\n",
    "tuner_max = 120\n",
    "window_width = 20\n",
    "window_step  = 2\n",
    "\n",
    "common_kwargs = dict(\n",
    "    spikes_list=spikes_list,\n",
    "    column=column,\n",
    "    binning=\"sliding\",      \n",
    "    window_width=window_width,\n",
    "    window_step=window_step,\n",
    "    tuner_min=tuner_min,\n",
    "    tuner_max=tuner_max,\n",
    "    trial_column=\"trial_number\",\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    "    peak_normalize=True,        \n",
    ")\n",
    "\n",
    "tun_early, centers, lo_early, hi_early, *_ = compute_tuning_bootstrap_trials(\n",
    "    df, mask=mask_early, **common_kwargs\n",
    ")\n",
    "tun_late, centers2, lo_late, hi_late, *_ = compute_tuning_bootstrap_trials(\n",
    "    df, mask=mask_late, **common_kwargs\n",
    ")\n",
    "\n",
    "if not np.allclose(centers, centers2, equal_nan=True):\n",
    "    raise ValueError(\"Early/Late centers differ; ensure tuner_min/max and window_width/step are identical.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad047eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- plot one unit: overlay early and late on the same axis ----\n",
    "unit_to_plot = 70\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.2*2, 3.5*2))\n",
    "\n",
    "plot_unit_tuning_bootstrap(\n",
    "    unit_to_plot,\n",
    "    tun_early, centers, lo_early, hi_early,\n",
    "    ax=ax,\n",
    "    s=4,\n",
    "    linewidth=2,\n",
    "    peak_normalize=False,    # already normalized in compute_tuning_bootstrap_trials\n",
    "    color = \"tab:blue\",\n",
    "    xlabel=column,\n",
    "    title=None,\n",
    "    ci_alpha=0.18,\n",
    ")\n",
    "\n",
    "plot_unit_tuning_bootstrap(\n",
    "    unit_to_plot,\n",
    "    tun_late, centers, lo_late, hi_late,\n",
    "    ax=ax,\n",
    "    s=4,\n",
    "    linewidth=2,\n",
    "    color = \"tab:red\",\n",
    "    peak_normalize=False,    # already normalized in compute\n",
    "    xlabel=column,\n",
    "    title=None,\n",
    "    ci_alpha=0.18,\n",
    ")\n",
    "\n",
    "# ax.set_title(f\"Unit {unit_to_plot} (epoch {e}): early vs late (continuous bins)\")\n",
    "ax.legend([\"early\", \"early CI\", \"late\", \"late CI\"], frameon=False)  # optional; depends on your function behavior\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21cb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: [2.0, 4.0, 6.0, 8.0]\n",
      "8.0 52\n",
      "n_centers: 41\n"
     ]
    }
   ],
   "source": [
    "# --- compute early and late -- SLIDING WINDOW version\n",
    "\n",
    "df = trialized_position.copy()\n",
    "\n",
    "base_mask = (\n",
    "    (df[\"zone\"] == \"run\")\n",
    "    & (df[\"trial_type\"].isin([\"inbound\", \"outbound\"]))\n",
    ")\n",
    "\n",
    "epoch_vals = sorted(df.loc[base_mask, \"epoch\"].dropna().unique())\n",
    "print(\"Epochs:\", epoch_vals)\n",
    "\n",
    "e = epoch_vals[3]\n",
    "trials_e = np.sort(df.loc[base_mask & (df[\"epoch\"] == e), \"trial_number\"].dropna().unique())\n",
    "\n",
    "M = len(trials_e)\n",
    "print(e, M)\n",
    "half = M // 2\n",
    "contig_A = trials_e[:half]\n",
    "contig_B = trials_e[half:]\n",
    "\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "# --- sliding-window parameters (speed_norm is [0,1]) ---\n",
    "window_width = 0.20   # window size in speed_norm units\n",
    "window_step  = 0.02   # step size; smaller => more bins\n",
    "\n",
    "def tuning_for_trials(epoch_val, trial_subset, n_boot=200, seed=0, spikes_list = spikes_list, peak_normalize = True):\n",
    "    # Returns exactly (tuning, centers) so downstream unpacking works in all sections.\n",
    "    # (n_boot/seed are accepted for API compatibility but unused here.)\n",
    "    m = base_mask & (df[\"epoch\"] == epoch_val) & (df[\"trial_number\"].isin(trial_subset))\n",
    "    tuning, centers = compute_tuning(\n",
    "        df,\n",
    "        column=\"speed_norm\",\n",
    "        spikes_list=spikes_list,\n",
    "        n_bins=8,  # ignored for binning='sliding'\n",
    "        mask=m,\n",
    "        binning=\"sliding\",\n",
    "        window_width=window_width,\n",
    "        window_step=window_step,\n",
    "        tuner_min=0.0,\n",
    "        tuner_max=1.0,\n",
    "        peak_normalize=peak_normalize,\n",
    "    )\n",
    "    return tuning, centers\n",
    "\n",
    "tunA, centers, *_ = tuning_for_trials(e, contig_A)\n",
    "tunB, centersB, *_ = tuning_for_trials(e, contig_B)\n",
    "\n",
    "# sanity check: centers should match\n",
    "if not np.allclose(centers, centersB, equal_nan=True):\n",
    "    raise ValueError(\"Sliding-window centers differ between splits; check your binning params.\")\n",
    "\n",
    "units = sorted(tunA.keys())\n",
    "print(\"n_centers:\", len(centers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09d55835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contiguous split summary:\n",
      "  median corr: 0.7139763043966885\n",
      "  median nrmse: 0.2501487921678058\n",
      "  median peak shift (bins): 4.0\n",
      "  median mean-rate diff: 0.05355886022723155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labuser/miniforge3/envs/spyglass/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/home/labuser/miniforge3/envs/spyglass/lib/python3.10/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# metrics for contigous epoch split\n",
    "\n",
    "contiguous_curve_correlation = {}\n",
    "contiguous_curve_nrmse = {}\n",
    "contiguous_peak_shift_bins = {}\n",
    "contiguous_mean_rate_diff = {}\n",
    "\n",
    "for unit_id in units:\n",
    "    curve_first_half = tunA[unit_id]\n",
    "    curve_second_half = tunB[unit_id]\n",
    "\n",
    "    contiguous_curve_correlation[unit_id] = curve_corr(curve_first_half, curve_second_half)\n",
    "    contiguous_curve_nrmse[unit_id] = nrmse(curve_first_half, curve_second_half)\n",
    "    contiguous_peak_shift_bins[unit_id] = peak_bin_shift(curve_first_half, curve_second_half)\n",
    "    contiguous_mean_rate_diff[unit_id] = mean_rate_diff(curve_first_half, curve_second_half)\n",
    "\n",
    "print(\"Contiguous split summary:\")\n",
    "print(\"  median corr:\", np.nanmedian(list(contiguous_curve_correlation.values())))\n",
    "print(\"  median nrmse:\", np.nanmedian(list(contiguous_curve_nrmse.values())))\n",
    "print(\"  median peak shift (bins):\", np.nanmedian(list(contiguous_peak_shift_bins.values())))\n",
    "print(\"  median mean-rate diff:\", np.nanmedian(list(contiguous_mean_rate_diff.values())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91d2e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_split_runs = 1000\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "null_curve_correlation = {unit_id: [] for unit_id in units}\n",
    "null_curve_nrmse = {unit_id: [] for unit_id in units}\n",
    "null_peak_shift_bins = {unit_id: [] for unit_id in units}\n",
    "null_mean_rate_diff = {unit_id: [] for unit_id in units}\n",
    "\n",
    "for run_idx in range(random_split_runs):\n",
    "    permuted_trials = rng.permutation(trials_e)\n",
    "    trials_split_A = permuted_trials[:half]\n",
    "    trials_split_B = permuted_trials[half:]\n",
    "\n",
    "    tuning_A, _, *_ = tuning_for_trials(e, trials_split_A, n_boot=200, seed=run_idx + 1)\n",
    "    tuning_B, _, *_ = tuning_for_trials(e, trials_split_B, n_boot=200, seed=1000 + run_idx + 1)\n",
    "\n",
    "    for unit_id in units:\n",
    "        curve_A = tuning_A[unit_id]\n",
    "        curve_B = tuning_B[unit_id]\n",
    "\n",
    "        null_curve_correlation[unit_id].append(curve_corr(curve_A, curve_B))\n",
    "        null_curve_nrmse[unit_id].append(nrmse(curve_A, curve_B))\n",
    "        null_peak_shift_bins[unit_id].append(peak_bin_shift(curve_A, curve_B))\n",
    "        null_mean_rate_diff[unit_id].append(mean_rate_diff(curve_A, curve_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f63a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9386693370152308"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit = 70\n",
    "print(contiguous_curve_correlation[unit])\n",
    "print(contiguous_curve_nrmse[unit])\n",
    "print(contiguous_peak_shift_bins[unit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d976c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- per-unit p-values (contiguous vs null) ----------\n",
    "# For corr: low is worse -> p = P(null <= contig)\n",
    "# For others: high is worse -> p = P(null >= contig)\n",
    "p_corr = {}\n",
    "p_nrmse = {}\n",
    "p_peak_shift = {}\n",
    "p_mean_rate_diff = {}\n",
    "\n",
    "for unit_id in units:\n",
    "    null_c = np.asarray(null_curve_correlation[unit_id], float)\n",
    "    null_e = np.asarray(null_curve_nrmse[unit_id], float)\n",
    "    null_p = np.asarray(null_peak_shift_bins[unit_id], float)\n",
    "    null_m = np.asarray(null_mean_rate_diff[unit_id], float)\n",
    "\n",
    "    null_c = null_c[np.isfinite(null_c)]\n",
    "    null_e = null_e[np.isfinite(null_e)]\n",
    "    null_p = null_p[np.isfinite(null_p)]\n",
    "    null_m = null_m[np.isfinite(null_m)]\n",
    "\n",
    "    contig_c = contiguous_curve_correlation[unit_id]\n",
    "    contig_e = contiguous_curve_nrmse[unit_id]\n",
    "    contig_p = contiguous_peak_shift_bins[unit_id]\n",
    "    contig_m = contiguous_mean_rate_diff[unit_id]\n",
    "    p_corr[unit_id] = np.nan if null_c.size == 0 else float(np.mean(null_c <= contig_c))\n",
    "    p_nrmse[unit_id] = np.nan if null_e.size == 0 else float(np.mean(null_e >= contig_e))\n",
    "    p_peak_shift[unit_id] = np.nan if null_p.size == 0 else float(np.mean(null_p >= contig_p))\n",
    "    p_mean_rate_diff[unit_id] = np.nan if null_m.size == 0 else float(np.mean(null_m >= contig_m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b99b3ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Within-epoch labels (alpha=0.05):\n",
      "  stationary: 255\n",
      "  drifting: 7\n",
      "  insufficient: 1\n",
      "\n",
      "Drift type:\n",
      "  shape drift: 4\n",
      "  rate drift: 5\n",
      "\n",
      "Null baseline (median across units of per-unit median):\n",
      "  corr: 0.7060447330243675\n",
      "  nrmse: 0.24652259777444918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3420873/2753853428.py:40: RuntimeWarning: All-NaN slice encountered\n",
      "  median_of_unit_median_null_corr = np.nanmedian([np.nanmedian(null_curve_correlation[u]) for u in units])\n"
     ]
    }
   ],
   "source": [
    "#label units\n",
    "alpha = 0.05\n",
    "\n",
    "within_epoch_shape_drift = {}\n",
    "within_epoch_rate_drift = {}\n",
    "within_epoch_status = {}\n",
    "\n",
    "for unit_id in units:\n",
    "    if (not np.isfinite(p_corr[unit_id]) or\n",
    "        not np.isfinite(p_nrmse[unit_id]) or\n",
    "        not np.isfinite(p_peak_shift[unit_id]) or\n",
    "        not np.isfinite(p_mean_rate_diff[unit_id])):\n",
    "        within_epoch_status[unit_id] = \"insufficient\"\n",
    "        within_epoch_shape_drift[unit_id] = False\n",
    "        within_epoch_rate_drift[unit_id] = False\n",
    "        continue\n",
    "\n",
    "    # shape metrics: correlation and peak shift\n",
    "    shape_drift = (p_corr[unit_id] < alpha) and (p_peak_shift[unit_id] < alpha)\n",
    "    # rate metrics: rate diff and nrmse\n",
    "    rate_drift = (p_nrmse[unit_id] < alpha) and (p_mean_rate_diff[unit_id] < alpha)\n",
    "\n",
    "    within_epoch_shape_drift[unit_id] = shape_drift\n",
    "    within_epoch_rate_drift[unit_id] = rate_drift\n",
    "\n",
    "    if shape_drift or rate_drift:\n",
    "        within_epoch_status[unit_id] = \"drifting\"\n",
    "    else:\n",
    "        within_epoch_status[unit_id] = \"stationary\"\n",
    "\n",
    "print(\"\\nWithin-epoch labels (alpha=0.05):\")\n",
    "print(\"  stationary:\", sum(v == \"stationary\" for v in within_epoch_status.values()))\n",
    "print(\"  drifting:\", sum(v == \"drifting\" for v in within_epoch_status.values()))\n",
    "print(\"  insufficient:\", sum(v == \"insufficient\" for v in within_epoch_status.values()))\n",
    "\n",
    "print(\"\\nDrift type:\")\n",
    "print(\"  shape drift:\", sum(within_epoch_shape_drift.values()))\n",
    "print(\"  rate drift:\", sum(within_epoch_rate_drift.values()))\n",
    "\n",
    "median_of_unit_median_null_corr = np.nanmedian([np.nanmedian(null_curve_correlation[u]) for u in units])\n",
    "median_of_unit_median_null_nrmse = np.nanmedian([np.nanmedian(null_curve_nrmse[u]) for u in units])\n",
    "\n",
    "print(\"\\nNull baseline (median across units of per-unit median):\")\n",
    "print(\"  corr:\", median_of_unit_median_null_corr)\n",
    "print(\"  nrmse:\", median_of_unit_median_null_nrmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f3982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EXAMPLE PLOT for correlation (lower tail) ---\n",
    "unit_to_show = units[70]  # pick unit\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7.52*2.5, 2.82*2.5))\n",
    "illustrate_pvalue_rule_for_unit(\n",
    "    unit_to_show,\n",
    "    null_metric_dict=null_curve_correlation,\n",
    "    contig_metric_dict=contiguous_curve_correlation,\n",
    "    alpha=0.05,\n",
    "    direction=\"lower\",\n",
    "    xlabel=\"null correlation\",\n",
    "    ax=ax,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662b9967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: [2.0, 4.0, 6.0, 8.0]\n",
      "2.0\n",
      "epoch 2.0: stationary=190 drifting=61 insufficient=12\n",
      "4.0\n",
      "epoch 4.0: stationary=198 drifting=60 insufficient=5\n",
      "6.0\n",
      "epoch 6.0: stationary=185 drifting=72 insufficient=6\n",
      "8.0\n",
      "epoch 8.0: stationary=248 drifting=11 insufficient=4\n",
      "Analyzed epochs: [2.0, 4.0, 6.0, 8.0]\n",
      "Overall (>=3/4 rule):\n",
      "  required_stationary: 3 out of 4\n",
      "  stable: 204\n",
      "  drifting: 52\n",
      "  insufficient: 7\n"
     ]
    }
   ],
   "source": [
    "def peak_shift_x(curve_a, curve_b, centers, min_bins=3):\n",
    "    curve_a = np.asarray(curve_a, float)``\n",
    "    curve_b = np.asarray(curve_b, float)\n",
    "    x = np.asarray(centers, float)\n",
    "\n",
    "    finite = np.isfinite(curve_a) & np.isfinite(curve_b) & np.isfinite(x)\n",
    "    if finite.sum() < min_bins:\n",
    "        return np.nan\n",
    "\n",
    "    idxs = np.where(finite)[0]\n",
    "    ia = idxs[np.argmax(curve_a[finite])]\n",
    "    ib = idxs[np.argmax(curve_b[finite])]\n",
    "    return float(abs(x[ia] - x[ib]))\n",
    "\n",
    "\n",
    "df = trialized_position.copy()\n",
    "df = df.sort_index()  \n",
    "\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "base_mask = (\n",
    "    (df[\"zone\"] == \"run\")\n",
    "    & (df[\"trial_type\"].isin([\"inbound\", \"outbound\"]))\n",
    ")\n",
    "\n",
    "# epochs to analyze\n",
    "epoch_vals = sorted(df.loc[base_mask, \"epoch\"].dropna().unique())\n",
    "print(\"Epochs:\", epoch_vals)\n",
    "\n",
    "column = \"speed_norm\"\n",
    "window_width = 0.20\n",
    "window_step = 0.02\n",
    "tuner_min = 0.0\n",
    "tuner_max = 1.0\n",
    "\n",
    "# stability test parameters\n",
    "alpha = 0.05\n",
    "random_split_runs = 50\n",
    "min_trials_per_epoch = 6  \n",
    "min_units_ok_bins = 3   \n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "\n",
    "def tuning_for_trials(\n",
    "    epoch_val,\n",
    "    trial_subset,\n",
    "    n_boot=200,\n",
    "    seed=0,\n",
    "    spikes_list=spikes_list,\n",
    "    peak_normalize=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Drop-in replacement: `epoch_val` can be a scalar (single epoch) OR any list-like\n",
    "    (list/tuple/set/np.ndarray/pd.Series/pd.Index) of epochs.\n",
    "    \"\"\"\n",
    "    # Normalize numpy 0-d arrays (e.g. np.array(3.0)) into a scalar\n",
    "    if isinstance(epoch_val, np.ndarray) and epoch_val.ndim == 0:\n",
    "        epoch_val = epoch_val.item()\n",
    "\n",
    "    # Decide whether epoch_val is \"list-like\" (multiple epochs) vs scalar (single epoch)\n",
    "    epoch_is_list_like = False\n",
    "    if isinstance(epoch_val, np.ndarray):\n",
    "        epoch_is_list_like = epoch_val.ndim > 0\n",
    "    elif isinstance(epoch_val, (str, bytes)):\n",
    "        epoch_is_list_like = False\n",
    "    elif np.isscalar(epoch_val):\n",
    "        epoch_is_list_like = False\n",
    "    else:\n",
    "        # pandas Index/Series, lists, tuples, sets, etc.\n",
    "        try:\n",
    "            iter(epoch_val)\n",
    "            epoch_is_list_like = True\n",
    "        except TypeError:\n",
    "            epoch_is_list_like = False\n",
    "\n",
    "    if epoch_is_list_like:\n",
    "        epoch_mask = df[\"epoch\"].isin(list(epoch_val))\n",
    "    else:\n",
    "        epoch_mask = df[\"epoch\"] == epoch_val\n",
    "\n",
    "    m = base_mask & epoch_mask & df[\"trial_number\"].isin(trial_subset)\n",
    "\n",
    "    tuning, centers = compute_tuning(\n",
    "        df,\n",
    "        column=column,\n",
    "        spikes_list=spikes_list,\n",
    "        n_bins=8,  # ignored for binning='sliding'\n",
    "        mask=m,\n",
    "        binning=\"sliding\",\n",
    "        window_width=window_width,\n",
    "        window_step=window_step,\n",
    "        tuner_min=tuner_min,\n",
    "        tuner_max=tuner_max,\n",
    "        peak_normalize=peak_normalize,\n",
    "    )\n",
    "    return tuning, centers\n",
    "\n",
    "\n",
    "\n",
    "per_epoch_results = {}   # epoch -> dict with per-unit stats/status\n",
    "\n",
    "for e in epoch_vals:\n",
    "    print(e)\n",
    "    trials_e = np.sort(df.loc[base_mask & (df[\"epoch\"] == e), \"trial_number\"].dropna().unique())\n",
    "    M = len(trials_e)\n",
    "\n",
    "    if M < min_trials_per_epoch:\n",
    "        print(f\"epoch {e}: skipped (only {M} trials)\")\n",
    "        continue\n",
    "\n",
    "    half = M // 2\n",
    "    contig_A = trials_e[:half]\n",
    "    contig_B = trials_e[half:]\n",
    "\n",
    "    # contiguous split tunings (peak-normalized so metrics focus on shape)\n",
    "    tunA, centers = tuning_for_trials(e, contig_A, peak_normalize=True)\n",
    "    tunB, centersB = tuning_for_trials(e, contig_B, peak_normalize=True)\n",
    "\n",
    "    if not np.allclose(centers, centersB, equal_nan=True):\n",
    "        raise ValueError(f\"epoch {e}: centers differ between splits; check sliding bin params.\")\n",
    "\n",
    "    units = sorted(tunA.keys())\n",
    "\n",
    "    # observed contiguous metrics\n",
    "    contig_corr = {}\n",
    "    contig_nrmse = {}\n",
    "    contig_peakx = {}\n",
    "\n",
    "    for u in units:\n",
    "        contig_corr[u] = curve_corr(tunA[u], tunB[u], min_bins=min_units_ok_bins)\n",
    "        contig_nrmse[u] = nrmse(tunA[u], tunB[u], min_bins=min_units_ok_bins)\n",
    "        contig_peakx[u] = peak_shift_x(tunA[u], tunB[u], centers, min_bins=min_units_ok_bins)\n",
    "\n",
    "    # null distributions per unit\n",
    "    null_corr = {u: [] for u in units}\n",
    "    null_nrmse = {u: [] for u in units}\n",
    "    null_peakx = {u: [] for u in units}\n",
    "\n",
    "    for run_idx in range(random_split_runs):\n",
    "        perm = rng.permutation(trials_e)\n",
    "        A = perm[:half]\n",
    "        B = perm[half:]\n",
    "\n",
    "        tA, cA = tuning_for_trials(e, A, peak_normalize=True)\n",
    "        tB, cB = tuning_for_trials(e, B, peak_normalize=True)\n",
    "\n",
    "        if not np.allclose(cA, centers, equal_nan=True) or not np.allclose(cB, centers, equal_nan=True):\n",
    "            raise ValueError(f\"epoch {e}: centers mismatch inside null loop; check fixed tuner_min/max.\")\n",
    "\n",
    "        for u in units:\n",
    "            null_corr[u].append(curve_corr(tA[u], tB[u], min_bins=min_units_ok_bins))\n",
    "            null_nrmse[u].append(nrmse(tA[u], tB[u], min_bins=min_units_ok_bins))\n",
    "            null_peakx[u].append(peak_shift_x(tA[u], tB[u], centers, min_bins=min_units_ok_bins))\n",
    "\n",
    "    # p-values (same logic as your original, adapted to peak_shift_x)\n",
    "    p_corr = {}\n",
    "    p_nrmse = {}\n",
    "    p_peakx = {}\n",
    "\n",
    "    for u in units:\n",
    "        nc = np.asarray(null_corr[u], float);   nc = nc[np.isfinite(nc)]\n",
    "        ne = np.asarray(null_nrmse[u], float);  ne = ne[np.isfinite(ne)]\n",
    "        npk = np.asarray(null_peakx[u], float); npk = npk[np.isfinite(npk)]\n",
    "\n",
    "        oc = contig_corr[u]\n",
    "        oe = contig_nrmse[u]\n",
    "        op = contig_peakx[u]\n",
    "\n",
    "        # corr: low is worse -> p = P(null <= contig)\n",
    "        p_corr[u]  = np.nan if nc.size == 0 or not np.isfinite(oc) else float(np.mean(nc <= oc))\n",
    "        # nrmse: high is worse -> p = P(null >= contig)\n",
    "        p_nrmse[u] = np.nan if ne.size == 0 or not np.isfinite(oe) else float(np.mean(ne >= oe))\n",
    "        # peak shift (x): high is worse -> p = P(null >= contig)\n",
    "        p_peakx[u] = np.nan if npk.size == 0 or not np.isfinite(op) else float(np.mean(npk >= op))\n",
    "\n",
    "    # classify per unit within this epoch\n",
    "    status = {}\n",
    "    shape_drift = {}\n",
    "    rate_drift = {}\n",
    "\n",
    "    for u in units:\n",
    "        if (not np.isfinite(p_corr[u]) or not np.isfinite(p_nrmse[u]) or not np.isfinite(p_peakx[u])):\n",
    "            status[u] = \"insufficient\"\n",
    "            shape_drift[u] = False\n",
    "            rate_drift[u] = False\n",
    "            continue\n",
    "\n",
    "        # shape drift: corr low AND peak shift high\n",
    "        shape_drift[u] = (p_corr[u] < alpha) and (p_peakx[u] < alpha)\n",
    "        # â€œrate driftâ€:\n",
    "        rate_drift[u] = (p_nrmse[u] < alpha)\n",
    "\n",
    "        status[u] = \"drifting\" if (shape_drift[u] or rate_drift[u]) else \"stationary\"\n",
    "\n",
    "    per_epoch_results[e] = dict(\n",
    "        centers=centers,\n",
    "        contig_corr=contig_corr,\n",
    "        contig_nrmse=contig_nrmse,\n",
    "        contig_peakx=contig_peakx,\n",
    "        null_corr=null_corr,\n",
    "        null_nrmse=null_nrmse,\n",
    "        null_peakx=null_peakx,\n",
    "        p_corr=p_corr,\n",
    "        p_nrmse=p_nrmse,\n",
    "        p_peakx=p_peakx,\n",
    "        shape_drift=shape_drift,\n",
    "        rate_drift=rate_drift,\n",
    "        status=status,\n",
    "        n_trials=M,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"epoch {e}: stationary={sum(v=='stationary' for v in status.values())} \"\n",
    "        f\"drifting={sum(v=='drifting' for v in status.values())} \"\n",
    "        f\"insufficient={sum(v=='insufficient' for v in status.values())}\"\n",
    "    )\n",
    "\n",
    "# --- aggregate across epochs: stable if stationary in >=3/4 epochs ---\n",
    "\n",
    "analyzed_epochs = sorted(per_epoch_results.keys())\n",
    "print(\"Analyzed epochs:\", analyzed_epochs)\n",
    "\n",
    "if len(analyzed_epochs) == 0:\n",
    "    raise ValueError(\"No epochs analyzed (maybe too few trials per epoch).\")\n",
    "\n",
    "# units considered = intersection across analyzed epochs\n",
    "unit_sets = [set(per_epoch_results[e][\"status\"].keys()) for e in analyzed_epochs]\n",
    "units_all = sorted(set.intersection(*unit_sets))\n",
    "\n",
    "n_epochs = len(analyzed_epochs)\n",
    "\n",
    "# >=3/4 rule (generalized): require ceil(0.75 * n_epochs) stationary epochs\n",
    "required_stationary = int(np.ceil(0.75 * n_epochs))   # for 4 epochs => 3\n",
    "max_insufficient = n_epochs - required_stationary      # for 4 epochs => 1 (optional policy)\n",
    "\n",
    "overall_status = {}\n",
    "overall_stationary_count = {}\n",
    "\n",
    "for u in units_all:\n",
    "    st = [per_epoch_results[e][\"status\"][u] for e in analyzed_epochs]\n",
    "    n_stationary = sum(x == \"stationary\" for x in st)\n",
    "    n_insufficient = sum(x == \"insufficient\" for x in st)\n",
    "\n",
    "    overall_stationary_count[u] = n_stationary\n",
    "\n",
    "    # policy: if too many insufficient epochs, call overall insufficient\n",
    "    if n_insufficient > max_insufficient:\n",
    "        overall_status[u] = \"insufficient\"\n",
    "    elif n_stationary >= required_stationary:\n",
    "        overall_status[u] = \"stable\"\n",
    "    else:\n",
    "        overall_status[u] = \"drifting\"\n",
    "\n",
    "stable_units = [u for u in units_all if overall_status[u] == \"stable\"]\n",
    "unstable_units = [u for u in units_all if overall_status[u] == \"drifting\"]\n",
    "\n",
    "print(\"Overall (>=3/4 rule):\")\n",
    "print(\"  required_stationary:\", required_stationary, \"out of\", n_epochs)\n",
    "print(\"  stable:\", sum(v == \"stable\" for v in overall_status.values()))\n",
    "print(\"  drifting:\", sum(v == \"drifting\" for v in overall_status.values()))\n",
    "print(\"  insufficient:\", sum(v == \"insufficient\" for v in overall_status.values()))\n",
    "\n",
    "# `overall_status` is your final dict of labels\n",
    "# `stable_units` is the list of units stable in >=3/4 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "670df372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HISTOGRAM\n",
    "\n",
    "labels = list(overall_status.values())\n",
    "cats = [\"stable\", \"drifting\", \"insufficient\"]\n",
    "counts = {c: labels.count(c) for c in cats}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "ax.bar(cats, [counts[c] for c in cats], color=[colors[0], colors[1], colors[2]], alpha=0.9)\n",
    "ax.set_ylabel(\"Number of units\")\n",
    "# ax.set_title(\"Overall stability labels (>=3/4 rule)\")\n",
    "\n",
    "# annotate counts on bars\n",
    "for i, c in enumerate(cats):\n",
    "    ax.text(i, counts[c] + 0.5, str(counts[c]), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7bc188",
   "metadata": {},
   "source": [
    "##### Stability across epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c039608",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_epochs = epoch_vals[:2]\n",
    "last_epochs  = epoch_vals[2:]\n",
    "\n",
    "trials_first = np.sort(df.loc[base_mask & (df[\"epoch\"].isin(first_epochs)), \"trial_number\"].dropna().unique())\n",
    "trials_last  = np.sort(df.loc[base_mask & (df[\"epoch\"].isin(last_epochs)),  \"trial_number\"].dropna().unique())\n",
    "\n",
    "tuning_first, _, *_ = tuning_for_trials(first_epochs, trials_first, n_boot=200, seed=202, spikes_list = spikes_list)\n",
    "tuning_last,  _, *_ = tuning_for_trials(last_epochs,  trials_last,  n_boot=200, seed=808, spikes_list = spikes_list )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac5f6813",
   "metadata": {},
   "outputs": [],
   "source": [
    "between_epoch_corr = {}\n",
    "between_epoch_nrmse = {}\n",
    "between_epoch_peak_shift = {}\n",
    "# between_epoch_mean_rate_diff = {}\n",
    "units = sorted(tuning_first.keys())\n",
    "\n",
    "for unit_id in stable_units:\n",
    "    curve_first = tuning_first[unit_id]\n",
    "    curve_last  = tuning_last[unit_id]\n",
    "\n",
    "    between_epoch_corr[unit_id] = curve_corr(curve_first, curve_last)\n",
    "    between_epoch_nrmse[unit_id] = nrmse(curve_first, curve_last)\n",
    "    between_epoch_peak_shift[unit_id] = peak_bin_shift(curve_first, curve_last)\n",
    "    # between_epoch_mean_rate_diff[unit_id] = mean_rate_diff(curve_first, curve_last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b53d2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_between_corr = {}\n",
    "p_between_nrmse = {}\n",
    "p_between_peak = {}\n",
    "p_between_mean = {}\n",
    "\n",
    "for unit_id in stable_units:\n",
    "    null_c = np.asarray(null_curve_correlation[unit_id], float)\n",
    "    null_e = np.asarray(null_curve_nrmse[unit_id], float)\n",
    "    null_p = np.asarray(null_peak_shift_bins[unit_id], float)\n",
    "    null_m = np.asarray(null_mean_rate_diff[unit_id], float)\n",
    "\n",
    "    null_c = null_c[np.isfinite(null_c)]\n",
    "    null_e = null_e[np.isfinite(null_e)]\n",
    "    null_p = null_p[np.isfinite(null_p)]\n",
    "    null_m = null_m[np.isfinite(null_m)]\n",
    "\n",
    "    obs_c = between_epoch_corr[unit_id]\n",
    "    obs_e = between_epoch_nrmse[unit_id]\n",
    "    obs_p = between_epoch_peak_shift[unit_id]\n",
    "    # obs_m = between_epoch_mean_rate_diff[unit_id]\n",
    "\n",
    "    p_between_corr[unit_id]  = np.nan if null_c.size == 0 else float(np.mean(null_c <= obs_c))\n",
    "    p_between_nrmse[unit_id] = np.nan if null_e.size == 0 else float(np.mean(null_e >= obs_e))\n",
    "    p_between_peak[unit_id]  = np.nan if null_p.size == 0 else float(np.mean(null_p >= obs_p))\n",
    "    # p_between_mean[unit_id]  = np.nan if null_m.size == 0 else float(np.mean(null_m >= obs_m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80d9a4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Across-epoch stable: 180\n",
      "Across-epoch changed: 24\n",
      "Across-epoch insufficient: 0\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "across_epoch_shape_change = {}\n",
    "across_epoch_rate_change = {}\n",
    "across_epoch_status = {}\n",
    "\n",
    "for unit_id in stable_units:\n",
    "    if (not np.isfinite(p_between_corr[unit_id]) or\n",
    "        not np.isfinite(p_between_peak[unit_id]) or\n",
    "        not np.isfinite(p_between_nrmse[unit_id])):\n",
    "        # not np.isfinite(p_between_mean[unit_id])):\n",
    "        across_epoch_status[unit_id] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    shape_change = (p_between_corr[unit_id] < alpha) and (p_between_peak[unit_id] < alpha)\n",
    "    rate_change  = (p_between_nrmse[unit_id] < alpha) \n",
    "\n",
    "    across_epoch_shape_change[unit_id] = shape_change\n",
    "    across_epoch_rate_change[unit_id] = rate_change\n",
    "\n",
    "    across_epoch_status[unit_id] = \"changed\" if (shape_change or rate_change) else \"stable\"\n",
    "\n",
    "print(\"Across-epoch stable:\", sum(v==\"stable\" for v in across_epoch_status.values()))\n",
    "print(\"Across-epoch changed:\", sum(v==\"changed\" for v in across_epoch_status.values()))\n",
    "print(\"Across-epoch insufficient:\", sum(v==\"insufficient\" for v in across_epoch_status.values()))\n",
    "\n",
    "across_stable_units = np.where(np.array([value for value in across_epoch_status.values()]) == 'stable')\n",
    "across_drifting_units = np.where(np.array([value for value in across_epoch_status.values()]) != 'stable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d79f1c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: ([2, 4], [6, 8])\n"
     ]
    }
   ],
   "source": [
    "# --- drop-in: plot for all epochs with CONTINUOUS (sliding-window) bins ---\n",
    "\n",
    "df = trialized_position\n",
    "\n",
    "base_mask = (\n",
    "    (df[\"zone\"] == \"run\")\n",
    "    & (df[\"trial_type\"].isin([\"inbound\", \"outbound\"]))\n",
    "    # & (df[\"epoch\"].isin([2, 8]))\n",
    ")\n",
    "\n",
    "epoch_vals = ([2,4], [6,8])\n",
    "print(\"Epochs:\", epoch_vals)\n",
    "\n",
    "# continuous (sliding-window) binning for speed_norm in [0, 1]\n",
    "window_width = 0.20   # window size in speed_norm units\n",
    "window_step  = 0.02   # step size; smaller => more bins\n",
    "tuner_min = 0.0\n",
    "tuner_max = 1.0\n",
    "\n",
    "results_by_epoch = {}\n",
    "\n",
    "for ind, e in enumerate(epoch_vals):\n",
    "    mask_e = base_mask & (df[\"epoch\"].isin(e))\n",
    "\n",
    "    tuning, centers, lo, hi, slope_boot, curv_boot = compute_tuning_bootstrap_trials(\n",
    "        df,\n",
    "        column=\"speed_norm\",\n",
    "        spikes_list=spikes_list,\n",
    "        n_bins=8,  # ignored when binning='sliding'\n",
    "        mask=mask_e,\n",
    "        trial_column=\"trial_number\",\n",
    "        n_boot=500,\n",
    "        ci=0.95,\n",
    "        random_state=0,\n",
    "        binning=\"sliding\",\n",
    "        window_width=window_width,\n",
    "        window_step=window_step,\n",
    "        tuner_min=tuner_min,\n",
    "        tuner_max=tuner_max,\n",
    "        peak_normalize=True,  \n",
    "    )\n",
    "\n",
    "    results_by_epoch[ind] = dict(\n",
    "        tuning=tuning, centers=centers, lo=lo, hi=hi,\n",
    "        slope_boot=slope_boot, curv_boot=curv_boot,\n",
    "        mask=mask_e,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eff978c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot grids\n",
    "for ind,e in enumerate(epoch_vals):\n",
    "    r = results_by_epoch[ind]\n",
    "    plot_tuning_grid_bootstrap(\n",
    "        r[\"tuning\"], r[\"lo\"], r[\"hi\"], r[\"centers\"],\n",
    "        column=\"speed_norm\",\n",
    "        n_units=50,\n",
    "        label=f\"epoch {e}\",\n",
    "        indices= across_drifting_units[0].tolist(),\n",
    "        s = 5, \n",
    "        linewidth = 2,\n",
    "        peak_normalize = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f243a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAM\n",
    "# (assumed already computed)\n",
    "\n",
    "labels = list(across_epoch_status.values())\n",
    "cats = [\"stable\", \"changed\", \"insufficient\"]\n",
    "counts = {c: labels.count(c) for c in cats}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.2*2.5, 3.2*2.5))\n",
    "\n",
    "ax.bar(cats, [counts[c] for c in cats], color=[colors[0], colors[1], colors[2]], alpha=0.9)\n",
    "ax.set_ylabel(\"Number of units\")\n",
    "# ax.set_title(\"Overall stability labels (>=3/4 rule)\")\n",
    "\n",
    "# annotate counts on bars\n",
    "for i, c in enumerate(cats):\n",
    "    ax.text(i, counts[c] + 0.5, str(counts[c]), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "293749cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x70e0ddc57fa0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot single unit spikes: rest vs run\n",
    "unit = 8\n",
    "\n",
    "mask_stat = trialized_position[\"speed\"]<5\n",
    "mask_running = trialized_position[\"speed\"]>5\n",
    "\n",
    "\n",
    "spike_idx = np.searchsorted(trialized_position.index.tolist(), spikes_list[unit][spikes_list[unit]>trialized_position.index[0]])\n",
    "spike_idx_stat = np.searchsorted(trialized_position[mask_stat].index.tolist(), spikes_list[unit])\n",
    "spike_idx_running = np.searchsorted(trialized_position[mask_running].index.tolist(), spikes_list[unit])\n",
    "fig, ax = plt.subplots(layout = \"tight\")\n",
    "plot_background_position(trialized_position, ax)\n",
    "ax.scatter(trialized_position.position_x.iloc[spike_idx_stat], trialized_position.position_y.iloc[spike_idx_stat], s = 10, color = \"y\", label = \"speed < 3 cm/s\")\n",
    "ax.scatter(trialized_position.position_x.iloc[spike_idx_running], trialized_position.position_y.iloc[spike_idx_running], s = 10, color = \"r\", label = \"speed > 3 cm/s\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7f0e3",
   "metadata": {},
   "source": [
    "#### Direction tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddee0fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>n_trials_a</th>\n",
       "      <th>n_trials_b</th>\n",
       "      <th>fr_mean_a</th>\n",
       "      <th>fr_mean_b</th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "      <th>preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>9.244446606</td>\n",
       "      <td>18.547881245</td>\n",
       "      <td>946.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.665399355</td>\n",
       "      <td>1.504843338</td>\n",
       "      <td>1913.500000000</td>\n",
       "      <td>0.000181030</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>3.029891164</td>\n",
       "      <td>11.525432241</td>\n",
       "      <td>533.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.625277785</td>\n",
       "      <td>3.935882401</td>\n",
       "      <td>1282.500000000</td>\n",
       "      <td>0.000000003</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.541099277</td>\n",
       "      <td>8.106321308</td>\n",
       "      <td>1378.500000000</td>\n",
       "      <td>0.000000023</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.025141720</td>\n",
       "      <td>0.070558737</td>\n",
       "      <td>3718.000000000</td>\n",
       "      <td>0.000187093</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.834443724</td>\n",
       "      <td>17.118031428</td>\n",
       "      <td>322.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>8.852478267</td>\n",
       "      <td>1.293452657</td>\n",
       "      <td>5249.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.053814458</td>\n",
       "      <td>0.385097290</td>\n",
       "      <td>1521.000000000</td>\n",
       "      <td>0.000000002</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>3.602391020</td>\n",
       "      <td>1.239719641</td>\n",
       "      <td>4526.000000000</td>\n",
       "      <td>0.000000001</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>9.456272073</td>\n",
       "      <td>4.769921448</td>\n",
       "      <td>4276.000000000</td>\n",
       "      <td>0.000000312</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>5.056039770</td>\n",
       "      <td>8.527576926</td>\n",
       "      <td>1673.500000000</td>\n",
       "      <td>0.000007723</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.837786983</td>\n",
       "      <td>6.005740756</td>\n",
       "      <td>924.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.480313254</td>\n",
       "      <td>0.637471063</td>\n",
       "      <td>2183.000000000</td>\n",
       "      <td>0.004858898</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>5.629839591</td>\n",
       "      <td>0.077720316</td>\n",
       "      <td>4636.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>66.511651792</td>\n",
       "      <td>53.916095160</td>\n",
       "      <td>4403.000000000</td>\n",
       "      <td>0.000000024</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.799595368</td>\n",
       "      <td>1.254544965</td>\n",
       "      <td>1995.000000000</td>\n",
       "      <td>0.000856499</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>5.400988340</td>\n",
       "      <td>2.932677215</td>\n",
       "      <td>3787.000000000</td>\n",
       "      <td>0.000910372</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>16.946309543</td>\n",
       "      <td>4.250145328</td>\n",
       "      <td>4687.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>15.142481602</td>\n",
       "      <td>3.569360131</td>\n",
       "      <td>5526.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.208991149</td>\n",
       "      <td>2.818244784</td>\n",
       "      <td>2186.000000000</td>\n",
       "      <td>0.009503989</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.710461288</td>\n",
       "      <td>0.044217900</td>\n",
       "      <td>3249.500000000</td>\n",
       "      <td>0.048782064</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.077820237</td>\n",
       "      <td>0.322891883</td>\n",
       "      <td>2270.500000000</td>\n",
       "      <td>0.000778114</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.898237144</td>\n",
       "      <td>3.110610115</td>\n",
       "      <td>2032.500000000</td>\n",
       "      <td>0.001513797</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.997022006</td>\n",
       "      <td>0.106843701</td>\n",
       "      <td>3552.000000000</td>\n",
       "      <td>0.001582026</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.167667485</td>\n",
       "      <td>0.142255182</td>\n",
       "      <td>2298.500000000</td>\n",
       "      <td>0.002342364</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.419156860</td>\n",
       "      <td>0.796383047</td>\n",
       "      <td>2005.500000000</td>\n",
       "      <td>0.000366497</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.136799518</td>\n",
       "      <td>0.343788957</td>\n",
       "      <td>1940.000000000</td>\n",
       "      <td>0.000029439</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.429968602</td>\n",
       "      <td>5.728100144</td>\n",
       "      <td>1033.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>5.147836610</td>\n",
       "      <td>1.976430982</td>\n",
       "      <td>4818.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.018877242</td>\n",
       "      <td>0.032470174</td>\n",
       "      <td>2618.000000000</td>\n",
       "      <td>0.040972149</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>5.692339572</td>\n",
       "      <td>7.113647522</td>\n",
       "      <td>1901.500000000</td>\n",
       "      <td>0.000281374</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>14.004378208</td>\n",
       "      <td>6.675485560</td>\n",
       "      <td>5414.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.198311692</td>\n",
       "      <td>0.713348492</td>\n",
       "      <td>1504.500000000</td>\n",
       "      <td>0.000000004</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.285281979</td>\n",
       "      <td>4.211140173</td>\n",
       "      <td>1911.500000000</td>\n",
       "      <td>0.000293246</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>4.440441357</td>\n",
       "      <td>3.338227381</td>\n",
       "      <td>3434.500000000</td>\n",
       "      <td>0.044006109</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.160150036</td>\n",
       "      <td>1.032402580</td>\n",
       "      <td>972.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.018877242</td>\n",
       "      <td>0.032470174</td>\n",
       "      <td>2618.000000000</td>\n",
       "      <td>0.040972149</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.189012310</td>\n",
       "      <td>1.910228165</td>\n",
       "      <td>1058.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>6.246293722</td>\n",
       "      <td>1.759671336</td>\n",
       "      <td>4690.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>6.890122517</td>\n",
       "      <td>8.813276554</td>\n",
       "      <td>2179.500000000</td>\n",
       "      <td>0.009123103</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>3.669721630</td>\n",
       "      <td>11.959292786</td>\n",
       "      <td>557.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.069321943</td>\n",
       "      <td>4.291767172</td>\n",
       "      <td>1911.000000000</td>\n",
       "      <td>0.000268001</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>11.166264151</td>\n",
       "      <td>2.333086051</td>\n",
       "      <td>5520.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>8.462740646</td>\n",
       "      <td>2.603844842</td>\n",
       "      <td>5374.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>8.833254719</td>\n",
       "      <td>3.088689105</td>\n",
       "      <td>5443.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>4.703202507</td>\n",
       "      <td>1.091591362</td>\n",
       "      <td>4694.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.767680377</td>\n",
       "      <td>8.904648674</td>\n",
       "      <td>760.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>6.255489784</td>\n",
       "      <td>1.777255472</td>\n",
       "      <td>4676.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>5.513137925</td>\n",
       "      <td>14.258085177</td>\n",
       "      <td>781.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>10.666845031</td>\n",
       "      <td>15.609744204</td>\n",
       "      <td>1070.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.007616217</td>\n",
       "      <td>0.974361127</td>\n",
       "      <td>3492.000000000</td>\n",
       "      <td>0.023258419</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.066900046</td>\n",
       "      <td>0.104728857</td>\n",
       "      <td>2514.500000000</td>\n",
       "      <td>0.014427323</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>13.914006772</td>\n",
       "      <td>11.542044914</td>\n",
       "      <td>3748.000000000</td>\n",
       "      <td>0.001527769</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>3.053468543</td>\n",
       "      <td>4.245948071</td>\n",
       "      <td>2156.000000000</td>\n",
       "      <td>0.006883997</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.020248417</td>\n",
       "      <td>0.773593641</td>\n",
       "      <td>2039.000000000</td>\n",
       "      <td>0.000000849</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.183557302</td>\n",
       "      <td>3.858538244</td>\n",
       "      <td>1055.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.244681588</td>\n",
       "      <td>3.399328530</td>\n",
       "      <td>1231.000000000</td>\n",
       "      <td>0.000000001</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.042019003</td>\n",
       "      <td>0.448923628</td>\n",
       "      <td>1638.000000000</td>\n",
       "      <td>0.000000005</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>5.272856882</td>\n",
       "      <td>6.721273454</td>\n",
       "      <td>2342.000000000</td>\n",
       "      <td>0.044582045</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.171174503</td>\n",
       "      <td>3.331059728</td>\n",
       "      <td>2277.000000000</td>\n",
       "      <td>0.021266172</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.094775243</td>\n",
       "      <td>0.151253599</td>\n",
       "      <td>2354.000000000</td>\n",
       "      <td>0.009087997</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>11.925524076</td>\n",
       "      <td>3.936605383</td>\n",
       "      <td>5154.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.795386777</td>\n",
       "      <td>4.393378009</td>\n",
       "      <td>2098.000000000</td>\n",
       "      <td>0.003566066</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>4.142482315</td>\n",
       "      <td>0.847405822</td>\n",
       "      <td>4402.500000000</td>\n",
       "      <td>0.000000017</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.153314248</td>\n",
       "      <td>6.705132703</td>\n",
       "      <td>498.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.324748332</td>\n",
       "      <td>1.924779929</td>\n",
       "      <td>1308.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>6.889120009</td>\n",
       "      <td>3.087835609</td>\n",
       "      <td>4143.000000000</td>\n",
       "      <td>0.000003733</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>8.041150712</td>\n",
       "      <td>4.130117846</td>\n",
       "      <td>4230.500000000</td>\n",
       "      <td>0.000000752</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.159945307</td>\n",
       "      <td>1.114075690</td>\n",
       "      <td>1419.000000000</td>\n",
       "      <td>0.000000001</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.725815090</td>\n",
       "      <td>1.175932569</td>\n",
       "      <td>2157.500000000</td>\n",
       "      <td>0.004156373</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>7.336785075</td>\n",
       "      <td>1.500511597</td>\n",
       "      <td>5086.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.531974471</td>\n",
       "      <td>7.920604735</td>\n",
       "      <td>847.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>4.142917412</td>\n",
       "      <td>19.011455622</td>\n",
       "      <td>775.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.126547989</td>\n",
       "      <td>2.988976360</td>\n",
       "      <td>438.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>6.270106152</td>\n",
       "      <td>2.035978524</td>\n",
       "      <td>4981.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.492625140</td>\n",
       "      <td>4.670108539</td>\n",
       "      <td>1435.500000000</td>\n",
       "      <td>0.000000084</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.942997392</td>\n",
       "      <td>10.576621220</td>\n",
       "      <td>644.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.216458589</td>\n",
       "      <td>1.436278336</td>\n",
       "      <td>767.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.561470110</td>\n",
       "      <td>0.736755850</td>\n",
       "      <td>2412.000000000</td>\n",
       "      <td>0.039620914</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.202913821</td>\n",
       "      <td>3.040794800</td>\n",
       "      <td>1990.500000000</td>\n",
       "      <td>0.000928821</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.546482111</td>\n",
       "      <td>0.910786754</td>\n",
       "      <td>1980.500000000</td>\n",
       "      <td>0.000489486</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>5.246297126</td>\n",
       "      <td>1.439782374</td>\n",
       "      <td>5134.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.074921339</td>\n",
       "      <td>2579.500000000</td>\n",
       "      <td>0.003405435</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>12.768460066</td>\n",
       "      <td>2.793315278</td>\n",
       "      <td>4348.000000000</td>\n",
       "      <td>0.000000071</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>3.192687064</td>\n",
       "      <td>5.863277479</td>\n",
       "      <td>1644.000000000</td>\n",
       "      <td>0.000004600</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>4.408640198</td>\n",
       "      <td>2.000329210</td>\n",
       "      <td>4017.500000000</td>\n",
       "      <td>0.000030828</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>121</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.702708721</td>\n",
       "      <td>1.880461608</td>\n",
       "      <td>1552.000000000</td>\n",
       "      <td>0.000000397</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.948633647</td>\n",
       "      <td>4.483230748</td>\n",
       "      <td>1797.500000000</td>\n",
       "      <td>0.000059348</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.790955977</td>\n",
       "      <td>3.132169901</td>\n",
       "      <td>1239.000000000</td>\n",
       "      <td>0.000000001</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>7.495804335</td>\n",
       "      <td>3.448017453</td>\n",
       "      <td>4800.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.530421870</td>\n",
       "      <td>3.976134152</td>\n",
       "      <td>1094.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.340888285</td>\n",
       "      <td>0.578263642</td>\n",
       "      <td>4020.000000000</td>\n",
       "      <td>0.000018171</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>10.200335811</td>\n",
       "      <td>14.033195670</td>\n",
       "      <td>1427.500000000</td>\n",
       "      <td>0.000000075</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>4.197999245</td>\n",
       "      <td>7.179859289</td>\n",
       "      <td>1661.000000000</td>\n",
       "      <td>0.000006186</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>4.878335305</td>\n",
       "      <td>3.239792755</td>\n",
       "      <td>3749.000000000</td>\n",
       "      <td>0.001494788</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>4.232969111</td>\n",
       "      <td>1.614959121</td>\n",
       "      <td>4271.000000000</td>\n",
       "      <td>0.000000323</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.433560669</td>\n",
       "      <td>0.701467278</td>\n",
       "      <td>2074.000000000</td>\n",
       "      <td>0.001101590</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>8.452004103</td>\n",
       "      <td>11.733910929</td>\n",
       "      <td>1678.000000000</td>\n",
       "      <td>0.000008369</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.132247986</td>\n",
       "      <td>2.755534130</td>\n",
       "      <td>1242.500000000</td>\n",
       "      <td>0.000000001</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.348438676</td>\n",
       "      <td>0.502581101</td>\n",
       "      <td>2324.500000000</td>\n",
       "      <td>0.013082563</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.619192546</td>\n",
       "      <td>1.294846536</td>\n",
       "      <td>1801.000000000</td>\n",
       "      <td>0.000047674</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>8.122735837</td>\n",
       "      <td>5.922772488</td>\n",
       "      <td>3447.000000000</td>\n",
       "      <td>0.039390737</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>5.018789506</td>\n",
       "      <td>3.220696292</td>\n",
       "      <td>3685.000000000</td>\n",
       "      <td>0.003299883</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>3.936400902</td>\n",
       "      <td>2.199997422</td>\n",
       "      <td>4051.500000000</td>\n",
       "      <td>0.000018026</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>147</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.110100794</td>\n",
       "      <td>0.375147682</td>\n",
       "      <td>3549.500000000</td>\n",
       "      <td>0.006840613</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>148</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.510804442</td>\n",
       "      <td>1.187378338</td>\n",
       "      <td>1710.000000000</td>\n",
       "      <td>0.000003993</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>149</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.929000154</td>\n",
       "      <td>4.211552002</td>\n",
       "      <td>823.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>4.594090122</td>\n",
       "      <td>1.408394128</td>\n",
       "      <td>4801.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>151</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.837184564</td>\n",
       "      <td>4.285956910</td>\n",
       "      <td>1152.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>152</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.613066162</td>\n",
       "      <td>2.554874476</td>\n",
       "      <td>1900.000000000</td>\n",
       "      <td>0.000257708</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>3.825263464</td>\n",
       "      <td>1.197905062</td>\n",
       "      <td>4223.500000000</td>\n",
       "      <td>0.000000778</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>155</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>4.229042000</td>\n",
       "      <td>8.622683087</td>\n",
       "      <td>1374.000000000</td>\n",
       "      <td>0.000000024</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>157</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.882908861</td>\n",
       "      <td>1.018448552</td>\n",
       "      <td>4426.500000000</td>\n",
       "      <td>0.000000012</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>159</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.076117039</td>\n",
       "      <td>0.515869068</td>\n",
       "      <td>1575.500000000</td>\n",
       "      <td>0.000000002</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>160</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>4.065213354</td>\n",
       "      <td>2.848800664</td>\n",
       "      <td>3461.000000000</td>\n",
       "      <td>0.034687171</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.786293421</td>\n",
       "      <td>0.258924827</td>\n",
       "      <td>3574.500000000</td>\n",
       "      <td>0.005004925</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>162</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.050590877</td>\n",
       "      <td>0.130553264</td>\n",
       "      <td>2258.000000000</td>\n",
       "      <td>0.000722856</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.404027291</td>\n",
       "      <td>0.751397880</td>\n",
       "      <td>4473.500000000</td>\n",
       "      <td>0.000000004</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.811786530</td>\n",
       "      <td>1.090923656</td>\n",
       "      <td>2184.000000000</td>\n",
       "      <td>0.008664171</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.785911263</td>\n",
       "      <td>0.744530133</td>\n",
       "      <td>4184.000000000</td>\n",
       "      <td>0.000001543</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>168</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.191357733</td>\n",
       "      <td>2.430261177</td>\n",
       "      <td>1736.500000000</td>\n",
       "      <td>0.000013989</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.570728933</td>\n",
       "      <td>1.801445127</td>\n",
       "      <td>3473.000000000</td>\n",
       "      <td>0.030567545</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>3.511644498</td>\n",
       "      <td>2.079713176</td>\n",
       "      <td>3878.500000000</td>\n",
       "      <td>0.000261022</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.596079362</td>\n",
       "      <td>1.750542744</td>\n",
       "      <td>1162.500000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.241158092</td>\n",
       "      <td>0.438725637</td>\n",
       "      <td>1935.500000000</td>\n",
       "      <td>0.000041590</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.378371806</td>\n",
       "      <td>0.920377141</td>\n",
       "      <td>1617.000000000</td>\n",
       "      <td>0.000000649</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.239267278</td>\n",
       "      <td>0.701901543</td>\n",
       "      <td>1458.000000000</td>\n",
       "      <td>0.000000003</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>3.923840073</td>\n",
       "      <td>2.282614172</td>\n",
       "      <td>3939.000000000</td>\n",
       "      <td>0.000089351</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>16.359121335</td>\n",
       "      <td>9.822847586</td>\n",
       "      <td>4226.000000000</td>\n",
       "      <td>0.000000818</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>184</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>3.009765753</td>\n",
       "      <td>1.569766136</td>\n",
       "      <td>4239.000000000</td>\n",
       "      <td>0.000000630</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>191</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.462680299</td>\n",
       "      <td>1.636004407</td>\n",
       "      <td>2329.500000000</td>\n",
       "      <td>0.029761201</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>192</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.865366840</td>\n",
       "      <td>2.277458813</td>\n",
       "      <td>1463.000000000</td>\n",
       "      <td>0.000000064</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>193</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.320586274</td>\n",
       "      <td>0.567389088</td>\n",
       "      <td>2180.000000000</td>\n",
       "      <td>0.001938382</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.606824261</td>\n",
       "      <td>0.701166477</td>\n",
       "      <td>2341.500000000</td>\n",
       "      <td>0.035131536</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>1.325573222</td>\n",
       "      <td>1.913700007</td>\n",
       "      <td>2052.500000000</td>\n",
       "      <td>0.002011614</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>2.335038829</td>\n",
       "      <td>3.440237071</td>\n",
       "      <td>2006.500000000</td>\n",
       "      <td>0.001154826</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.274132677</td>\n",
       "      <td>0.607544806</td>\n",
       "      <td>1748.500000000</td>\n",
       "      <td>0.000006030</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>201</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>5.845247707</td>\n",
       "      <td>8.536203425</td>\n",
       "      <td>1643.000000000</td>\n",
       "      <td>0.000004540</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>202</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.134707168</td>\n",
       "      <td>0.763633478</td>\n",
       "      <td>1486.000000000</td>\n",
       "      <td>0.000000004</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>0.312010569</td>\n",
       "      <td>0.519653361</td>\n",
       "      <td>2144.500000000</td>\n",
       "      <td>0.002304014</td>\n",
       "      <td>outbound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit  n_trials_a  n_trials_b    fr_mean_a    fr_mean_b      statistic  \\\n",
       "0       0          77          75  9.244446606 18.547881245  946.000000000   \n",
       "2       2          77          75  0.665399355  1.504843338 1913.500000000   \n",
       "3       3          77          75  3.029891164 11.525432241  533.000000000   \n",
       "5       5          77          75  1.625277785  3.935882401 1282.500000000   \n",
       "6       6          77          75  2.541099277  8.106321308 1378.500000000   \n",
       "7       7          77          75  1.025141720  0.070558737 3718.000000000   \n",
       "8       8          77          75  1.834443724 17.118031428  322.000000000   \n",
       "9       9          77          75  8.852478267  1.293452657 5249.500000000   \n",
       "10     10          77          75  0.053814458  0.385097290 1521.000000000   \n",
       "11     11          77          75  3.602391020  1.239719641 4526.000000000   \n",
       "12     12          77          75  9.456272073  4.769921448 4276.000000000   \n",
       "13     13          77          75  5.056039770  8.527576926 1673.500000000   \n",
       "14     14          77          75  0.837786983  6.005740756  924.000000000   \n",
       "15     15          77          75  0.480313254  0.637471063 2183.000000000   \n",
       "17     17          77          75  5.629839591  0.077720316 4636.500000000   \n",
       "18     18          77          75 66.511651792 53.916095160 4403.000000000   \n",
       "19     19          77          75  0.799595368  1.254544965 1995.000000000   \n",
       "20     20          77          75  5.400988340  2.932677215 3787.000000000   \n",
       "21     21          77          75 16.946309543  4.250145328 4687.000000000   \n",
       "22     22          77          75 15.142481602  3.569360131 5526.000000000   \n",
       "23     23          77          75  2.208991149  2.818244784 2186.000000000   \n",
       "25     25          77          75  0.710461288  0.044217900 3249.500000000   \n",
       "26     26          77          75  0.077820237  0.322891883 2270.500000000   \n",
       "27     27          77          75  1.898237144  3.110610115 2032.500000000   \n",
       "30     30          77          75  0.997022006  0.106843701 3552.000000000   \n",
       "31     31          77          75  0.167667485  0.142255182 2298.500000000   \n",
       "32     32          77          75  0.419156860  0.796383047 2005.500000000   \n",
       "33     33          77          75  0.136799518  0.343788957 1940.000000000   \n",
       "34     34          77          75  2.429968602  5.728100144 1033.500000000   \n",
       "35     35          77          75  5.147836610  1.976430982 4818.500000000   \n",
       "36     36          77          75  0.018877242  0.032470174 2618.000000000   \n",
       "37     37          77          75  5.692339572  7.113647522 1901.500000000   \n",
       "38     38          77          75 14.004378208  6.675485560 5414.000000000   \n",
       "40     40          77          75  0.198311692  0.713348492 1504.500000000   \n",
       "44     44          77          75  2.285281979  4.211140173 1911.500000000   \n",
       "45     45          77          75  4.440441357  3.338227381 3434.500000000   \n",
       "47     47          77          75  0.160150036  1.032402580  972.500000000   \n",
       "48     48          77          75  0.018877242  0.032470174 2618.000000000   \n",
       "49     49          77          75  0.189012310  1.910228165 1058.500000000   \n",
       "52     52          77          75  6.246293722  1.759671336 4690.000000000   \n",
       "53     53          77          75  6.890122517  8.813276554 2179.500000000   \n",
       "54     54          77          75  3.669721630 11.959292786  557.000000000   \n",
       "55     55          77          75  2.069321943  4.291767172 1911.000000000   \n",
       "56     56          77          75 11.166264151  2.333086051 5520.000000000   \n",
       "57     57          77          75  8.462740646  2.603844842 5374.000000000   \n",
       "59     59          77          75  8.833254719  3.088689105 5443.000000000   \n",
       "60     60          77          75  4.703202507  1.091591362 4694.000000000   \n",
       "62     62          77          75  2.767680377  8.904648674  760.000000000   \n",
       "63     63          77          75  6.255489784  1.777255472 4676.000000000   \n",
       "65     65          77          75  5.513137925 14.258085177  781.000000000   \n",
       "66     66          77          75 10.666845031 15.609744204 1070.500000000   \n",
       "68     68          77          75  2.007616217  0.974361127 3492.000000000   \n",
       "69     69          77          75  0.066900046  0.104728857 2514.500000000   \n",
       "70     70          77          75 13.914006772 11.542044914 3748.000000000   \n",
       "71     71          77          75  3.053468543  4.245948071 2156.000000000   \n",
       "73     73          77          75  0.020248417  0.773593641 2039.000000000   \n",
       "74     74          77          75  1.183557302  3.858538244 1055.000000000   \n",
       "75     75          77          75  1.244681588  3.399328530 1231.000000000   \n",
       "76     76          77          75  0.042019003  0.448923628 1638.000000000   \n",
       "77     77          77          75  5.272856882  6.721273454 2342.000000000   \n",
       "78     78          77          75  2.171174503  3.331059728 2277.000000000   \n",
       "82     82          77          75  0.094775243  0.151253599 2354.000000000   \n",
       "88     88          77          75 11.925524076  3.936605383 5154.000000000   \n",
       "89     89          77          75  2.795386777  4.393378009 2098.000000000   \n",
       "90     90          77          75  4.142482315  0.847405822 4402.500000000   \n",
       "91     91          77          75  1.153314248  6.705132703  498.500000000   \n",
       "92     92          77          75  0.324748332  1.924779929 1308.500000000   \n",
       "93     93          77          75  6.889120009  3.087835609 4143.000000000   \n",
       "94     94          77          75  8.041150712  4.130117846 4230.500000000   \n",
       "95     95          77          75  0.159945307  1.114075690 1419.000000000   \n",
       "96     96          77          75  0.725815090  1.175932569 2157.500000000   \n",
       "97     97          77          75  7.336785075  1.500511597 5086.000000000   \n",
       "98     98          77          75  1.531974471  7.920604735  847.500000000   \n",
       "100   100          77          75  4.142917412 19.011455622  775.000000000   \n",
       "101   101          77          75  0.126547989  2.988976360  438.500000000   \n",
       "102   102          77          75  6.270106152  2.035978524 4981.000000000   \n",
       "103   103          77          75  2.492625140  4.670108539 1435.500000000   \n",
       "104   104          77          75  2.942997392 10.576621220  644.500000000   \n",
       "105   105          77          75  0.216458589  1.436278336  767.500000000   \n",
       "107   107          77          75  0.561470110  0.736755850 2412.000000000   \n",
       "109   109          77          75  2.202913821  3.040794800 1990.500000000   \n",
       "112   112          77          75  0.546482111  0.910786754 1980.500000000   \n",
       "114   114          77          75  5.246297126  1.439782374 5134.500000000   \n",
       "116   116          77          75  0.000000000  0.074921339 2579.500000000   \n",
       "117   117          77          75 12.768460066  2.793315278 4348.000000000   \n",
       "119   119          77          75  3.192687064  5.863277479 1644.000000000   \n",
       "120   120          77          75  4.408640198  2.000329210 4017.500000000   \n",
       "121   121          77          75  0.702708721  1.880461608 1552.000000000   \n",
       "124   124          77          75  2.948633647  4.483230748 1797.500000000   \n",
       "126   126          77          75  0.790955977  3.132169901 1239.000000000   \n",
       "127   127          77          75  7.495804335  3.448017453 4800.000000000   \n",
       "130   130          77          75  1.530421870  3.976134152 1094.500000000   \n",
       "133   133          77          75  1.340888285  0.578263642 4020.000000000   \n",
       "134   134          77          75 10.200335811 14.033195670 1427.500000000   \n",
       "135   135          77          75  4.197999245  7.179859289 1661.000000000   \n",
       "136   136          77          75  4.878335305  3.239792755 3749.000000000   \n",
       "137   137          77          75  4.232969111  1.614959121 4271.000000000   \n",
       "138   138          77          75  0.433560669  0.701467278 2074.000000000   \n",
       "139   139          77          75  8.452004103 11.733910929 1678.000000000   \n",
       "141   141          77          75  1.132247986  2.755534130 1242.500000000   \n",
       "142   142          77          75  0.348438676  0.502581101 2324.500000000   \n",
       "143   143          77          75  0.619192546  1.294846536 1801.000000000   \n",
       "144   144          77          75  8.122735837  5.922772488 3447.000000000   \n",
       "145   145          77          75  5.018789506  3.220696292 3685.000000000   \n",
       "146   146          77          75  3.936400902  2.199997422 4051.500000000   \n",
       "147   147          77          75  1.110100794  0.375147682 3549.500000000   \n",
       "148   148          77          75  0.510804442  1.187378338 1710.000000000   \n",
       "149   149          77          75  0.929000154  4.211552002  823.500000000   \n",
       "150   150          77          75  4.594090122  1.408394128 4801.500000000   \n",
       "151   151          77          75  1.837184564  4.285956910 1152.500000000   \n",
       "152   152          77          75  1.613066162  2.554874476 1900.000000000   \n",
       "154   154          77          75  3.825263464  1.197905062 4223.500000000   \n",
       "155   155          77          75  4.229042000  8.622683087 1374.000000000   \n",
       "157   157          77          75  2.882908861  1.018448552 4426.500000000   \n",
       "159   159          77          75  0.076117039  0.515869068 1575.500000000   \n",
       "160   160          77          75  4.065213354  2.848800664 3461.000000000   \n",
       "161   161          77          75  0.786293421  0.258924827 3574.500000000   \n",
       "162   162          77          75  0.050590877  0.130553264 2258.000000000   \n",
       "163   163          77          75  2.404027291  0.751397880 4473.500000000   \n",
       "164   164          77          75  0.811786530  1.090923656 2184.000000000   \n",
       "165   165          77          75  1.785911263  0.744530133 4184.000000000   \n",
       "168   168          77          75  1.191357733  2.430261177 1736.500000000   \n",
       "169   169          77          75  2.570728933  1.801445127 3473.000000000   \n",
       "170   170          77          75  3.511644498  2.079713176 3878.500000000   \n",
       "173   173          77          75  0.596079362  1.750542744 1162.500000000   \n",
       "174   174          77          75  0.241158092  0.438725637 1935.500000000   \n",
       "175   175          77          75  0.378371806  0.920377141 1617.000000000   \n",
       "179   179          77          75  0.239267278  0.701901543 1458.000000000   \n",
       "180   180          77          75  3.923840073  2.282614172 3939.000000000   \n",
       "181   181          77          75 16.359121335  9.822847586 4226.000000000   \n",
       "184   184          77          75  3.009765753  1.569766136 4239.000000000   \n",
       "191   191          77          75  1.462680299  1.636004407 2329.500000000   \n",
       "192   192          77          75  0.865366840  2.277458813 1463.000000000   \n",
       "193   193          77          75  0.320586274  0.567389088 2180.000000000   \n",
       "196   196          77          75  0.606824261  0.701166477 2341.500000000   \n",
       "198   198          77          75  1.325573222  1.913700007 2052.500000000   \n",
       "199   199          77          75  2.335038829  3.440237071 2006.500000000   \n",
       "200   200          77          75  0.274132677  0.607544806 1748.500000000   \n",
       "201   201          77          75  5.845247707  8.536203425 1643.000000000   \n",
       "202   202          77          75  0.134707168  0.763633478 1486.000000000   \n",
       "203   203          77          75  0.312010569  0.519653361 2144.500000000   \n",
       "\n",
       "        p_value preference  \n",
       "0   0.000000000   outbound  \n",
       "2   0.000181030   outbound  \n",
       "3   0.000000000   outbound  \n",
       "5   0.000000003   outbound  \n",
       "6   0.000000023   outbound  \n",
       "7   0.000187093    inbound  \n",
       "8   0.000000000   outbound  \n",
       "9   0.000000000    inbound  \n",
       "10  0.000000002   outbound  \n",
       "11  0.000000001    inbound  \n",
       "12  0.000000312    inbound  \n",
       "13  0.000007723   outbound  \n",
       "14  0.000000000   outbound  \n",
       "15  0.004858898   outbound  \n",
       "17  0.000000000    inbound  \n",
       "18  0.000000024    inbound  \n",
       "19  0.000856499   outbound  \n",
       "20  0.000910372    inbound  \n",
       "21  0.000000000    inbound  \n",
       "22  0.000000000    inbound  \n",
       "23  0.009503989   outbound  \n",
       "25  0.048782064    inbound  \n",
       "26  0.000778114   outbound  \n",
       "27  0.001513797   outbound  \n",
       "30  0.001582026    inbound  \n",
       "31  0.002342364    inbound  \n",
       "32  0.000366497   outbound  \n",
       "33  0.000029439   outbound  \n",
       "34  0.000000000   outbound  \n",
       "35  0.000000000    inbound  \n",
       "36  0.040972149   outbound  \n",
       "37  0.000281374   outbound  \n",
       "38  0.000000000    inbound  \n",
       "40  0.000000004   outbound  \n",
       "44  0.000293246   outbound  \n",
       "45  0.044006109    inbound  \n",
       "47  0.000000000   outbound  \n",
       "48  0.040972149   outbound  \n",
       "49  0.000000000   outbound  \n",
       "52  0.000000000    inbound  \n",
       "53  0.009123103   outbound  \n",
       "54  0.000000000   outbound  \n",
       "55  0.000268001   outbound  \n",
       "56  0.000000000    inbound  \n",
       "57  0.000000000    inbound  \n",
       "59  0.000000000    inbound  \n",
       "60  0.000000000    inbound  \n",
       "62  0.000000000   outbound  \n",
       "63  0.000000000    inbound  \n",
       "65  0.000000000   outbound  \n",
       "66  0.000000000   outbound  \n",
       "68  0.023258419    inbound  \n",
       "69  0.014427323   outbound  \n",
       "70  0.001527769    inbound  \n",
       "71  0.006883997   outbound  \n",
       "73  0.000000849   outbound  \n",
       "74  0.000000000   outbound  \n",
       "75  0.000000001   outbound  \n",
       "76  0.000000005   outbound  \n",
       "77  0.044582045   outbound  \n",
       "78  0.021266172   outbound  \n",
       "82  0.009087997   outbound  \n",
       "88  0.000000000    inbound  \n",
       "89  0.003566066   outbound  \n",
       "90  0.000000017    inbound  \n",
       "91  0.000000000   outbound  \n",
       "92  0.000000000   outbound  \n",
       "93  0.000003733    inbound  \n",
       "94  0.000000752    inbound  \n",
       "95  0.000000001   outbound  \n",
       "96  0.004156373   outbound  \n",
       "97  0.000000000    inbound  \n",
       "98  0.000000000   outbound  \n",
       "100 0.000000000   outbound  \n",
       "101 0.000000000   outbound  \n",
       "102 0.000000000    inbound  \n",
       "103 0.000000084   outbound  \n",
       "104 0.000000000   outbound  \n",
       "105 0.000000000   outbound  \n",
       "107 0.039620914   outbound  \n",
       "109 0.000928821   outbound  \n",
       "112 0.000489486   outbound  \n",
       "114 0.000000000    inbound  \n",
       "116 0.003405435   outbound  \n",
       "117 0.000000071    inbound  \n",
       "119 0.000004600   outbound  \n",
       "120 0.000030828    inbound  \n",
       "121 0.000000397   outbound  \n",
       "124 0.000059348   outbound  \n",
       "126 0.000000001   outbound  \n",
       "127 0.000000000    inbound  \n",
       "130 0.000000000   outbound  \n",
       "133 0.000018171    inbound  \n",
       "134 0.000000075   outbound  \n",
       "135 0.000006186   outbound  \n",
       "136 0.001494788    inbound  \n",
       "137 0.000000323    inbound  \n",
       "138 0.001101590   outbound  \n",
       "139 0.000008369   outbound  \n",
       "141 0.000000001   outbound  \n",
       "142 0.013082563   outbound  \n",
       "143 0.000047674   outbound  \n",
       "144 0.039390737    inbound  \n",
       "145 0.003299883    inbound  \n",
       "146 0.000018026    inbound  \n",
       "147 0.006840613    inbound  \n",
       "148 0.000003993   outbound  \n",
       "149 0.000000000   outbound  \n",
       "150 0.000000000    inbound  \n",
       "151 0.000000000   outbound  \n",
       "152 0.000257708   outbound  \n",
       "154 0.000000778    inbound  \n",
       "155 0.000000024   outbound  \n",
       "157 0.000000012    inbound  \n",
       "159 0.000000002   outbound  \n",
       "160 0.034687171    inbound  \n",
       "161 0.005004925    inbound  \n",
       "162 0.000722856   outbound  \n",
       "163 0.000000004    inbound  \n",
       "164 0.008664171   outbound  \n",
       "165 0.000001543    inbound  \n",
       "168 0.000013989   outbound  \n",
       "169 0.030567545    inbound  \n",
       "170 0.000261022    inbound  \n",
       "173 0.000000000   outbound  \n",
       "174 0.000041590   outbound  \n",
       "175 0.000000649   outbound  \n",
       "179 0.000000003   outbound  \n",
       "180 0.000089351    inbound  \n",
       "181 0.000000818    inbound  \n",
       "184 0.000000630    inbound  \n",
       "191 0.029761201   outbound  \n",
       "192 0.000000064   outbound  \n",
       "193 0.001938382   outbound  \n",
       "196 0.035131536   outbound  \n",
       "198 0.002011614   outbound  \n",
       "199 0.001154826   outbound  \n",
       "200 0.000006030   outbound  \n",
       "201 0.000004540   outbound  \n",
       "202 0.000000004   outbound  \n",
       "203 0.002304014   outbound  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of siginificant units:  141\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#OUTBOUND VS INBOUND \n",
    "pos_df = trialized_position[(trialized_position[\"zone\"] == \"run\")].copy()\n",
    "arms = [2]\n",
    "last_trial = 1e6\n",
    "\n",
    "pos_mask_outin = (pos_df[\"track_segment_id\"].isin(arms))\n",
    "\n",
    "summary_outin , trial_outin  = compute_trialwise_firing_rates_two_trial_categories_with_pos_mask(\n",
    "    spikes_list=l_mpfc_spikes,\n",
    "    trials_df=trials_df[trials_df[\"trial_number\"] < last_trial],  \n",
    "    position_df=pos_df,\n",
    "    pos_mask=pos_mask_outin,\n",
    "    category_col=\"trial_type\",       \n",
    "    category_a=\"inbound\",\n",
    "    category_b=\"outbound\",\n",
    "    only_correct=True,\n",
    "    min_duration=0.5,              \n",
    ")\n",
    "\n",
    "mw_outin  = test_trialwise_firing_rates_two_trial_categories(\n",
    "    trialwise_df=trial_outin ,\n",
    "    category_a=\"inbound\",\n",
    "    category_b=\"outbound\",\n",
    "    min_trials_a=3,\n",
    "    min_trials_b=3,\n",
    "    alternative=\"two-sided\"\n",
    ")\n",
    "plot_trialwise_fr_two_categories_side_by_side(\n",
    "    summary_df=summary_outin ,\n",
    "    category_a=\"inbound\",\n",
    "    category_b=\"outbound\",\n",
    "    use_sem=True,\n",
    "    title = f\"Trialwise firing rate; inbound vs outbound\",\n",
    "    stats_df = mw_outin ,\n",
    "    alpha = 0.05\n",
    ")\n",
    "\n",
    "display(mw_outin [mw_outin [\"p_value\"]<0.05])\n",
    "print(\"Number of siginificant units: \", len(mw_outin [mw_outin [\"p_value\"]<0.05]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "f749fb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>n_trials_a</th>\n",
       "      <th>n_trials_b</th>\n",
       "      <th>fr_mean_a</th>\n",
       "      <th>fr_mean_b</th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "      <th>preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>6.504200030</td>\n",
       "      <td>11.836278489</td>\n",
       "      <td>404.000000000</td>\n",
       "      <td>0.000984715</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.390065958</td>\n",
       "      <td>0.943674613</td>\n",
       "      <td>489.000000000</td>\n",
       "      <td>0.005794653</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>2.329584035</td>\n",
       "      <td>0.998763594</td>\n",
       "      <td>952.500000000</td>\n",
       "      <td>0.014245659</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>1.159130947</td>\n",
       "      <td>2.522162095</td>\n",
       "      <td>522.500000000</td>\n",
       "      <td>0.031997487</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.019516824</td>\n",
       "      <td>0.087733098</td>\n",
       "      <td>613.000000000</td>\n",
       "      <td>0.035114783</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>6.281533939</td>\n",
       "      <td>4.000767472</td>\n",
       "      <td>1073.500000000</td>\n",
       "      <td>0.000257086</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>7.823787372</td>\n",
       "      <td>3.514628581</td>\n",
       "      <td>923.000000000</td>\n",
       "      <td>0.032575544</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>12.115213958</td>\n",
       "      <td>20.984472114</td>\n",
       "      <td>455.000000000</td>\n",
       "      <td>0.005702233</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>16.696540839</td>\n",
       "      <td>13.789194120</td>\n",
       "      <td>959.500000000</td>\n",
       "      <td>0.013579163</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.100221528</td>\n",
       "      <td>0.235953842</td>\n",
       "      <td>614.000000000</td>\n",
       "      <td>0.036840911</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.244368183</td>\n",
       "      <td>0.595729628</td>\n",
       "      <td>567.500000000</td>\n",
       "      <td>0.042945920</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>3.732670062</td>\n",
       "      <td>4.898894490</td>\n",
       "      <td>523.000000000</td>\n",
       "      <td>0.039602199</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.328649164</td>\n",
       "      <td>0.602578634</td>\n",
       "      <td>548.000000000</td>\n",
       "      <td>0.029202548</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>9.059673304</td>\n",
       "      <td>3.425626987</td>\n",
       "      <td>1249.000000000</td>\n",
       "      <td>0.000000043</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>12.824818001</td>\n",
       "      <td>9.366960141</td>\n",
       "      <td>1048.000000000</td>\n",
       "      <td>0.000704020</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>3.236526990</td>\n",
       "      <td>6.635443598</td>\n",
       "      <td>363.500000000</td>\n",
       "      <td>0.000195640</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>9.973115991</td>\n",
       "      <td>7.800213349</td>\n",
       "      <td>1004.500000000</td>\n",
       "      <td>0.003324870</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>2.399831014</td>\n",
       "      <td>6.741854973</td>\n",
       "      <td>208.500000000</td>\n",
       "      <td>0.000000096</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>9.096312059</td>\n",
       "      <td>3.409023469</td>\n",
       "      <td>1249.500000000</td>\n",
       "      <td>0.000000041</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>9.754869511</td>\n",
       "      <td>11.716497307</td>\n",
       "      <td>420.500000000</td>\n",
       "      <td>0.001789683</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>3.086573670</td>\n",
       "      <td>1.035467254</td>\n",
       "      <td>1064.000000000</td>\n",
       "      <td>0.000304490</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>15.427939909</td>\n",
       "      <td>12.322361968</td>\n",
       "      <td>927.000000000</td>\n",
       "      <td>0.033133057</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>3.949500269</td>\n",
       "      <td>2.259415198</td>\n",
       "      <td>931.000000000</td>\n",
       "      <td>0.027889713</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.765890525</td>\n",
       "      <td>1.730834176</td>\n",
       "      <td>456.000000000</td>\n",
       "      <td>0.004338695</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>7.296063458</td>\n",
       "      <td>3.310477715</td>\n",
       "      <td>1180.000000000</td>\n",
       "      <td>0.000001932</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>1.781806635</td>\n",
       "      <td>2.395851668</td>\n",
       "      <td>527.500000000</td>\n",
       "      <td>0.034269035</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.037517778</td>\n",
       "      <td>0.151526562</td>\n",
       "      <td>596.000000000</td>\n",
       "      <td>0.033760708</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.577813071</td>\n",
       "      <td>2.002434450</td>\n",
       "      <td>386.500000000</td>\n",
       "      <td>0.000285752</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.064934268</td>\n",
       "      <td>1.473936798</td>\n",
       "      <td>507.000000000</td>\n",
       "      <td>0.003446965</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>9.199108553</td>\n",
       "      <td>14.172191243</td>\n",
       "      <td>411.000000000</td>\n",
       "      <td>0.001274502</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>1.829882121</td>\n",
       "      <td>3.582660697</td>\n",
       "      <td>450.000000000</td>\n",
       "      <td>0.004477638</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>1.257928221</td>\n",
       "      <td>1.061371226</td>\n",
       "      <td>942.500000000</td>\n",
       "      <td>0.013162492</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.361800486</td>\n",
       "      <td>1.045240863</td>\n",
       "      <td>531.000000000</td>\n",
       "      <td>0.021010556</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>5.663452309</td>\n",
       "      <td>8.956566395</td>\n",
       "      <td>451.500000000</td>\n",
       "      <td>0.005094521</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>2.048800377</td>\n",
       "      <td>6.169074395</td>\n",
       "      <td>175.500000000</td>\n",
       "      <td>0.000000013</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.051613769</td>\n",
       "      <td>0.200884249</td>\n",
       "      <td>597.000000000</td>\n",
       "      <td>0.035210013</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>2.106216434</td>\n",
       "      <td>3.634199746</td>\n",
       "      <td>469.000000000</td>\n",
       "      <td>0.008563212</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>1.976337218</td>\n",
       "      <td>3.835132056</td>\n",
       "      <td>525.500000000</td>\n",
       "      <td>0.038117249</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>2.061907275</td>\n",
       "      <td>4.176042571</td>\n",
       "      <td>400.000000000</td>\n",
       "      <td>0.000699463</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>4.557120534</td>\n",
       "      <td>2.097369171</td>\n",
       "      <td>1051.500000000</td>\n",
       "      <td>0.000548559</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.600172667</td>\n",
       "      <td>0.969970421</td>\n",
       "      <td>514.000000000</td>\n",
       "      <td>0.024758969</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>6.602702745</td>\n",
       "      <td>8.290379634</td>\n",
       "      <td>499.500000000</td>\n",
       "      <td>0.021339225</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>9.133365062</td>\n",
       "      <td>11.095614688</td>\n",
       "      <td>461.500000000</td>\n",
       "      <td>0.006998899</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.317222411</td>\n",
       "      <td>0.555049802</td>\n",
       "      <td>558.500000000</td>\n",
       "      <td>0.034969660</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>6.239299869</td>\n",
       "      <td>10.523028060</td>\n",
       "      <td>302.500000000</td>\n",
       "      <td>0.000013652</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.786305114</td>\n",
       "      <td>1.489482198</td>\n",
       "      <td>458.000000000</td>\n",
       "      <td>0.005044616</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.186616919</td>\n",
       "      <td>0.510896206</td>\n",
       "      <td>564.500000000</td>\n",
       "      <td>0.025784237</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.385212416</td>\n",
       "      <td>0.834784398</td>\n",
       "      <td>496.000000000</td>\n",
       "      <td>0.012430506</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>6.912400058</td>\n",
       "      <td>9.078489870</td>\n",
       "      <td>482.500000000</td>\n",
       "      <td>0.013187414</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>4.041450108</td>\n",
       "      <td>5.874301584</td>\n",
       "      <td>495.000000000</td>\n",
       "      <td>0.018829628</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>3.803415349</td>\n",
       "      <td>5.239354361</td>\n",
       "      <td>476.500000000</td>\n",
       "      <td>0.011039109</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.296523517</td>\n",
       "      <td>0.414629051</td>\n",
       "      <td>556.500000000</td>\n",
       "      <td>0.021817952</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>13.413882710</td>\n",
       "      <td>18.971603947</td>\n",
       "      <td>446.000000000</td>\n",
       "      <td>0.004263433</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>202</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>0.039448899</td>\n",
       "      <td>0.228534428</td>\n",
       "      <td>560.000000000</td>\n",
       "      <td>0.006250952</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit  n_trials_a  n_trials_b    fr_mean_a    fr_mean_b      statistic  \\\n",
       "0       0          37          39  6.504200030 11.836278489  404.000000000   \n",
       "2       2          37          39  0.390065958  0.943674613  489.000000000   \n",
       "5       5          37          39  2.329584035  0.998763594  952.500000000   \n",
       "8       8          37          39  1.159130947  2.522162095  522.500000000   \n",
       "10     10          37          39  0.019516824  0.087733098  613.000000000   \n",
       "13     13          37          39  6.281533939  4.000767472 1073.500000000   \n",
       "17     17          37          39  7.823787372  3.514628581  923.000000000   \n",
       "21     21          37          39 12.115213958 20.984472114  455.000000000   \n",
       "22     22          37          39 16.696540839 13.789194120  959.500000000   \n",
       "31     31          37          39  0.100221528  0.235953842  614.000000000   \n",
       "32     32          37          39  0.244368183  0.595729628  567.500000000   \n",
       "39     39          37          39  3.732670062  4.898894490  523.000000000   \n",
       "43     43          37          39  0.328649164  0.602578634  548.000000000   \n",
       "52     52          37          39  9.059673304  3.425626987 1249.000000000   \n",
       "56     56          37          39 12.824818001  9.366960141 1048.000000000   \n",
       "58     58          37          39  3.236526990  6.635443598  363.500000000   \n",
       "59     59          37          39  9.973115991  7.800213349 1004.500000000   \n",
       "60     60          37          39  2.399831014  6.741854973  208.500000000   \n",
       "63     63          37          39  9.096312059  3.409023469 1249.500000000   \n",
       "66     66          37          39  9.754869511 11.716497307  420.500000000   \n",
       "68     68          37          39  3.086573670  1.035467254 1064.000000000   \n",
       "70     70          37          39 15.427939909 12.322361968  927.000000000   \n",
       "71     71          37          39  3.949500269  2.259415198  931.000000000   \n",
       "75     75          37          39  0.765890525  1.730834176  456.000000000   \n",
       "77     77          37          39  7.296063458  3.310477715 1180.000000000   \n",
       "78     78          37          39  1.781806635  2.395851668  527.500000000   \n",
       "82     82          37          39  0.037517778  0.151526562  596.000000000   \n",
       "86     86          37          39  0.577813071  2.002434450  386.500000000   \n",
       "87     87          37          39  0.064934268  1.473936798  507.000000000   \n",
       "88     88          37          39  9.199108553 14.172191243  411.000000000   \n",
       "89     89          37          39  1.829882121  3.582660697  450.000000000   \n",
       "91     91          37          39  1.257928221  1.061371226  942.500000000   \n",
       "96     96          37          39  0.361800486  1.045240863  531.000000000   \n",
       "97     97          37          39  5.663452309  8.956566395  451.500000000   \n",
       "100   100          37          39  2.048800377  6.169074395  175.500000000   \n",
       "101   101          37          39  0.051613769  0.200884249  597.000000000   \n",
       "104   104          37          39  2.106216434  3.634199746  469.000000000   \n",
       "108   108          37          39  1.976337218  3.835132056  525.500000000   \n",
       "123   123          37          39  2.061907275  4.176042571  400.000000000   \n",
       "125   125          37          39  4.557120534  2.097369171 1051.500000000   \n",
       "126   126          37          39  0.600172667  0.969970421  514.000000000   \n",
       "127   127          37          39  6.602702745  8.290379634  499.500000000   \n",
       "134   134          37          39  9.133365062 11.095614688  461.500000000   \n",
       "138   138          37          39  0.317222411  0.555049802  558.500000000   \n",
       "139   139          37          39  6.239299869 10.523028060  302.500000000   \n",
       "141   141          37          39  0.786305114  1.489482198  458.000000000   \n",
       "142   142          37          39  0.186616919  0.510896206  564.500000000   \n",
       "143   143          37          39  0.385212416  0.834784398  496.000000000   \n",
       "144   144          37          39  6.912400058  9.078489870  482.500000000   \n",
       "145   145          37          39  4.041450108  5.874301584  495.000000000   \n",
       "150   150          37          39  3.803415349  5.239354361  476.500000000   \n",
       "172   172          37          39  0.296523517  0.414629051  556.500000000   \n",
       "181   181          37          39 13.413882710 18.971603947  446.000000000   \n",
       "202   202          37          39  0.039448899  0.228534428  560.000000000   \n",
       "\n",
       "        p_value preference  \n",
       "0   0.000984715      right  \n",
       "2   0.005794653      right  \n",
       "5   0.014245659       left  \n",
       "8   0.031997487      right  \n",
       "10  0.035114783      right  \n",
       "13  0.000257086       left  \n",
       "17  0.032575544       left  \n",
       "21  0.005702233      right  \n",
       "22  0.013579163       left  \n",
       "31  0.036840911      right  \n",
       "32  0.042945920      right  \n",
       "39  0.039602199      right  \n",
       "43  0.029202548      right  \n",
       "52  0.000000043       left  \n",
       "56  0.000704020       left  \n",
       "58  0.000195640      right  \n",
       "59  0.003324870       left  \n",
       "60  0.000000096      right  \n",
       "63  0.000000041       left  \n",
       "66  0.001789683      right  \n",
       "68  0.000304490       left  \n",
       "70  0.033133057       left  \n",
       "71  0.027889713       left  \n",
       "75  0.004338695      right  \n",
       "77  0.000001932       left  \n",
       "78  0.034269035      right  \n",
       "82  0.033760708      right  \n",
       "86  0.000285752      right  \n",
       "87  0.003446965      right  \n",
       "88  0.001274502      right  \n",
       "89  0.004477638      right  \n",
       "91  0.013162492       left  \n",
       "96  0.021010556      right  \n",
       "97  0.005094521      right  \n",
       "100 0.000000013      right  \n",
       "101 0.035210013      right  \n",
       "104 0.008563212      right  \n",
       "108 0.038117249      right  \n",
       "123 0.000699463      right  \n",
       "125 0.000548559       left  \n",
       "126 0.024758969      right  \n",
       "127 0.021339225      right  \n",
       "134 0.006998899      right  \n",
       "138 0.034969660      right  \n",
       "139 0.000013652      right  \n",
       "141 0.005044616      right  \n",
       "142 0.025784237      right  \n",
       "143 0.012430506      right  \n",
       "144 0.013187414      right  \n",
       "145 0.018829628      right  \n",
       "150 0.011039109      right  \n",
       "172 0.021817952      right  \n",
       "181 0.004263433      right  \n",
       "202 0.006250952      right  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of siginificant units:  54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#INBOUND LEFT VS RIGHT ONLY IN THE CENTRAL ARM\n",
    "trial_type = \"inbound\"\n",
    "category_a = \"left\"\n",
    "category_b = \"right\"\n",
    "arms = [2]\n",
    "last_trial = 1e6\n",
    "\n",
    "pos_df = trialized_position[(trialized_position[\"trial_type\"] == trial_type) & (trialized_position[\"zone\"] == \"run\")].copy()\n",
    "pos_mask_in_lr   = (pos_df[\"track_segment_id\"].isin(arms)) \n",
    "trials_df_subset = trials_df[(trials_df[\"trial_number\"] < last_trial) & (trials_df[\"trial_type\"]== trial_type)]\n",
    "\n",
    "summary_in_lr  , trial_in_lr   = compute_trialwise_firing_rates_two_trial_categories_with_pos_mask(\n",
    "    spikes_list=l_mpfc_spikes,\n",
    "    trials_df= trials_df_subset,  \n",
    "    position_df= pos_df,\n",
    "    pos_mask=pos_mask_in_lr  ,\n",
    "    category_col=\"left/right\",       \n",
    "    category_a= category_a,\n",
    "    category_b= category_b,\n",
    "    only_correct=True,\n",
    "    min_duration=0.5,                \n",
    ")\n",
    "\n",
    "\n",
    "mw_in_lr   = test_trialwise_firing_rates_two_trial_categories(\n",
    "    trialwise_df=trial_in_lr  ,\n",
    "    category_a= category_a,\n",
    "    category_b= category_b,\n",
    "    min_trials_a=3,\n",
    "    min_trials_b=3,\n",
    "    alternative=\"two-sided\",\n",
    ")\n",
    "\n",
    "plot_trialwise_fr_two_categories_side_by_side(\n",
    "    summary_df=summary_in_lr  ,\n",
    "    category_a= category_a,\n",
    "    category_b= category_b,\n",
    "    use_sem=True,\n",
    "    title = f\"Trialwise firing rate: {trial_type}; {category_a} vs {category_b} (valid arms: {arms})\",\n",
    "    stats_df = mw_in_lr  ,\n",
    "    alpha = 0.05\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "display(mw_in_lr  [mw_in_lr  [\"p_value\"]<0.05])\n",
    "print(\"Number of siginificant units: \", len(mw_in_lr  [mw_in_lr  [\"p_value\"]<0.05]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "5ae5fb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>n_trials_a</th>\n",
       "      <th>n_trials_b</th>\n",
       "      <th>fr_mean_a</th>\n",
       "      <th>fr_mean_b</th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "      <th>preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3.190661850</td>\n",
       "      <td>1.317392717</td>\n",
       "      <td>36.000000000</td>\n",
       "      <td>0.034965035</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.307469510</td>\n",
       "      <td>1.722950128</td>\n",
       "      <td>6.000000000</td>\n",
       "      <td>0.037259910</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5.039529103</td>\n",
       "      <td>2.914450558</td>\n",
       "      <td>38.000000000</td>\n",
       "      <td>0.013986014</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4.580074547</td>\n",
       "      <td>7.302256513</td>\n",
       "      <td>6.000000000</td>\n",
       "      <td>0.034965035</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3.940864000</td>\n",
       "      <td>1.633734611</td>\n",
       "      <td>36.000000000</td>\n",
       "      <td>0.034965035</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4.147895122</td>\n",
       "      <td>2.113276372</td>\n",
       "      <td>36.000000000</td>\n",
       "      <td>0.034965035</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.005177091</td>\n",
       "      <td>0.154342819</td>\n",
       "      <td>4.000000000</td>\n",
       "      <td>0.010392624</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1.072074062</td>\n",
       "      <td>1.935261989</td>\n",
       "      <td>4.000000000</td>\n",
       "      <td>0.013986014</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit  n_trials_a  n_trials_b   fr_mean_a   fr_mean_b    statistic  \\\n",
       "4       4           7           6 3.190661850 1.317392717 36.000000000   \n",
       "14     14           7           6 0.307469510 1.722950128  6.000000000   \n",
       "60     60           7           6 5.039529103 2.914450558 38.000000000   \n",
       "65     65           7           6 4.580074547 7.302256513  6.000000000   \n",
       "96     96           7           6 3.940864000 1.633734611 36.000000000   \n",
       "120   120           7           6 4.147895122 2.113276372 36.000000000   \n",
       "153   153           7           6 0.005177091 0.154342819  4.000000000   \n",
       "170   170           7           6 1.072074062 1.935261989  4.000000000   \n",
       "\n",
       "        p_value preference  \n",
       "4   0.034965035       left  \n",
       "14  0.037259910      right  \n",
       "60  0.013986014       left  \n",
       "65  0.034965035      right  \n",
       "96  0.034965035       left  \n",
       "120 0.034965035       left  \n",
       "153 0.010392624      right  \n",
       "170 0.013986014      right  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of siginificant units:  8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#OUTBOUND LEFT VS RIGHT ONLY IN THE CENTRAL ARM\n",
    "trial_type = \"outbound\"\n",
    "category_a = \"left\"\n",
    "category_b = \"right\"\n",
    "arms = [2]\n",
    "last_trial = 31\n",
    "\n",
    "pos_df = trialized_position[(trialized_position[\"trial_type\"] == trial_type) & (trialized_position[\"zone\"] == \"run\")].copy()\n",
    "pos_mask_out_lr   = (pos_df[\"track_segment_id\"].isin(arms)) \n",
    "trials_df_subset = trials_df[(trials_df[\"trial_number\"] < last_trial) & (trials_df[\"trial_type\"]== trial_type)]\n",
    "\n",
    "summary_out_lr  , trial_out_lr   = compute_trialwise_firing_rates_two_trial_categories_with_pos_mask(\n",
    "    spikes_list=l_mpfc_spikes,\n",
    "    trials_df= trials_df_subset,  \n",
    "    position_df= pos_df,\n",
    "    pos_mask=pos_mask_out_lr  ,\n",
    "    category_col=\"left/right\",       \n",
    "    category_a= category_a,\n",
    "    category_b= category_b,\n",
    "    only_correct=True,\n",
    "    min_duration=0.5,                \n",
    ")\n",
    "\n",
    "\n",
    "mw_out_lr   = test_trialwise_firing_rates_two_trial_categories(\n",
    "    trialwise_df=trial_out_lr  ,\n",
    "    category_a= category_a,\n",
    "    category_b= category_b,\n",
    "    min_trials_a=3,\n",
    "    min_trials_b=3,\n",
    "    alternative=\"two-sided\",\n",
    ")\n",
    "\n",
    "plot_trialwise_fr_two_categories_side_by_side(\n",
    "    summary_df=summary_out_lr  ,\n",
    "    category_a= category_a,\n",
    "    category_b= category_b,\n",
    "    use_sem=True,\n",
    "    title = f\"Trialwise firing rate: {trial_type}; {category_a} vs {category_b} (valid arms: {arms})\",\n",
    "    stats_df = mw_out_lr  ,\n",
    "    alpha = 0.05\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "display(mw_out_lr  [mw_out_lr  [\"p_value\"]<0.05])\n",
    "print(\"Number of siginificant units: \", len(mw_out_lr  [mw_out_lr  [\"p_value\"]<0.05]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c529a0f4",
   "metadata": {},
   "source": [
    "#### Location tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1fae38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do speeds cluster at certain locations?\n",
    "\n",
    "zones = [\"run\"]\n",
    "trial_types = [\"outbound\"]  \n",
    "\n",
    "mask = (\n",
    "    trialized_position[\"zone\"].isin(zones)\n",
    "    & trialized_position[\"trial_type\"].isin(trial_types)\n",
    ")\n",
    "\n",
    "speed_col = \"speed\"\n",
    "n_bins = 8\n",
    "\n",
    "# Work only on the masked rows for binning\n",
    "speed_vals = trialized_position.loc[mask, speed_col].astype(float)\n",
    "speed_vals = speed_vals.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Guard: nothing to bin\n",
    "if speed_vals.empty:\n",
    "    raise ValueError(\"No finite speed values after applying mask; cannot bin/plot.\")\n",
    "\n",
    "bin_edges = np.linspace(speed_vals.min(), speed_vals.max(), n_bins + 1)\n",
    "speed_bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Assign bins for masked rows (others stay NaN)\n",
    "trialized_position[\"speed_bin\"] = np.nan\n",
    "trialized_position.loc[speed_vals.index, \"speed_bin\"] = pd.cut(\n",
    "    speed_vals,\n",
    "    bins=bin_edges,\n",
    "    labels=False,\n",
    "    include_lowest=True,\n",
    ").astype(int)\n",
    "\n",
    "binned_position_idx = [\n",
    "    trialized_position.index[mask & (trialized_position[\"speed_bin\"] == i)]\n",
    "    for i in range(n_bins)\n",
    "]\n",
    "\n",
    "# arrange on different axes in a 2-column grid\n",
    "n_cols = 2\n",
    "n_rows = int(np.ceil(n_bins / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    n_rows, n_cols,\n",
    "    layout=\"tight\",\n",
    "    figsize=(12, 3 * n_rows),\n",
    "    sharex=True, sharey=True,\n",
    ")\n",
    "\n",
    "axes = np.array(axes).reshape(-1)\n",
    "cmap = plt.get_cmap(\"viridis\", n_bins)\n",
    "\n",
    "# background once-per-axis, but use masked background (faster + consistent)\n",
    "background_df = trialized_position.loc[mask]\n",
    "\n",
    "for i, index in enumerate(binned_position_idx):\n",
    "    ax_i = axes[i]\n",
    "    color = cmap(i)\n",
    "\n",
    "    # background: all positions within mask\n",
    "    background_df.plot.scatter(\n",
    "        x=\"position_x\", y=\"position_y\",\n",
    "        s=4, ax=ax_i, color=\"k\", alpha=0.02,\n",
    "    )\n",
    "\n",
    "    # highlighted: this speed bin (already within mask by construction)\n",
    "    df_bin = trialized_position.loc[index]\n",
    "    df_bin.plot.scatter(\n",
    "        x=\"position_x\", y=\"position_y\",\n",
    "        s=8, ax=ax_i, color=color,\n",
    "        label=int(speed_bin_centers[i]),\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    ax_i.set_title(f\"bin {i} (center {int(speed_bin_centers[i])})\")\n",
    "    ax_i.set_xlabel(\"x position (cm)\")\n",
    "    ax_i.set_ylabel(\"y position (cm)\")\n",
    "\n",
    "# hide any unused axes\n",
    "for j in range(n_bins, len(axes)):\n",
    "    axes[j].axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2b5ed99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: speed_bins_map_outbound.svg (dpi=160, rasterized points)\n"
     ]
    }
   ],
   "source": [
    "# Plot all speed bins on one map (manual bin range 0â€“125 cm/s)\n",
    "# + Square plotting area (axes box is square)\n",
    "# + Save as small SVG with rasterized points\n",
    "\n",
    "from matplotlib import colors\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- user knobs ----------\n",
    "zones = [\"run\"]\n",
    "trial_types = [\"outbound\"]\n",
    "\n",
    "speed_col = \"speed\"\n",
    "n_bins = 8\n",
    "\n",
    "# Manual binning range (cm/s)\n",
    "speed_min = 0.0\n",
    "speed_max = 125.0\n",
    "\n",
    "# Saving\n",
    "save_svg = True\n",
    "out_path = Path(\"speed_bins_map_outbound.svg\")\n",
    "svg_dpi = 160  # lower = smaller file; affects rasterized parts in SVG\n",
    "\n",
    "# Optional downsampling (helps guarantee small files for huge datasets)\n",
    "max_points_background = 120_000\n",
    "max_points_colored = 120_000\n",
    "rng_seed = 0\n",
    "# -------------------------------\n",
    "\n",
    "mask = (\n",
    "    trialized_position[\"zone\"].isin(zones)\n",
    "    & trialized_position[\"trial_type\"].isin(trial_types)\n",
    ")\n",
    "\n",
    "# Background: all positions within mask\n",
    "df_background = trialized_position.loc[mask, [\"position_x\", \"position_y\"]].dropna()\n",
    "\n",
    "# Clean speed values within the mask\n",
    "speed_raw = trialized_position.loc[mask, speed_col].astype(float)\n",
    "speed_raw = speed_raw.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Keep only speeds within the manual range\n",
    "in_range = speed_raw.notna() & (speed_raw >= speed_min) & (speed_raw <= speed_max)\n",
    "\n",
    "if not in_range.any():\n",
    "    raise ValueError(\n",
    "        f\"No finite speed values within [{speed_min}, {speed_max}] cm/s after applying mask.\"\n",
    "    )\n",
    "\n",
    "# Manual bin edges + centers (fixed range regardless of data)\n",
    "bin_edges = np.linspace(speed_min, speed_max, n_bins + 1)\n",
    "speed_bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Assign bins only to in-range rows (others stay NaN)\n",
    "trialized_position[\"speed_bin\"] = np.nan\n",
    "trialized_position.loc[speed_raw.index[in_range], \"speed_bin\"] = pd.cut(\n",
    "    speed_raw.loc[in_range],\n",
    "    bins=bin_edges,\n",
    "    labels=False,\n",
    "    include_lowest=True,\n",
    ").astype(int)\n",
    "\n",
    "# Colored points to plot: only those with an assigned bin\n",
    "df_colored = trialized_position.loc[\n",
    "    speed_raw.index[in_range], [\"position_x\", \"position_y\", \"speed_bin\"]\n",
    "].dropna()\n",
    "\n",
    "# Optional downsampling to keep SVG small\n",
    "if max_points_background is not None and len(df_background) > max_points_background:\n",
    "    df_background = df_background.sample(n=max_points_background, random_state=rng_seed)\n",
    "\n",
    "if max_points_colored is not None and len(df_colored) > max_points_colored:\n",
    "    df_colored = df_colored.sample(n=max_points_colored, random_state=rng_seed)\n",
    "\n",
    "# Make SVG smaller: keep text as text (not vector paths)\n",
    "plt.rcParams[\"svg.fonttype\"] = \"none\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15), layout=\"tight\")\n",
    "\n",
    "# Background points (rasterized inside SVG)\n",
    "ax.scatter(\n",
    "    df_background[\"position_x\"].to_numpy(),\n",
    "    df_background[\"position_y\"].to_numpy(),\n",
    "    s=4,\n",
    "    c=\"k\",\n",
    "    alpha=0.015,\n",
    "    linewidths=0,\n",
    "    rasterized=True,\n",
    "    zorder=1,\n",
    ")\n",
    "\n",
    "# Stepped gradient with strong bin separation\n",
    "cmap = plt.get_cmap(\"turbo\", n_bins)  # try \"plasma\" if you prefer\n",
    "boundaries = np.arange(-0.5, n_bins + 0.5, 1.0)\n",
    "norm = colors.BoundaryNorm(boundaries, ncolors=n_bins)\n",
    "\n",
    "ax.scatter(\n",
    "    df_colored[\"position_x\"].to_numpy(),\n",
    "    df_colored[\"position_y\"].to_numpy(),\n",
    "    c=df_colored[\"speed_bin\"].to_numpy(),\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    s=12,\n",
    "    alpha=1.0,\n",
    "    linewidths=0,\n",
    "    rasterized=True,\n",
    "    zorder=2,\n",
    ")\n",
    "\n",
    "# ax.set_title(\n",
    "#     f\"Speed bins across position ({zones=}, {trial_types=}, range={speed_min:g}â€“{speed_max:g} cm/s, {n_bins} bins)\"\n",
    "# )\n",
    "ax.set_xlabel(\"x position (cm)\")\n",
    "ax.set_ylabel(\"y position (cm)\")\n",
    "\n",
    "# Make the plotting area (axes box) square\n",
    "ax.set_box_aspect(1)\n",
    "\n",
    "# Optional: if you want equal data scaling too (1 cm in x == 1 cm in y), uncomment:\n",
    "# ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "# Colorbar labeled in cm/s using bin centers\n",
    "mappable = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "mappable.set_array([])\n",
    "cbar = fig.colorbar(\n",
    "    mappable,\n",
    "    ax=ax,\n",
    "    ticks=np.arange(n_bins),\n",
    "    boundaries=boundaries,\n",
    "    fraction=0.046,\n",
    "    pad=0.04,\n",
    ")\n",
    "cbar.set_label(f\"{speed_col} (bin centers, cm/s)\")\n",
    "cbar.set_ticklabels([f\"{c:.1f}\" for c in speed_bin_centers])\n",
    "\n",
    "if save_svg:\n",
    "    fig.savefig(out_path, format=\"svg\", dpi=svg_dpi, bbox_inches=\"tight\")\n",
    "    print(f\"Saved: {out_path} (dpi={svg_dpi}, rasterized points)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "549dcf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spikes_list = l_mpfc_spikes.copy()\n",
    "zone = \"run\"\n",
    "trial_type = \"outbound\"\n",
    "mask = (trialized_position[\"trial_type\"] == f\"{trial_type}\") \\\n",
    "          #  & (trialized_position[\"track_segment_id\"]==2) \\\n",
    "           #     | (trialized_position[\"track_segment_id\"]==4))\n",
    "\n",
    "\n",
    "position_tuning, position_bin_centers = compute_tuning(\n",
    "    trialized_position,  # full df\n",
    "    \"linear_position\",\n",
    "    spikes_list,\n",
    "    n_bins=8,\n",
    "    mask=mask,\n",
    ")\n",
    "\n",
    "# plot_speed_tuning_heatmap(speed_tuning)\n",
    "\n",
    "plot_tuning_grid(position_tuning, \"linear_position\", trialized_position, spikes_list, None, n_units = 33, label = f\"({zone}; {trial_type})\")\n",
    "# plot_position_tuning_grid(position_tuning, trialized_position, spikes_list, mask, n_units = -1, label = f\"entire epoch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de29f3a",
   "metadata": {},
   "source": [
    "#### Progress tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f1420da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#progress in time\n",
    "df = e2_trialized_position.copy()\n",
    "\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "# spikes_list = spikes_list[160:200]\n",
    "zones = [\"run\"]\n",
    "trial_types = [\"inbound\", \"outbound\"]\n",
    "track_segment_ids = [0, 1,2,3,4]\n",
    "\n",
    "mask = ( df[\"trial_type\"].isin(trial_types)) & \\\n",
    "            ( df[\"track_segment_id\"].isin(track_segment_ids)) & \\\n",
    "                ( df[\"zone\"].isin(zones))\n",
    "\n",
    "\n",
    "progress_tuning,  progress_centers,  progress_lower,  progress_upper, slope_boot, curvature_boot = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    \"trial_progress\",\n",
    "    spikes_list,\n",
    "    n_bins=6,\n",
    "    mask=mask,\n",
    "    trial_column=\"trial_number\",\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "\n",
    "shape_by_unit, stats_by_unit = classify_tuning_shapes_from_bootstraps(\n",
    "    slope_boot,\n",
    "    curvature_boot,\n",
    "    ci=0.95,\n",
    "    min_valid_boot=200,   # you have lots of trials; you can be strict\n",
    ")\n",
    "unit_shapes = pd.Series(shape_by_unit)\n",
    "progress_bell_unit_ids = unit_shapes[unit_shapes==\"bell\"].index.tolist()\n",
    "progress_increasing_unit_ids = unit_shapes[unit_shapes==\"increasing\"].index.tolist()\n",
    "progress_decreasing_unit_ids = unit_shapes[unit_shapes==\"decreasing\"].index.tolist()\n",
    "progress_u_unit_ids = unit_shapes[unit_shapes==\"U\"].index.tolist()\n",
    "progress_complex_unit_ids = unit_shapes[unit_shapes==\"flat/complex\"].index.tolist()\n",
    "\n",
    "\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    progress_tuning,  progress_lower,  progress_upper,  progress_centers,\n",
    "    column= \"trial_progress\", \n",
    "    n_units=50, \n",
    "    indices = None,\n",
    "    label = \"epoch 2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1ae3c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#progress in distance\n",
    "df = e4_trialized_position.copy()\n",
    "\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "# spikes_list = spikes_list[160:200]\n",
    "zones = [\"run\"]\n",
    "trial_types = [\"inbound\", \"outbound\"]\n",
    "track_segment_ids = [0, 1,2,3,4]\n",
    "\n",
    "mask = ( df[\"trial_type\"].isin(trial_types)) & \\\n",
    "            ( df[\"track_segment_id\"].isin(track_segment_ids)) & \\\n",
    "                ( df[\"zone\"].isin(zones))\n",
    "\n",
    "\n",
    "\n",
    "progress_tuning,  progress_centers,  progress_lower,  progress_upper, slope_boot, curvature_boot = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    \"trial_progress_distance\",\n",
    "    spikes_list,\n",
    "    n_bins=8,\n",
    "    mask=mask,\n",
    "    trial_column=\"trial_number\",\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "\n",
    "shape_by_unit, stats_by_unit = classify_tuning_shapes_from_bootstraps(\n",
    "    slope_boot,\n",
    "    curvature_boot,\n",
    "    ci=0.95,\n",
    "    min_valid_boot=200, \n",
    ")\n",
    "unit_shapes = pd.Series(shape_by_unit)\n",
    "progress_bell_unit_ids = unit_shapes[unit_shapes==\"bell\"].index.tolist()\n",
    "progress_increasing_unit_ids = unit_shapes[unit_shapes==\"increasing\"].index.tolist()\n",
    "progress_decreasing_unit_ids = unit_shapes[unit_shapes==\"decreasing\"].index.tolist()\n",
    "progress_u_unit_ids = unit_shapes[unit_shapes==\"U\"].index.tolist()\n",
    "progress_complex_unit_ids = unit_shapes[unit_shapes==\"flat/complex\"].index.tolist()\n",
    "\n",
    "\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    progress_tuning,  progress_lower,  progress_upper,  progress_centers,\n",
    "    column= \"trial_progress_distance\",\n",
    "    n_units=30, \n",
    "    indices = speed_decreasing_unit_ids,\n",
    "    label = \"epoch 4\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b1ad787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning time shape counts\n",
      "-------------------\n",
      "Shape           Speed   Progress\n",
      "------------ -------- ----------\n",
      "bell               26         24\n",
      "increasing         55         87\n",
      "decreasing         94         76\n",
      "U                  24          8\n",
      "flat/complex       64         68\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuning time shape counts\")\n",
    "print(\"-------------------\")\n",
    "print(f\"{'Shape':<12} {'Speed':>8} {'Progress':>10}\")\n",
    "print(f\"{'-'*12} {'-'*8:>8} {'-'*10:>10}\")\n",
    "print(f\"{'bell':<12} {len(speed_bell_unit_ids):>8} {len(progress_bell_unit_ids):>10}\")\n",
    "print(f\"{'increasing':<12} {len(speed_increasing_unit_ids):>8} {len(progress_increasing_unit_ids):>10}\")\n",
    "print(f\"{'decreasing':<12} {len(speed_decreasing_unit_ids):>8} {len(progress_decreasing_unit_ids):>10}\")\n",
    "print(f\"{'U':<12} {len(speed_u_unit_ids):>8} {len(progress_u_unit_ids):>10}\")\n",
    "print(f\"{'flat/complex':<12} {len(speed_complex_unit_ids):>8} {len(progress_complex_unit_ids):>10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "61fbffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning distance shape counts\n",
      "-------------------\n",
      "Shape           Speed   Progress\n",
      "------------ -------- ----------\n",
      "bell               26         24\n",
      "increasing         55         87\n",
      "decreasing         94         76\n",
      "U                  24          8\n",
      "flat/complex       64         68\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuning distance shape counts\")\n",
    "print(\"-------------------\")\n",
    "print(f\"{'Shape':<12} {'Speed':>8} {'Progress':>10}\")\n",
    "print(f\"{'-'*12} {'-'*8:>8} {'-'*10:>10}\")\n",
    "print(f\"{'bell':<12} {len(speed_bell_unit_ids):>8} {len(progress_bell_unit_ids):>10}\")\n",
    "print(f\"{'increasing':<12} {len(speed_increasing_unit_ids):>8} {len(progress_increasing_unit_ids):>10}\")\n",
    "print(f\"{'decreasing':<12} {len(speed_decreasing_unit_ids):>8} {len(progress_decreasing_unit_ids):>10}\")\n",
    "print(f\"{'U':<12} {len(speed_u_unit_ids):>8} {len(progress_u_unit_ids):>10}\")\n",
    "print(f\"{'flat/complex':<12} {len(speed_complex_unit_ids):>8} {len(progress_complex_unit_ids):>10}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276b0e4",
   "metadata": {},
   "source": [
    "#### Speed vs progress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0629c1df",
   "metadata": {},
   "source": [
    "##### Calculate in various progress segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47fd293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old method\n",
    "df = trialized_position.copy()\n",
    "\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "# spikes_list = spikes_list[160:200]\n",
    "zones = [\"run\"]\n",
    "trial_types = [\"inbound\", \"outbound\"]\n",
    "track_segment_ids = [0, 1,2,3,4]\n",
    "\n",
    "mask = ( df[\"trial_type\"].isin(trial_types)) & \\\n",
    "            ( df[\"track_segment_id\"].isin(track_segment_ids)) & \\\n",
    "                ( df[\"zone\"].isin(zones)) & \\\n",
    "                    (df[\"trial_progress_distance\"]>0) & (df[\"trial_progress_distance\"]<0.5) # explicit progress bins - for visual examination.\n",
    "\n",
    "\n",
    "n_bins = 6\n",
    "tuner_bins = np.linspace(0, 120, n_bins + 1)\n",
    "tuner_bin_centers = (tuner_bins[:-1] + tuner_bins[1:]) / 2\n",
    "\n",
    "\n",
    "# bootstrap across trials\n",
    "speed_tuning, speed_centers, speed_lower, speed_upper, slope_boot, curvature_boot = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    \"speed\",\n",
    "    spikes_list,\n",
    "    n_bins=6,\n",
    "    mask=mask,\n",
    "    trial_column=\"trial_number\",\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    "    # tuner_bins= tuner_bins,\n",
    "    binning = \"sliding\", # ignores n_bins when \"sliding\"\n",
    "    window_width = 20,\n",
    "    window_step = 2,\n",
    "    tuner_min = 0,\n",
    "    tuner_max = 120,\n",
    "    peak_normalize = True\n",
    ")\n",
    "\n",
    "\n",
    "shape_by_unit, stats_by_unit = classify_tuning_shapes_from_bootstraps(\n",
    "    slope_boot,\n",
    "    curvature_boot,\n",
    "    ci=0.95,\n",
    "    min_valid_boot=200,   \n",
    ")\n",
    "unit_shapes = pd.Series(shape_by_unit)\n",
    "speed_bell_unit_ids = unit_shapes[unit_shapes==\"bell\"].index.tolist()\n",
    "speed_increasing_unit_ids = unit_shapes[unit_shapes==\"increasing\"].index.tolist()\n",
    "speed_decreasing_unit_ids = unit_shapes[unit_shapes==\"decreasing\"].index.tolist()\n",
    "speed_u_unit_ids = unit_shapes[unit_shapes==\"U\"].index.tolist()\n",
    "speed_complex_unit_ids = unit_shapes[unit_shapes==\"flat/complex\"].index.tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6287d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    speed_tuning, speed_lower, speed_upper, speed_centers,\n",
    "    column=\"speed\", \n",
    "    n_units=30, \n",
    "    indices = None,\n",
    "    label = \"all eps\",\n",
    "    peak_normalize = True, \n",
    "    s = 2,\n",
    "    linewidth = 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb97549",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = trialized_position.copy()\n",
    "# spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "# # -----------------------\n",
    "# # 1) Base mask (no progress restriction yet)\n",
    "# # -----------------------\n",
    "# zones = [\"run\"]\n",
    "# trial_types = [\"inbound\", \"outbound\"]\n",
    "# track_segment_ids = [0, 1, 2, 3, 4]\n",
    "\n",
    "# base_mask = (\n",
    "#     df[\"trial_type\"].isin(trial_types)\n",
    "#     & df[\"track_segment_id\"].isin(track_segment_ids)\n",
    "#     & df[\"zone\"].isin(zones)\n",
    "#     & df[\"trial_number\"].notna()\n",
    "#     & np.isfinite(df[\"speed_norm\"].to_numpy())\n",
    "#     & np.isfinite(df[\"trial_progress_distance\"].to_numpy())\n",
    "# )\n",
    "\n",
    "# # dt for converting sample counts -> seconds (same assumption as your tuning code)\n",
    "# timestamps = df.index.to_numpy()\n",
    "# dt = float(np.median(np.diff(timestamps)))\n",
    "# if not np.isfinite(dt) or dt <= 0:\n",
    "#     raise ValueError(\"Bad dt from df.index; check that df.index is sorted and in seconds.\")\n",
    "\n",
    "# # -----------------------\n",
    "# # 2) Define progress windows cleanly and consistently\n",
    "# #    (use 0..1, include endpoints)\n",
    "# # -----------------------\n",
    "# progress = df[\"trial_progress\"].to_numpy()\n",
    "# progress = np.clip(progress, 0.0, 1.0)\n",
    "\n",
    "# # 3 bins: 0â€“0.33, 0.33â€“0.66, 0.66â€“1.0\n",
    "# # (you can change these edges if you want exactly 0.30 etc.)\n",
    "# # progress_edges = np.array([0.0, 0.33, 0.66, 1.0], dtype=float)\n",
    "# progress_edges = np.array([0.0, 0.5, 1.0], dtype=float)\n",
    "\n",
    "# # progress_labels = [\"early(0-33)\", \"mid(33-66)\", \"late(66-100)\"]\n",
    "# progress_labels = [\"early(0-50)\", \"late (50 - 100)\"]\n",
    "\n",
    "# df[\"_progress_bin\"] = pd.cut(\n",
    "#     progress,\n",
    "#     bins=progress_edges,\n",
    "#     include_lowest=True,\n",
    "#     right=True,\n",
    "#     labels=progress_labels,\n",
    "# )\n",
    "\n",
    "\n",
    "# min_time_per_trial_per_window_s = 0.5  # tweak: 0.2â€“1.0s depending on data density\n",
    "\n",
    "# df_base = df.loc[base_mask, [\"trial_number\", \"_progress_bin\"]].copy()\n",
    "# df_base = df_base.dropna(subset=[\"trial_number\", \"_progress_bin\"])\n",
    "# df_base[\"trial_number\"] = df_base[\"trial_number\"].astype(int)\n",
    "\n",
    "# # time per (trial, progress_bin) in seconds\n",
    "# counts = (\n",
    "#     df_base.groupby([\"trial_number\", \"_progress_bin\"])\n",
    "#     .size()\n",
    "#     .unstack(fill_value=0)\n",
    "# )\n",
    "\n",
    "# # make sure all bins exist as columns (even if empty)\n",
    "# for lab in progress_labels:\n",
    "#     if lab not in counts.columns:\n",
    "#         counts[lab] = 0\n",
    "# counts = counts[progress_labels]\n",
    "\n",
    "# time_sec = counts * dt\n",
    "# eligible_trials = time_sec.index[\n",
    "#     (time_sec >= min_time_per_trial_per_window_s).all(axis=1)\n",
    "# ].to_numpy()\n",
    "\n",
    "# print(\"Total trials under base_mask:\", df_base[\"trial_number\"].nunique())\n",
    "# print(\"Eligible trials (enough time in all windows):\", len(eligible_trials))\n",
    "# if len(eligible_trials) < 2:\n",
    "#     raise ValueError(\n",
    "#         \"Too few eligible trials after requiring per-window time. \"\n",
    "#         \"Lower min_time_per_trial_per_window_s or relax base_mask.\"\n",
    "#     )\n",
    "\n",
    "# eligible_trial_mask = df[\"trial_number\"].isin(eligible_trials)\n",
    "\n",
    "\n",
    "# n_bins = 6\n",
    "# tuner_bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "\n",
    "\n",
    "# window_results = {}\n",
    "\n",
    "# for lab in progress_labels:\n",
    "#     win_mask = base_mask & eligible_trial_mask & (df[\"_progress_bin\"] == lab)\n",
    "\n",
    "#     out = compute_tuning_bootstrap_trials(\n",
    "#         df,\n",
    "#         \"speed_norm\",\n",
    "#         spikes_list,\n",
    "#         n_bins=n_bins,\n",
    "#         mask=win_mask,\n",
    "#         trial_column=\"trial_number\",\n",
    "#         n_boot=500,\n",
    "#         random_state=0,\n",
    "#         tuner_bins=tuner_bins,\n",
    "#     )\n",
    "#     speed_tuning, speed_centers, speed_lower, speed_upper, slope_boot, curvature_boot = out\n",
    "\n",
    "#     window_results[lab] = dict(\n",
    "#         speed_tuning=speed_tuning,\n",
    "#         speed_centers=speed_centers,\n",
    "#         speed_lower=speed_lower,\n",
    "#         speed_upper=speed_upper,\n",
    "#         slope_boot=slope_boot,\n",
    "#         curvature_boot=curvature_boot,\n",
    "#         win_mask=win_mask,\n",
    "#     )\n",
    "\n",
    "# # -----------------------\n",
    "# # 6) Visual compare (one plot per window)\n",
    "# # -----------------------\n",
    "# for lab in progress_labels:\n",
    "#     res = window_results[lab]\n",
    "#     plot_tuning_grid_bootstrap(\n",
    "#         res[\"speed_tuning\"],\n",
    "#         res[\"speed_lower\"],\n",
    "#         res[\"speed_upper\"],\n",
    "#         res[\"speed_centers\"],\n",
    "#         column=\"speed_norm\",\n",
    "#         n_units=50,\n",
    "#         indices=None,\n",
    "#         label=f\"{lab} | eligible_trials={len(eligible_trials)} | min_time={min_time_per_trial_per_window_s}s\",\n",
    "#     )\n",
    "\n",
    "# # Optional: store for later metric comparisons\n",
    "# (speed_tuning_early, speed_tuning_mid, speed_tuning_late) = (\n",
    "#     window_results[progress_labels[0]][\"speed_tuning\"],\n",
    "#     window_results[progress_labels[1]][\"speed_tuning\"],\n",
    "#     window_results[progress_labels[2]][\"speed_tuning\"],\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e2328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid speed bins: [0 1 2 3 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labuser/miniforge3/envs/spyglass/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compare_speed_tuning_across_progress_segments(\n",
    "    trialized_position_df: pd.DataFrame,\n",
    "    spikes_list: list,\n",
    "    base_mask: np.ndarray,\n",
    "    progress_col: str,\n",
    "    progress_edges: np.ndarray,\n",
    "    progress_labels: list,\n",
    "    speed_col: str = \"speed\",\n",
    "    trial_col: str = \"trial_number\",\n",
    "    tuner_bins: np.ndarray = None,\n",
    "    n_boot: int = 500,\n",
    "    random_state: int = 0,\n",
    "    # occupancy / stratification controls\n",
    "    min_speedbin_occupancy_s: float = 1.0,\n",
    "    stratify_equalize_speedbin_occupancy: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      segment_results[label] = dict(tuning, lo, hi, centers, mask, occ_s_per_speedbin)\n",
    "      valid_speed_bins_mask\n",
    "      pairwise_metrics[(label_i, label_j)] = dict per-unit metrics\n",
    "    \"\"\"\n",
    "    df = trialized_position_df.copy()\n",
    "\n",
    "    if tuner_bins is None:\n",
    "        raise ValueError(\"Pass tuner_bins (fixed across segments).\")\n",
    "\n",
    "    # dt from index\n",
    "    timestamps = df.index.to_numpy()\n",
    "    dt = float(np.median(np.diff(timestamps)))\n",
    "    if not np.isfinite(dt) or dt <= 0:\n",
    "        raise ValueError(\"Bad dt; ensure df.index sorted and in seconds.\")\n",
    "\n",
    "    # base validity\n",
    "    base_mask = np.asarray(base_mask, bool).copy()\n",
    "    base_mask &= df[trial_col].notna().to_numpy()\n",
    "    base_mask &= np.isfinite(df[speed_col].to_numpy())\n",
    "    base_mask &= np.isfinite(df[progress_col].to_numpy())\n",
    "\n",
    "    # assign segment labels\n",
    "    progress_vals = np.clip(df[progress_col].to_numpy(), 0.0, 1.0)\n",
    "    seg_series = pd.cut(\n",
    "        progress_vals,\n",
    "        bins=np.asarray(progress_edges, float),\n",
    "        include_lowest=True,\n",
    "        right=True,\n",
    "        labels=progress_labels,\n",
    "    )\n",
    "    seg_labels = seg_series.to_numpy()\n",
    "\n",
    "    # speed bin index per sample (0..n_bins-1)\n",
    "    speed_vals = df[speed_col].to_numpy()\n",
    "    n_speed_bins = len(tuner_bins) - 1\n",
    "    speed_bin_idx = np.searchsorted(tuner_bins, speed_vals, side=\"right\") - 1\n",
    "    speed_bin_idx = np.clip(speed_bin_idx, 0, n_speed_bins - 1)\n",
    "\n",
    "    # --- compute occupancy per segment per speed bin ---\n",
    "    occ_s_by_segment = {}\n",
    "    sample_indices_by_segment_and_speedbin = {}\n",
    "\n",
    "    for label in progress_labels:\n",
    "        seg_mask = base_mask & (seg_labels == label)\n",
    "        seg_idx = np.where(seg_mask)[0]\n",
    "\n",
    "        # occupancy seconds per speed bin for this segment\n",
    "        b = speed_bin_idx[seg_idx]\n",
    "        counts = np.bincount(b, minlength=n_speed_bins)\n",
    "        occ_s = counts * dt\n",
    "        occ_s_by_segment[label] = occ_s\n",
    "\n",
    "        # store sample indices per speed bin (for optional equalization)\n",
    "        sample_indices_by_segment_and_speedbin[label] = [\n",
    "            seg_idx[b == bin_id] for bin_id in range(n_speed_bins)\n",
    "        ]\n",
    "\n",
    "    # valid bins are those with enough occupancy in ALL segments\n",
    "    valid_speed_bins_mask = np.ones(n_speed_bins, dtype=bool)\n",
    "    for label in progress_labels:\n",
    "        valid_speed_bins_mask &= (occ_s_by_segment[label] >= min_speedbin_occupancy_s)\n",
    "\n",
    "    # If no overlap, you cannot compare fairly\n",
    "    if valid_speed_bins_mask.sum() < 2:\n",
    "        raise ValueError(\n",
    "            f\"Too few overlapping speed bins across segments with >= {min_speedbin_occupancy_s}s occupancy. \"\n",
    "            f\"Try lowering min_speedbin_occupancy_s or using fewer speed bins.\"\n",
    "        )\n",
    "\n",
    "    # --- build stratified masks per segment ---\n",
    "    segment_masks = {}\n",
    "\n",
    "    if stratify_equalize_speedbin_occupancy:\n",
    "        # Equalize occupancy per speed bin across segments:\n",
    "        # for each speed bin, target the MIN occupancy among segments, then downsample samples to match it\n",
    "        rng = np.random.default_rng(random_state)\n",
    "\n",
    "        target_occ_s_per_bin = np.zeros(n_speed_bins, float)\n",
    "        for bin_id in range(n_speed_bins):\n",
    "            if not valid_speed_bins_mask[bin_id]:\n",
    "                target_occ_s_per_bin[bin_id] = 0.0\n",
    "                continue\n",
    "            target_occ_s_per_bin[bin_id] = min(occ_s_by_segment[label][bin_id] for label in progress_labels)\n",
    "\n",
    "        target_counts_per_bin = np.floor(target_occ_s_per_bin / dt).astype(int)\n",
    "\n",
    "        for label in progress_labels:\n",
    "            keep_indices = []\n",
    "            for bin_id in range(n_speed_bins):\n",
    "                if not valid_speed_bins_mask[bin_id]:\n",
    "                    continue\n",
    "                bin_indices = sample_indices_by_segment_and_speedbin[label][bin_id]\n",
    "                if bin_indices.size == 0:\n",
    "                    continue\n",
    "                k = target_counts_per_bin[bin_id]\n",
    "                if k <= 0:\n",
    "                    continue\n",
    "                if bin_indices.size <= k:\n",
    "                    chosen = bin_indices\n",
    "                else:\n",
    "                    chosen = rng.choice(bin_indices, size=k, replace=False)\n",
    "                keep_indices.append(chosen)\n",
    "\n",
    "            keep_indices = np.concatenate(keep_indices) if len(keep_indices) else np.array([], dtype=int)\n",
    "            mask = np.zeros(len(df), dtype=bool)\n",
    "            mask[keep_indices] = True\n",
    "            segment_masks[label] = mask\n",
    "\n",
    "    else:\n",
    "        # Common-support only: keep all samples in segment but restrict to valid speed bins\n",
    "        for label in progress_labels:\n",
    "            seg_mask = base_mask & (seg_labels == label) & valid_speed_bins_mask[speed_bin_idx]\n",
    "            segment_masks[label] = seg_mask\n",
    "\n",
    "    # --- compute tuning per segment using your existing function ---\n",
    "    segment_results = {}\n",
    "    for label in progress_labels:\n",
    "        out = compute_tuning_bootstrap_trials(\n",
    "            df,\n",
    "            column=speed_col,\n",
    "            spikes_list=spikes_list,\n",
    "            n_bins=n_speed_bins,\n",
    "            # tuner_bins=tuner_bins, #comment out if binning = \"sliding\"\n",
    "            mask=segment_masks[label],\n",
    "            trial_column=trial_col,\n",
    "            n_boot=n_boot,\n",
    "            ci=0.95,\n",
    "            random_state=random_state,\n",
    "            binning = \"edges\",\n",
    "            window_step = 2,\n",
    "            window_width = 20,\n",
    "            tuner_min = 0,\n",
    "            tuner_max = 120,\n",
    "            peak_normalize = True\n",
    "        )\n",
    "        tuning, centers, lo, hi, slope_boot, curv_boot = out\n",
    "        segment_results[label] = dict(\n",
    "            tuning=tuning, centers=centers, lo=lo, hi=hi,\n",
    "            mask=segment_masks[label],\n",
    "            occ_s_per_speedbin=occ_s_by_segment[label],\n",
    "            slope_boot=slope_boot, curv_boot=curv_boot,\n",
    "        )\n",
    "\n",
    "    # --- pairwise curve-comparison metrics (per unit) ---\n",
    "    # (use only bins that are valid across segments)\n",
    "    valid_bins = valid_speed_bins_mask\n",
    "\n",
    "    def restrict_curve(curve):\n",
    "        c = np.asarray(curve, float).copy()\n",
    "        c[~valid_bins] = np.nan\n",
    "        return c\n",
    "\n",
    "    pairwise_metrics = {}\n",
    "    for i in range(len(progress_labels)):\n",
    "        for j in range(i + 1, len(progress_labels)):\n",
    "            li = progress_labels[i]\n",
    "            lj = progress_labels[j]\n",
    "\n",
    "            metrics_per_unit = {}\n",
    "            for unit_id in segment_results[li][\"tuning\"].keys():\n",
    "                ci = restrict_curve(segment_results[li][\"tuning\"][unit_id])\n",
    "                cj = restrict_curve(segment_results[lj][\"tuning\"][unit_id])\n",
    "\n",
    "                metrics_per_unit[unit_id] = dict(\n",
    "                    corr=curve_corr(ci, cj),\n",
    "                    nrmse=nrmse(ci, cj),\n",
    "                    peak_shift_bins=peak_bin_shift(ci, cj),\n",
    "                    mean_rate_diff=mean_rate_diff(ci, cj),\n",
    "                )\n",
    "\n",
    "            pairwise_metrics[(li, lj)] = metrics_per_unit\n",
    "\n",
    "    return segment_results, valid_speed_bins_mask, pairwise_metrics\n",
    "\n",
    "\n",
    "progress_edges = np.array([0.0, 0.5, 1.0])\n",
    "progress_labels = [\"early\", \"late\"]\n",
    "\n",
    "\n",
    "df = trialized_position.copy()\n",
    "segment_results, valid_speed_bins_mask, pairwise_metrics = compare_speed_tuning_across_progress_segments(\n",
    "    trialized_position_df=df,\n",
    "    spikes_list=spikes_list,\n",
    "    base_mask=base_mask,\n",
    "    progress_col=\"trial_progress_distance\",             \n",
    "    progress_edges=progress_edges,\n",
    "    progress_labels=progress_labels,\n",
    "    speed_col=\"speed\",\n",
    "    trial_col=\"trial_number\",\n",
    "    tuner_bins=tuner_bins,\n",
    "    n_boot=500, \n",
    "    random_state=0,\n",
    "    min_speedbin_occupancy_s=1.0,\n",
    "    stratify_equalize_speedbin_occupancy=True,  \n",
    ")\n",
    "\n",
    "print(\"Valid speed bins:\", np.where(valid_speed_bins_mask)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "366ecba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot\n",
    "for lab in progress_labels:\n",
    "    res = segment_results[lab]\n",
    "    plot_tuning_grid_bootstrap(\n",
    "        res[\"tuning\"], res[\"lo\"], res[\"hi\"], res[\"centers\"],\n",
    "        column=\"speed\", n_units=50, label=f\"{lab} \", peak_normalize = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0aa7f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_speed_tuning_across_progress_segments(\n",
    "    trialized_position_df: pd.DataFrame,\n",
    "    spikes_list: list,\n",
    "    base_mask: np.ndarray,\n",
    "    progress_col: str,\n",
    "    progress_edges: np.ndarray,\n",
    "    progress_labels: list,\n",
    "    speed_col: str = \"speed\",\n",
    "    trial_col: str = \"trial_number\",\n",
    "    tuner_bins: np.ndarray = None,  # used for binning='edges' OR (by default) for stratification when binning='sliding'\n",
    "    n_boot: int = 500,\n",
    "    random_state: int = 0,\n",
    "    # occupancy / stratification controls\n",
    "    min_speedbin_occupancy_s: float = 1.0,\n",
    "    stratify_equalize_speedbin_occupancy: bool = True,\n",
    "    # NEW: make this compatible with compute_tuning_bootstrap_trials(binning=\"sliding\")\n",
    "    binning: str = \"sliding\",\n",
    "    window_width: float = 20.0,\n",
    "    window_step: float = 2.0,\n",
    "    tuner_min: float = 0.0,\n",
    "    tuner_max: float = 120.0,\n",
    "    stratify_bins: np.ndarray = None,\n",
    "    peak_normalize: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    segment_results[label] = dict(\n",
    "        tuning, lo, hi, centers, mask,\n",
    "        occ_s_per_tuningbin,\n",
    "        slope_boot, curv_boot,\n",
    "    )\n",
    "    valid_speed_bins_mask : np.ndarray[bool]\n",
    "        Mask over *tuning bins* (i.e., histogram bins for binning='edges' OR sliding-window centers for binning='sliding')\n",
    "        that have >= min_speedbin_occupancy_s in ALL segments after applying segment_masks.\n",
    "    pairwise_metrics[(label_i, label_j)] : dict\n",
    "        Per-unit curve comparison metrics, computed after restricting curves to valid_speed_bins_mask.\n",
    "    \"\"\"\n",
    "    def _validate_binning_mode(m: str) -> str:\n",
    "        if m is None:\n",
    "            return \"edges\"\n",
    "        m = str(m).strip().lower()\n",
    "        if m in {\"edge\", \"edges\", \"discrete\", \"hist\", \"histogram\"}:\n",
    "            return \"edges\"\n",
    "        if m in {\"sliding\", \"moving\", \"moving_window\", \"moving-window\", \"continuous\"}:\n",
    "            return \"sliding\"\n",
    "        raise ValueError(f\"Unknown binning mode {m!r}. Expected 'edges' or 'sliding'.\")\n",
    "\n",
    "    def _counts_in_windows(values: np.ndarray, left_edges: np.ndarray, right_edges: np.ndarray) -> np.ndarray:\n",
    "        # counts in half-open intervals [left, right)\n",
    "        left_edges = np.asarray(left_edges, dtype=float)\n",
    "        right_edges = np.asarray(right_edges, dtype=float)\n",
    "        if left_edges.shape != right_edges.shape:\n",
    "            raise ValueError(\"left_edges and right_edges must have the same shape\")\n",
    "        values = np.asarray(values, dtype=float)\n",
    "        values = values[np.isfinite(values)]\n",
    "        if values.size == 0:\n",
    "            return np.zeros(left_edges.shape, dtype=np.int64)\n",
    "        values_sorted = np.sort(values)\n",
    "        li = np.searchsorted(values_sorted, left_edges, side=\"left\")\n",
    "        ri = np.searchsorted(values_sorted, right_edges, side=\"left\")\n",
    "        return (ri - li).astype(np.int64)\n",
    "\n",
    "    df = trialized_position_df.copy()\n",
    "\n",
    "    mode = _validate_binning_mode(binning)\n",
    "\n",
    "    # dt from index\n",
    "    timestamps = df.index.to_numpy()\n",
    "    if len(timestamps) < 2:\n",
    "        raise ValueError(\"df must have at least 2 timestamped samples\")\n",
    "    dt = float(np.median(np.diff(timestamps)))\n",
    "    if not np.isfinite(dt) or dt <= 0:\n",
    "        raise ValueError(\"Bad dt; ensure df.index sorted and in seconds.\")\n",
    "\n",
    "    # base validity\n",
    "    base_mask = np.asarray(base_mask, bool).copy()\n",
    "    base_mask &= df[trial_col].notna().to_numpy()\n",
    "    speed_vals = df[speed_col].to_numpy(dtype=float)\n",
    "    prog_vals_raw = df[progress_col].to_numpy(dtype=float)\n",
    "    base_mask &= np.isfinite(speed_vals)\n",
    "    base_mask &= np.isfinite(prog_vals_raw)\n",
    "\n",
    "    # For sliding windows, avoid \"stratify bins grabbing out-of-range samples that never contribute to tuning\"\n",
    "    # by restricting to the analysis range.\n",
    "    if mode == \"edges\":\n",
    "        if tuner_bins is None:\n",
    "            raise ValueError(\"Pass tuner_bins when binning='edges'.\")\n",
    "        tuner_bins = np.asarray(tuner_bins, dtype=float)\n",
    "        if tuner_bins.ndim != 1 or tuner_bins.size < 2 or not np.all(np.diff(tuner_bins) > 0):\n",
    "            raise ValueError(\"tuner_bins must be 1D and strictly increasing.\")\n",
    "        base_mask &= (speed_vals >= tuner_bins[0]) & (speed_vals <= tuner_bins[-1])\n",
    "    else:\n",
    "        if window_width is None or (not np.isfinite(window_width)) or window_width <= 0:\n",
    "            raise ValueError(\"For binning='sliding', window_width must be a positive number.\")\n",
    "        if window_step is None:\n",
    "            window_step = window_width / 2.0\n",
    "        if (not np.isfinite(window_step)) or window_step <= 0:\n",
    "            raise ValueError(\"For binning='sliding', window_step must be a positive number.\")\n",
    "        if tuner_min is None or tuner_max is None:\n",
    "            # If user leaves these as None, lock them globally (across ALL segments) so centers match.\n",
    "            masked_vals = speed_vals[base_mask]\n",
    "            if masked_vals.size == 0:\n",
    "                raise ValueError(\"Mask leaves zero samples; cannot infer tuner_min/tuner_max.\")\n",
    "            if tuner_min is None:\n",
    "                tuner_min = float(np.nanmin(masked_vals))\n",
    "            if tuner_max is None:\n",
    "                tuner_max = float(np.nanmax(masked_vals))\n",
    "        if (not np.isfinite(tuner_min)) or (not np.isfinite(tuner_max)) or tuner_max <= tuner_min:\n",
    "            raise ValueError(\"Invalid tuner_min/tuner_max for sliding-window binning.\")\n",
    "        base_mask &= (speed_vals >= tuner_min) & (speed_vals <= tuner_max)\n",
    "\n",
    "    # assign segment labels\n",
    "    progress_vals = np.clip(prog_vals_raw, 0.0, 1.0)\n",
    "    seg_series = pd.cut(\n",
    "        progress_vals,\n",
    "        bins=np.asarray(progress_edges, float),\n",
    "        include_lowest=True,\n",
    "        right=True,\n",
    "        labels=progress_labels,\n",
    "    )\n",
    "    seg_labels = seg_series.to_numpy()\n",
    "\n",
    "    # ---- define tuning bins/windows (must be FIXED across segments) ----\n",
    "    if mode == \"edges\":\n",
    "        tuning_centers = (tuner_bins[:-1] + tuner_bins[1:]) / 2.0\n",
    "        tuning_left = tuner_bins[:-1]\n",
    "        tuning_right = tuner_bins[1:]\n",
    "        n_tuning_bins = int(tuning_centers.size)\n",
    "    else:\n",
    "        start = float(tuner_min) + float(window_width) / 2.0\n",
    "        stop = float(tuner_max) - float(window_width) / 2.0\n",
    "        if stop < start:\n",
    "            raise ValueError(\n",
    "                \"window_width is larger than the available tuner range; \"\n",
    "                \"choose smaller window_width or widen tuner_min/tuner_max.\"\n",
    "            )\n",
    "        tuning_centers = np.arange(start, stop + (float(window_step) * 0.5), float(window_step), dtype=float)\n",
    "        tuning_left = tuning_centers - float(window_width) / 2.0\n",
    "        tuning_right = tuning_centers + float(window_width) / 2.0\n",
    "        n_tuning_bins = int(tuning_centers.size)\n",
    "        if n_tuning_bins < 2:\n",
    "            raise ValueError(\"Sliding-window setup produced <2 tuning bins; adjust range/step/width.\")\n",
    "\n",
    "    # ---- stratification bins (NON-overlapping) used only for downsampling ----\n",
    "    if stratify_bins is not None:\n",
    "        stratify_bins = np.asarray(stratify_bins, dtype=float)\n",
    "    elif tuner_bins is not None:\n",
    "        # Keep old behavior: if you passed tuner_bins, use it for stratification by default.\n",
    "        stratify_bins = np.asarray(tuner_bins, dtype=float)\n",
    "    else:\n",
    "        # Reasonable default for sliding: non-overlapping bins at window_step resolution.\n",
    "        if mode == \"sliding\":\n",
    "            bw = float(window_step)\n",
    "            if bw <= 0 or (not np.isfinite(bw)):\n",
    "                bw = float(window_width) / 2.0\n",
    "            stratify_bins = np.arange(float(tuner_min), float(tuner_max) + bw, bw, dtype=float)\n",
    "        else:\n",
    "            raise ValueError(\"Need tuner_bins or stratify_bins for stratification.\")\n",
    "\n",
    "    if stratify_bins.ndim != 1 or stratify_bins.size < 2 or not np.all(np.diff(stratify_bins) > 0):\n",
    "        raise ValueError(\"stratify_bins must be 1D and strictly increasing.\")\n",
    "    n_strat_bins = int(stratify_bins.size - 1)\n",
    "\n",
    "    # assign stratification bin index per sample (0..n_strat_bins-1), mark out-of-range invalid\n",
    "    in_strat_range = (speed_vals >= stratify_bins[0]) & (speed_vals <= stratify_bins[-1]) & np.isfinite(speed_vals)\n",
    "    base_mask &= in_strat_range\n",
    "\n",
    "    strat_bin_idx = np.searchsorted(stratify_bins, speed_vals, side=\"right\") - 1\n",
    "    strat_bin_idx[strat_bin_idx == n_strat_bins] = n_strat_bins - 1  # exact right edge\n",
    "    strat_bin_idx = np.clip(strat_bin_idx, 0, n_strat_bins - 1)\n",
    "\n",
    "    # ---- gather indices per segment x stratbin ----\n",
    "    occ_s_by_segment_strat = {}\n",
    "    sample_indices_by_segment_and_stratbin = {}\n",
    "\n",
    "    for label in progress_labels:\n",
    "        seg_mask = base_mask & (seg_labels == label)\n",
    "        seg_idx = np.where(seg_mask)[0]\n",
    "\n",
    "        b = strat_bin_idx[seg_idx]\n",
    "        counts = np.bincount(b, minlength=n_strat_bins)\n",
    "        occ_s = counts * dt\n",
    "        occ_s_by_segment_strat[label] = occ_s\n",
    "\n",
    "        sample_indices_by_segment_and_stratbin[label] = [\n",
    "            seg_idx[b == bin_id] for bin_id in range(n_strat_bins)\n",
    "        ]\n",
    "\n",
    "    # valid strat bins: enough occupancy in ALL segments (this is what we can *fairly* equalize over)\n",
    "    valid_strat_bins_mask = np.ones(n_strat_bins, dtype=bool)\n",
    "    for label in progress_labels:\n",
    "        valid_strat_bins_mask &= (occ_s_by_segment_strat[label] >= float(min_speedbin_occupancy_s))\n",
    "\n",
    "    if valid_strat_bins_mask.sum() < 2:\n",
    "        raise ValueError(\n",
    "            f\"Too few overlapping stratification bins across segments with >= {min_speedbin_occupancy_s}s occupancy. \"\n",
    "            f\"Try lowering min_speedbin_occupancy_s, widening stratify bins, or using fewer progress segments.\"\n",
    "        )\n",
    "\n",
    "    # ---- build per-segment sample masks (optionally equalized across strat bins) ----\n",
    "    segment_masks = {}\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    if stratify_equalize_speedbin_occupancy:\n",
    "        target_occ_s_per_bin = np.zeros(n_strat_bins, dtype=float)\n",
    "        for bin_id in range(n_strat_bins):\n",
    "            if not valid_strat_bins_mask[bin_id]:\n",
    "                continue\n",
    "            target_occ_s_per_bin[bin_id] = min(\n",
    "                occ_s_by_segment_strat[label][bin_id] for label in progress_labels\n",
    "            )\n",
    "        target_counts_per_bin = np.floor(target_occ_s_per_bin / dt).astype(int)\n",
    "\n",
    "        for label in progress_labels:\n",
    "            keep_indices = []\n",
    "            for bin_id in range(n_strat_bins):\n",
    "                if not valid_strat_bins_mask[bin_id]:\n",
    "                    continue\n",
    "                bin_indices = sample_indices_by_segment_and_stratbin[label][bin_id]\n",
    "                k = int(target_counts_per_bin[bin_id])\n",
    "                if k <= 0 or bin_indices.size == 0:\n",
    "                    continue\n",
    "                if bin_indices.size <= k:\n",
    "                    chosen = bin_indices\n",
    "                else:\n",
    "                    chosen = rng.choice(bin_indices, size=k, replace=False)\n",
    "                keep_indices.append(chosen)\n",
    "\n",
    "            keep_indices = np.concatenate(keep_indices) if keep_indices else np.array([], dtype=int)\n",
    "            mask = np.zeros(len(df), dtype=bool)\n",
    "            mask[keep_indices] = True\n",
    "            segment_masks[label] = mask\n",
    "    else:\n",
    "        # \"common support only\" at strat-bin level: keep all samples in segment but restrict to valid strat bins\n",
    "        for label in progress_labels:\n",
    "            seg_mask = base_mask & (seg_labels == label) & valid_strat_bins_mask[strat_bin_idx]\n",
    "            segment_masks[label] = seg_mask\n",
    "\n",
    "    # ---- occupancy per *tuning bin/window* AFTER applying segment_masks ----\n",
    "    occ_s_by_segment_tuning = {}\n",
    "    for label in progress_labels:\n",
    "        vals = speed_vals[segment_masks[label]]\n",
    "        if mode == \"edges\":\n",
    "            occ_counts = np.histogram(vals, bins=tuner_bins)[0].astype(np.int64)\n",
    "        else:\n",
    "            occ_counts = _counts_in_windows(vals, tuning_left, tuning_right).astype(np.int64)\n",
    "        occ_s_by_segment_tuning[label] = occ_counts * dt\n",
    "\n",
    "    # valid tuning bins/windows are those with enough occupancy in ALL segments\n",
    "    valid_speed_bins_mask = np.ones(n_tuning_bins, dtype=bool)\n",
    "    for label in progress_labels:\n",
    "        valid_speed_bins_mask &= (occ_s_by_segment_tuning[label] >= float(min_speedbin_occupancy_s))\n",
    "\n",
    "    if valid_speed_bins_mask.sum() < 2:\n",
    "        raise ValueError(\n",
    "            f\"Too few overlapping tuning bins/windows across segments with >= {min_speedbin_occupancy_s}s occupancy. \"\n",
    "            f\"Try lowering min_speedbin_occupancy_s, using a larger window_width, or widening tuner_min/tuner_max.\"\n",
    "        )\n",
    "\n",
    "    # ---- compute tuning per segment ----\n",
    "    segment_results = {}\n",
    "    for label in progress_labels:\n",
    "        out = compute_tuning_bootstrap_trials(\n",
    "            df,\n",
    "            column=speed_col,\n",
    "            spikes_list=spikes_list,\n",
    "            n_bins=n_tuning_bins,\n",
    "            mask=segment_masks[label],\n",
    "            trial_column=trial_col,\n",
    "            n_boot=n_boot,\n",
    "            ci=0.95,\n",
    "            random_state=random_state,\n",
    "            tuner_bins=(tuner_bins if mode == \"edges\" else None),\n",
    "            binning=mode,\n",
    "            window_step=(float(window_step) if mode == \"sliding\" else None),\n",
    "            window_width=(float(window_width) if mode == \"sliding\" else None),\n",
    "            tuner_min=(float(tuner_min) if mode == \"sliding\" else None),\n",
    "            tuner_max=(float(tuner_max) if mode == \"sliding\" else None),\n",
    "            peak_normalize=peak_normalize,\n",
    "        )\n",
    "        tuning, centers, lo, hi, slope_boot, curv_boot = out\n",
    "\n",
    "        # sanity: centers should be identical across segments if we fixed params\n",
    "        if centers.shape[0] != n_tuning_bins:\n",
    "            raise ValueError(\n",
    "                f\"compute_tuning_bootstrap_trials returned {centers.shape[0]} bins, \"\n",
    "                f\"but compare_* expected {n_tuning_bins}.\"\n",
    "            )\n",
    "\n",
    "        segment_results[label] = dict(\n",
    "            tuning=tuning,\n",
    "            centers=centers,\n",
    "            lo=lo,\n",
    "            hi=hi,\n",
    "            mask=segment_masks[label],\n",
    "            occ_s_per_tuningbin=occ_s_by_segment_tuning[label],\n",
    "            slope_boot=slope_boot,\n",
    "            curv_boot=curv_boot,\n",
    "        )\n",
    "\n",
    "    # ---- pairwise curve-comparison metrics (per unit), restricted to valid tuning bins ----\n",
    "    valid_bins = valid_speed_bins_mask\n",
    "\n",
    "    def restrict_curve(curve):\n",
    "        c = np.asarray(curve, dtype=float).copy()\n",
    "        if c.shape[0] != valid_bins.shape[0]:\n",
    "            raise ValueError(\"Curve length != valid_bins length; check binning params.\")\n",
    "        c[~valid_bins] = np.nan\n",
    "        return c\n",
    "\n",
    "    pairwise_metrics = {}\n",
    "    for i in range(len(progress_labels)):\n",
    "        for j in range(i + 1, len(progress_labels)):\n",
    "            li = progress_labels[i]\n",
    "            lj = progress_labels[j]\n",
    "\n",
    "            units_i = set(segment_results[li][\"tuning\"].keys())\n",
    "            units_j = set(segment_results[lj][\"tuning\"].keys())\n",
    "            common_units = sorted(units_i & units_j)\n",
    "\n",
    "            metrics_per_unit = {}\n",
    "            for unit_id in common_units:\n",
    "                ci = restrict_curve(segment_results[li][\"tuning\"][unit_id])\n",
    "                cj = restrict_curve(segment_results[lj][\"tuning\"][unit_id])\n",
    "\n",
    "                metrics_per_unit[unit_id] = dict(\n",
    "                    corr=curve_corr(ci, cj),\n",
    "                    nrmse=nrmse(ci, cj),\n",
    "                    peak_shift_bins=peak_bin_shift(ci, cj),\n",
    "                    mean_rate_diff=mean_rate_diff(ci, cj),\n",
    "                )\n",
    "\n",
    "            pairwise_metrics[(li, lj)] = metrics_per_unit\n",
    "\n",
    "    return segment_results, valid_speed_bins_mask, pairwise_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf11c4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid tuning bins/windows: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labuser/miniforge3/envs/spyglass/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n"
     ]
    }
   ],
   "source": [
    "progress_edges = np.array([0.0, 0.5, 1.0])\n",
    "progress_labels = [\"early\", \"late\"]\n",
    "\n",
    "df = trialized_position.sort_index().copy()\n",
    "\n",
    "segment_results, valid_speed_bins_mask, pairwise_metrics = compare_speed_tuning_across_progress_segments(\n",
    "    trialized_position_df=df,\n",
    "    spikes_list=spikes_list,\n",
    "    base_mask=base_mask,\n",
    "    progress_col=\"trial_progress_distance\",\n",
    "    progress_edges=progress_edges,\n",
    "    progress_labels=progress_labels,\n",
    "    speed_col=\"speed\",\n",
    "    trial_col=\"trial_number\",\n",
    "\n",
    "    # keep passing this if you already have it:\n",
    "    # for sliding itâ€™s used for stratification/downsampling (not for the tuning windows)\n",
    "    tuner_bins=tuner_bins,\n",
    "\n",
    "    # sliding-window tuning params (these define the returned x-axis / centers)\n",
    "    binning=\"sliding\",\n",
    "    window_width=30,\n",
    "    window_step=3,\n",
    "    tuner_min=0,\n",
    "    tuner_max=120,\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    "    min_speedbin_occupancy_s=1.0,\n",
    "    stratify_equalize_speedbin_occupancy=True,\n",
    ")\n",
    "\n",
    "print(\"Valid tuning bins/windows:\", np.where(valid_speed_bins_mask)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6eee53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for lab in progress_labels:\n",
    "    res = segment_results[lab]\n",
    "    plot_tuning_grid_bootstrap(\n",
    "        res[\"tuning\"], res[\"lo\"], res[\"hi\"], res[\"centers\"],\n",
    "        column=\"speed\", n_units=40, label=f\"{lab} \", peak_normalize = True,\n",
    "        s = 3, linewidth = 2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "59123c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corr              0.566060526\n",
       "nrmse             0.474197986\n",
       "peak_shift_bins   1.000000000\n",
       "mean_rate_diff    0.517335128\n",
       "dtype: float64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = list(pairwise_metrics[('early', 'late')].values())  \n",
    "df = pd.DataFrame(vals)\n",
    "\n",
    "means = df.median(numeric_only=True)  \n",
    "means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991cb520",
   "metadata": {},
   "source": [
    "##### Balance progress weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0f9167bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot progress vs speed\n",
    "trial_types = [ \"inbound\", \"outbound\"]\n",
    "# trial_types = [\"NA\"]\n",
    "\n",
    "zones = [\"run\"]\n",
    "mask = (\n",
    "    (trialized_position[\"zone\"].isin(zones)) &\n",
    "    (trialized_position[\"trial_type\"].isin(trial_types))\n",
    ")\n",
    "n_bins = 5\n",
    "fig, ax = plt.subplots(figsize = (20, 7.5), layout = \"tight\")\n",
    "plot_speed_vs_progress(trialized_position, mask, n_bins, \"trial_progress\", window_size=0.15, step_size=0.02, recompute_progress=True, ax = ax)\n",
    "# plot_speed_vs_progress(trialized_position, mask, n_bins, \"trial_progress_distance\", window_size=0.15, step_size=0.02, recompute_progress=True, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8250d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trialized_position.copy()\n",
    "speed_tuning, speed_centers, lo, hi, slope_boot, curv_boot = compute_speed_tuning_progress_balanced_bootstrap_trials(\n",
    "    df,\n",
    "    spikes_list=spikes_list,\n",
    "    mask=mask,\n",
    "    speed_col=\"speed\",\n",
    "    progress_col=\"trial_progress_distance\",\n",
    "    progress_bins=np.linspace(0, 1, 6),  # still discrete along progress\n",
    "    speed_binning=\"sliding\",\n",
    "    speed_window_width=20,\n",
    "    speed_window_step=2,\n",
    "    speed_min=0.0,\n",
    "    speed_max=120,\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    "    peak_normalize = True,\n",
    "    progress_weights=\"uniform\"\n",
    ")\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    speed_tuning, lo, hi, speed_centers,\n",
    "    column=\"speed\",\n",
    "    n_units=60,\n",
    "    s=1,\n",
    "    color=\"tab:blue\",\n",
    "    peak_normalize = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9854581",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (6,) and (51,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 35\u001b[0m\n\u001b[1;32m     30\u001b[0m (speed_tuning_dist, _, lo_dist, hi_dist, slope_dist, curv_dist) \u001b[38;5;241m=\u001b[39m bal_dist\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#  speed only\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mplot_tuning_grid_bootstrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeed_tuning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed_lower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed_upper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed_centers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch 8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpeak_normalize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# with time\u001b[39;00m\n\u001b[1;32m     46\u001b[0m plot_tuning_grid_bootstrap(\n\u001b[1;32m     47\u001b[0m     speed_tuning_time, lo_time, hi_time, speed_centers,\n\u001b[1;32m     48\u001b[0m     column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \n\u001b[1;32m     54\u001b[0m )\n",
      "File \u001b[0;32m/media/labuser/NA_1_2025/spyglass/wilbur/tuning_analysis/spike_analysis.py:3656\u001b[0m, in \u001b[0;36mplot_tuning_grid_bootstrap\u001b[0;34m(tuner_tuning, lower_ci, upper_ci, tuner_bin_centers, column, n_units, label, indices, s, color, ci, stderr, show_stderr, peak_normalize, ylims, linewidth)\u001b[0m\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m color \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3654\u001b[0m     plot_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m color\n\u001b[0;32m-> 3656\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtuner_bin_centers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplot_kwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   3657\u001b[0m fill_color \u001b[38;5;241m=\u001b[39m color \u001b[38;5;28;01mif\u001b[39;00m color \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m line\u001b[38;5;241m.\u001b[39mget_color()\n\u001b[1;32m   3659\u001b[0m \u001b[38;5;66;03m# Always show the bootstrap percentile CI band\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/spyglass/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/miniforge3/envs/spyglass/lib/python3.10/site-packages/matplotlib/axes/_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/spyglass/lib/python3.10/site-packages/matplotlib/axes/_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    491\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (6,) and (51,)"
     ]
    }
   ],
   "source": [
    "mask = (trialized_position[\"zone\"] == \"run\") & (trialized_position[\"trial_type\"].isin([\"inbound\", \"outbound\"]))\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "# Balanced wrt time-progress\n",
    "bal_time = compute_speed_tuning_progress_balanced_bootstrap_trials(\n",
    "    trialized_position,\n",
    "    speed_col=\"speed\",\n",
    "    progress_col=\"trial_progress_distance\",\n",
    "    spikes_list=spikes_list,\n",
    "    n_speed_bins=6,\n",
    "    n_progress_bins=4,\n",
    "    mask=mask,\n",
    "    n_boot=500,\n",
    "    progress_weights=\"uniform\",\n",
    "    binning = \"sliding\"\n",
    ")\n",
    "\n",
    "# Balanced wrt distance-progress\n",
    "bal_dist = compute_speed_tuning_progress_balanced_bootstrap_trials(\n",
    "    trialized_position,\n",
    "    speed_col=\"speed\",\n",
    "    progress_col=\"trial_progress_distance\",\n",
    "    spikes_list=spikes_list,\n",
    "    n_speed_bins=6,\n",
    "    n_progress_bins=4,\n",
    "    mask=mask,\n",
    "    n_boot=500,\n",
    "    progress_weights=\"uniform\"n_bin\n",
    ")\n",
    "\n",
    "(speed_tuning_time, speed_centers, lo_time, hi_time, slope_time, curv_time) = bal_time\n",
    "(speed_tuning_dist, _, lo_dist, hi_dist, slope_dist, curv_dist) = bal_dist\n",
    "\n",
    "\n",
    "\n",
    "#  speed only\n",
    "plot_tuning_grid_bootstrap(\n",
    "    speed_tuning, speed_lower, speed_upper, speed_centers,\n",
    "    column=\"speed\", \n",
    "    n_units=30, \n",
    "    indices = None,\n",
    "    label = \"epoch 8\",\n",
    "    peak_normalize = True\n",
    ")\n",
    "\n",
    "\n",
    "# with time\n",
    "plot_tuning_grid_bootstrap(\n",
    "    speed_tuning_time, lo_time, hi_time, speed_centers,\n",
    "    column=\"speed\", \n",
    "    n_units=30, \n",
    "    indices = None,\n",
    "    label = \"epoch 8 time weighted\",\n",
    "    peak_normalize = True\n",
    "    \n",
    ")\n",
    "\n",
    "# with distance\n",
    "# plot_tuning_grid_bootstrap(\n",
    "#     speed_tuning_dist, lo_dist, hi_dist, speed_centers,\n",
    "#     column=\"speed\", \n",
    "#     n_units=30, \n",
    "#     indices = None,\n",
    "#     label = \"epoch 8 distance weighted\"\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "142ccebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Across-stable units: 180\n",
      "Samples in mask_common: 63566\n",
      "Trials in mask_common: 199\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 1 â€” Select across-stable units + params + progress (re)compute inside mask\n",
    "# =========================\n",
    "\n",
    "# Units to use (across-epoch stable only)\n",
    "# NOTE: `across_stable_units` is an index array; safest is to use the dict keys directly.\n",
    "across_stable_unit_ids = sorted([u for u, s in across_epoch_status.items() if s == \"stable\"])\n",
    "print(\"Across-stable units:\", len(across_stable_unit_ids))\n",
    "\n",
    "if len(across_stable_unit_ids) == 0:\n",
    "    raise ValueError(\"No across-stable units found in across_epoch_status.\")\n",
    "\n",
    "df = trialized_position.copy().sort_index()\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "# ---- analysis mask (match your typical tuning mask) ----\n",
    "base_mask = (\n",
    "    (df[\"zone\"] == \"run\")\n",
    "    & (df[\"trial_type\"].isin([\"inbound\", \"outbound\"]))\n",
    ")\n",
    "\n",
    "# ---- choose what you are tuning vs ----\n",
    "speed_col = \"speed\"           # keep normalized to use 0..1 tuner_min/max\n",
    "\n",
    "# ---- choose what you are balancing over ----\n",
    "progress_col_raw = \"trial_progress\"  # or \"trial_progress_distance\"\n",
    "trial_col = \"trial_number\"\n",
    "\n",
    "# ---- continuous sliding-window binning for speed tuning curves ----\n",
    "window_width = 20\n",
    "window_step = 2\n",
    "tuner_min = 0\n",
    "tuner_max = 120\n",
    "\n",
    "# ---- progress balancing settings ----\n",
    "n_progress_bins = 5\n",
    "progress_weights = \"uniform\"       # \"uniform\" or \"global\"\n",
    "min_occupancy_cell_s = 0.25\n",
    "min_occupancy_speed_s = 1.0\n",
    "\n",
    "# ---- metric settings ----\n",
    "min_units_ok_bins = 3\n",
    "\n",
    "# Recompute progress within each trial AFTER masking (matches plot_speed_vs_progress(..., recompute_progress=True))\n",
    "progress_col = \"_progress_norm_for_balance\"\n",
    "df[progress_col] = np.nan\n",
    "\n",
    "sub = df.loc[base_mask, [trial_col, progress_col_raw]].copy()\n",
    "sub = sub.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "per_trial_min = sub.groupby(trial_col)[progress_col_raw].transform(\"min\")\n",
    "per_trial_max = sub.groupby(trial_col)[progress_col_raw].transform(\"max\")\n",
    "denom = per_trial_max - per_trial_min\n",
    "\n",
    "ok = np.isfinite(denom) & (denom > 0)\n",
    "sub = sub.loc[ok].copy()\n",
    "sub[progress_col] = (sub[progress_col_raw] - per_trial_min.loc[ok]) / denom.loc[ok]\n",
    "sub = sub[(sub[progress_col] >= 0) & (sub[progress_col] <= 1)]\n",
    "\n",
    "df.loc[sub.index, progress_col] = sub[progress_col].to_numpy()\n",
    "\n",
    "# Common mask used for BOTH tunings (apples-to-apples)\n",
    "mask_common = (\n",
    "    base_mask\n",
    "    & df[trial_col].notna()\n",
    "    & np.isfinite(df[speed_col].to_numpy())\n",
    "    & np.isfinite(df[progress_col].to_numpy())\n",
    ")\n",
    "\n",
    "print(\"Samples in mask_common:\", int(np.sum(mask_common)))\n",
    "print(\"Trials in mask_common:\", int(df.loc[mask_common, trial_col].nunique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5dc06df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced units: 180 n_centers: 51\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 2 â€” Unbalanced tuning (BOOTSTRAPPED; sliding windows)\n",
    "# =========================\n",
    "\n",
    "(\n",
    "    tuning_unbal,\n",
    "    centers_unbal,\n",
    "    lo_unbal,\n",
    "    hi_unbal,\n",
    "    slope_boot_unbal,\n",
    "    curv_boot_unbal,\n",
    ") = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    column=speed_col,\n",
    "    spikes_list=spikes_list,\n",
    "    n_bins=8,  # not used for sliding centers; kept for API consistency\n",
    "    mask=mask_common,\n",
    "    trial_column=trial_col,\n",
    "    n_boot=500,\n",
    "    ci=0.95,\n",
    "    random_state=0,\n",
    "    tuner_bins=None,\n",
    "    binning=\"sliding\",\n",
    "    window_width=window_width,\n",
    "    window_step=window_step,\n",
    "    tuner_min=tuner_min,\n",
    "    tuner_max=tuner_max,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Restrict dicts to across-stable unit IDs\n",
    "tuning_unbal = {u: tuning_unbal[u] for u in across_stable_unit_ids if u in tuning_unbal}\n",
    "lo_unbal     = {u: lo_unbal[u]     for u in across_stable_unit_ids if u in lo_unbal}\n",
    "hi_unbal     = {u: hi_unbal[u]     for u in across_stable_unit_ids if u in hi_unbal}\n",
    "\n",
    "# (optional, only if you plan to use them)\n",
    "slope_boot_unbal = {u: slope_boot_unbal[u] for u in across_stable_unit_ids if u in slope_boot_unbal}\n",
    "curv_boot_unbal  = {u: curv_boot_unbal[u]  for u in across_stable_unit_ids if u in curv_boot_unbal}\n",
    "\n",
    "print(\"Unbalanced units:\", len(tuning_unbal), \"n_centers:\", len(centers_unbal))\n",
    "\n",
    "\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_unbal,\n",
    "    lo_unbal,\n",
    "    hi_unbal,\n",
    "    centers_unbal,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"UNBALANCED (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e580daab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced units: 180 n_centers: 51\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 3 â€” Progress-balanced tuning (sliding windows)\n",
    "# =========================\n",
    "\n",
    "(\n",
    "    tuning_bal,\n",
    "    centers_bal,\n",
    "    lo_bal,\n",
    "    hi_bal,\n",
    "    slope_boot_bal,\n",
    "    curv_boot_bal,\n",
    ") = compute_speed_tuning_progress_balanced_bootstrap_trials(\n",
    "    df,\n",
    "    speed_col=speed_col,\n",
    "    progress_col=progress_col,\n",
    "    spikes_list=spikes_list,\n",
    "    n_speed_bins=8,                 # ignored for sliding; API compat\n",
    "    n_progress_bins=n_progress_bins,\n",
    "    mask=mask_common,\n",
    "    trial_column=trial_col,\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    "    progress_weights=progress_weights,\n",
    "    progress_bins=None,\n",
    "    min_occupancy_cell_s=min_occupancy_cell_s,\n",
    "    min_occupancy_speed_s=min_occupancy_speed_s,\n",
    "    speed_binning=\"sliding\",\n",
    "    speed_window_width=window_width,\n",
    "    speed_window_step=window_step,\n",
    "    speed_min=tuner_min,\n",
    "    speed_max=tuner_max,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Restrict dicts to across-stable units\n",
    "tuning_bal = {u: tuning_bal[u] for u in across_stable_unit_ids if u in tuning_bal}\n",
    "lo_bal = {u: lo_bal[u] for u in tuning_bal.keys() if u in lo_bal}\n",
    "hi_bal = {u: hi_bal[u] for u in tuning_bal.keys() if u in hi_bal}\n",
    "\n",
    "print(\"Balanced units:\", len(tuning_bal), \"n_centers:\", len(centers_bal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d817895f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units available for plotting/metrics: 180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>peak_shift_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.881521164</td>\n",
       "      <td>0.133676185</td>\n",
       "      <td>0.040000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.969673781</td>\n",
       "      <td>0.106119397</td>\n",
       "      <td>0.020000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.833617127</td>\n",
       "      <td>0.156788137</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.950536664</td>\n",
       "      <td>0.133743223</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.668368827</td>\n",
       "      <td>0.224883558</td>\n",
       "      <td>0.060000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         corr       nrmse  peak_shift_x\n",
       "0 0.881521164 0.133676185   0.040000000\n",
       "2 0.969673781 0.106119397   0.020000000\n",
       "3 0.833617127 0.156788137   0.000000000\n",
       "4 0.950536664 0.133743223   0.000000000\n",
       "5 0.668368827 0.224883558   0.060000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>peak_shift_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000000</td>\n",
       "      <td>180.000000000</td>\n",
       "      <td>180.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.722469378</td>\n",
       "      <td>0.280225346</td>\n",
       "      <td>0.182111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.312901809</td>\n",
       "      <td>0.237002670</td>\n",
       "      <td>0.273095209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.386724781</td>\n",
       "      <td>0.009805332</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.651276554</td>\n",
       "      <td>0.123859924</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.832810933</td>\n",
       "      <td>0.206014901</td>\n",
       "      <td>0.020000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.935006989</td>\n",
       "      <td>0.362739329</td>\n",
       "      <td>0.245000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999283180</td>\n",
       "      <td>1.166825201</td>\n",
       "      <td>0.800000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               corr         nrmse  peak_shift_x\n",
       "count 180.000000000 180.000000000 180.000000000\n",
       "mean    0.722469378   0.280225346   0.182111111\n",
       "std     0.312901809   0.237002670   0.273095209\n",
       "min    -0.386724781   0.009805332   0.000000000\n",
       "25%     0.651276554   0.123859924   0.000000000\n",
       "50%     0.832810933   0.206014901   0.020000000\n",
       "75%     0.935006989   0.362739329   0.245000000\n",
       "max     0.999283180   1.166825201   0.800000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median corr: 0.8328109327329712\n",
      "Median nrmse: 0.2060149007577469\n",
      "Median peak_shift_x: 0.020000000000000018\n"
     ]
    }
   ],
   "source": [
    "# compare using metrics and plot (UNBALANCED is bootstrapped now)\n",
    "\n",
    "def _interp_curve_to_centers(curve, from_centers, to_centers):\n",
    "    curve = np.asarray(curve, float)\n",
    "    from_centers = np.asarray(from_centers, float)\n",
    "    to_centers = np.asarray(to_centers, float)\n",
    "\n",
    "    finite = np.isfinite(curve) & np.isfinite(from_centers)\n",
    "    if finite.sum() < 2:\n",
    "        return np.full_like(to_centers, np.nan, dtype=float)\n",
    "\n",
    "    x = from_centers[finite]\n",
    "    y = curve[finite]\n",
    "    order = np.argsort(x)\n",
    "    x = x[order]\n",
    "    y = y[order]\n",
    "\n",
    "    out = np.interp(to_centers, x, y)\n",
    "    out[(to_centers < x.min()) | (to_centers > x.max())] = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "# Use UNBALANCED centers as the common x-axis\n",
    "centers = np.asarray(centers_unbal, float)\n",
    "\n",
    "# Align balanced tuning + CI onto unbalanced centers if needed\n",
    "if not np.allclose(centers_unbal, centers_bal, equal_nan=True):\n",
    "    print(\"Center mismatch: interpolating balanced tuning + CI onto unbalanced centers.\")\n",
    "    tuning_bal_aligned = {u: _interp_curve_to_centers(tuning_bal[u], centers_bal, centers) for u in tuning_bal.keys()}\n",
    "    lo_bal_aligned = {u: _interp_curve_to_centers(lo_bal[u], centers_bal, centers) for u in lo_bal.keys()}\n",
    "    hi_bal_aligned = {u: _interp_curve_to_centers(hi_bal[u], centers_bal, centers) for u in hi_bal.keys()}\n",
    "else:\n",
    "    tuning_bal_aligned = tuning_bal\n",
    "    lo_bal_aligned = lo_bal\n",
    "    hi_bal_aligned = hi_bal\n",
    "\n",
    "# Units available in BOTH methods (unbalanced + balanced)\n",
    "units_compared = sorted(set(tuning_unbal.keys()) & set(tuning_bal_aligned.keys()))\n",
    "print(\"Units available for plotting/metrics:\", len(units_compared))\n",
    "\n",
    "# Restrict to across-stable unit IDs if present (recommended)\n",
    "plot_units = units_compared\n",
    "if \"across_stable_unit_ids\" in globals():\n",
    "    stable_set = set(across_stable_unit_ids)\n",
    "    plot_units = [u for u in plot_units if u in stable_set]\n",
    "\n",
    "if len(plot_units) == 0:\n",
    "    raise ValueError(\"No units to plot after restricting to across_stable_unit_ids âˆ© units_compared.\")\n",
    "\n",
    "# Subset dicts so plotting funcs only see the units you want\n",
    "tuning_unbal_plot = {u: tuning_unbal[u] for u in plot_units}\n",
    "lo_unbal_plot     = {u: lo_unbal[u]     for u in plot_units}\n",
    "hi_unbal_plot     = {u: hi_unbal[u]     for u in plot_units}\n",
    "\n",
    "tuning_bal_plot = {u: tuning_bal_aligned[u] for u in plot_units}\n",
    "lo_bal_plot     = {u: lo_bal_aligned[u]     for u in plot_units}\n",
    "hi_bal_plot     = {u: hi_bal_aligned[u]     for u in plot_units}\n",
    "\n",
    "# -------------------------\n",
    "# Plot: unbalanced vs balanced (both bootstrapped)\n",
    "# -------------------------\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_unbal_plot,\n",
    "    lo_unbal_plot,\n",
    "    hi_unbal_plot,\n",
    "    centers,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"UNBALANCED (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_bal_plot,\n",
    "    lo_bal_plot,\n",
    "    hi_bal_plot,\n",
    "    centers,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"PROGRESS-BALANCED (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Metrics: exactly your 3 (corr / nrmse / peak_shift_x)\n",
    "# -------------------------\n",
    "metrics = {}\n",
    "for u in plot_units:\n",
    "    a = np.asarray(tuning_unbal_plot[u], float)\n",
    "    b = np.asarray(tuning_bal_plot[u], float)\n",
    "    metrics[u] = dict(\n",
    "        corr=curve_corr(a, b, min_bins=min_units_ok_bins),\n",
    "        nrmse=nrmse(a, b, min_bins=min_units_ok_bins),\n",
    "        peak_shift_x=peak_shift_x(a, b, centers, min_bins=min_units_ok_bins),\n",
    "    )\n",
    "\n",
    "metrics_df_progress = pd.DataFrame.from_dict(metrics, orient=\"index\")\n",
    "display(metrics_df_progress.head())\n",
    "display(metrics_df_progress.describe())\n",
    "\n",
    "print(\"Median corr:\", float(metrics_df_progress[\"corr\"].median(skipna=True)))\n",
    "print(\"Median nrmse:\", float(metrics_df_progress[\"nrmse\"].median(skipna=True)))\n",
    "print(\"Median peak_shift_x:\", float(metrics_df_progress[\"peak_shift_x\"].median(skipna=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "528d5dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unit_to_plot = 3  # set to an int unit id, or leave None to auto-pick\n",
    "\n",
    "# Choose available units\n",
    "if \"across_stable_unit_ids\" in globals():\n",
    "    candidate_units = [u for u in across_stable_unit_ids if (u in tuning_unbal and u in tuning_bal_aligned)]\n",
    "else:\n",
    "    candidate_units = [u for u in units_compared if (u in tuning_unbal and u in tuning_bal_aligned)]\n",
    "\n",
    "if len(candidate_units) == 0:\n",
    "    raise ValueError(\"No units available for overlay (check tuning_unbal/tuning_bal_aligned and stable-unit filtering).\")\n",
    "\n",
    "if unit_to_plot is None:\n",
    "    unit_to_plot = candidate_units[0]\n",
    "\n",
    "a = np.asarray(tuning_unbal[unit_to_plot], float)\n",
    "b = np.asarray(tuning_bal_aligned[unit_to_plot], float)\n",
    "x = np.asarray(centers, float)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.5, 4.5), layout=\"tight\")\n",
    "\n",
    "ax.plot(x, a, \"-o\", linewidth=2.0, markersize=4, label=\"unbalanced (sliding)\")\n",
    "ax.plot(x, b, \"-o\", linewidth=2.0, markersize=4, label=\"progress-balanced (sliding)\")\n",
    "\n",
    "# Optional: show balanced CI band if you have it aligned\n",
    "if \"lo_bal_aligned\" in globals() and \"hi_bal_aligned\" in globals():\n",
    "    if unit_to_plot in lo_bal_aligned and unit_to_plot in hi_bal_aligned:\n",
    "        lo = np.asarray(lo_bal_aligned[unit_to_plot], float)\n",
    "        hi = np.asarray(hi_bal_aligned[unit_to_plot], float)\n",
    "        ax.fill_between(x, lo, hi, alpha=0.25, label=\"balanced CI\")\n",
    "\n",
    "# Your 3 metrics, printed on-plot\n",
    "cc = curve_corr(a, b, min_bins=min_units_ok_bins)\n",
    "ee = nrmse(a, b, min_bins=min_units_ok_bins)\n",
    "pp = peak_shift_x(a, b, x, min_bins=min_units_ok_bins)\n",
    "\n",
    "ax.set_title(f\"Unit {unit_to_plot} | corr={cc:.3f} | nrmse={ee:.3f} | peak_shift_x={pp:.3f}\")\n",
    "ax.set_xlabel(speed_col)\n",
    "ax.set_ylabel(\"Peak-normalized firing rate\")\n",
    "ax.set_ylim([-0.05, 1.05])\n",
    "ax.grid(True, alpha=0.25)\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "97ea93cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stable': 180, 'unstable': 24, 'insufficient': 0}\n"
     ]
    }
   ],
   "source": [
    "if \"across_epoch_status\" in globals():\n",
    "    labels_raw = list(across_epoch_status.values())\n",
    "    labels = [\"unstable\" if x == \"changed\" else x for x in labels_raw]\n",
    "elif \"overall_status\" in globals():\n",
    "    # From your >=3/4 rule section (\"stable/drifting/insufficient\")\n",
    "    labels_raw = list(overall_status.values())\n",
    "    labels = [\"unstable\" if x in (\"drifting\", \"changed\") else x for x in labels_raw]\n",
    "else:\n",
    "    raise ValueError(\"Could not find across_epoch_status or overall_status in the notebook namespace.\")\n",
    "\n",
    "cats = [\"stable\", \"unstable\", \"insufficient\"]\n",
    "counts = {c: labels.count(c) for c in cats}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.2*2.2, 3.2*2.2), layout=\"tight\")\n",
    "\n",
    "# Reuse your existing `colors` list if you have it; otherwise default palette\n",
    "if \"colors\" in globals() and isinstance(colors, (list, tuple)) and len(colors) >= 3:\n",
    "    bar_colors = [colors[0], colors[1], colors[2]]\n",
    "else:\n",
    "    bar_colors = [\"tab:green\", \"tab:orange\", \"tab:gray\"]\n",
    "\n",
    "ax.bar(cats, [counts[c] for c in cats], color=bar_colors, alpha=0.9)\n",
    "ax.set_ylabel(\"Number of units\")\n",
    "\n",
    "# annotate counts\n",
    "for i, c in enumerate(cats):\n",
    "    ax.text(i, counts[c] + 0.5, str(counts[c]), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print({c: counts[c] for c in cats})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "609e9be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts: {'stable': 109, 'unstable': 71, 'insufficient': 0}\n",
      "Thresholds: {'corr_thresh': 0.3, 'nrmse_thresh': 0.5, 'peak_shift_thresh': 0.1}\n",
      "N evaluated (across_stable_unit_ids): 180\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell â€” Barplot for PROGRESS BALANCING comparison (unbalanced vs progress-balanced)\n",
    "# Categories are computed from the *progress-balancing metrics* (corr/nrmse/peak_shift_x).\n",
    "#\n",
    "# Requirements:\n",
    "# - `across_stable_unit_ids` exists (units you want to evaluate)\n",
    "# - you have a metrics table from the progress-balancing comparison with columns:\n",
    "#     corr, nrmse, peak_shift_x\n",
    "#\n",
    "# IMPORTANT (because your notebook overwrites `metrics_df` in multiple sections):\n",
    "# - If you already saved it as `metrics_df_progress`, this cell will use that.\n",
    "# - Otherwise it will fall back to `metrics_df` (make sure you run it right after progress section).\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if \"across_stable_unit_ids\" not in globals():\n",
    "    raise ValueError(\"Expected `across_stable_unit_ids` to exist.\")\n",
    "\n",
    "# Prefer a dedicated snapshot if you made one\n",
    "if \"metrics_df_progress\" in globals():\n",
    "    metrics_df_use = metrics_df_progress\n",
    "elif \"metrics_df\" in globals():\n",
    "    metrics_df_use = metrics_df\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Could not find `metrics_df_progress` or `metrics_df`.\\n\"\n",
    "        \"Run this right after the progress-balancing comparison cell, or save:\\n\"\n",
    "        \"  metrics_df_progress = metrics_df.copy()\"\n",
    "    )\n",
    "\n",
    "need_cols = {\"corr\", \"nrmse\", \"peak_shift_x\"}\n",
    "if not need_cols.issubset(set(metrics_df_use.columns)):\n",
    "    raise ValueError(f\"Progress metrics table missing columns {need_cols}; got {list(metrics_df_use.columns)}\")\n",
    "\n",
    "# ---- thresholds (same style as your inbound/outbound barplot) ----\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh = 0.10  # in speed_norm units if your centers are speed_norm\n",
    "\n",
    "labels_progress = {}\n",
    "for u in across_stable_unit_ids:\n",
    "    if u not in metrics_df_use.index:\n",
    "        labels_progress[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    c = metrics_df_use.loc[u, \"corr\"]\n",
    "    e = metrics_df_use.loc[u, \"nrmse\"]\n",
    "    p = metrics_df_use.loc[u, \"peak_shift_x\"]\n",
    "\n",
    "    if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "        labels_progress[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    # Here \"stable\" means: progress balancing does NOT change the tuning curve much\n",
    "    is_stable = (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh)\n",
    "    labels_progress[u] = \"stable\" if is_stable else \"unstable\"\n",
    "\n",
    "cats = [\"stable\", \"unstable\", \"insufficient\"]\n",
    "counts = {c: list(labels_progress.values()).count(c) for c in cats}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.2 * 2.2, 3.2 * 2.2), layout=\"tight\")\n",
    "\n",
    "# Reuse your existing `colors` list if you have it; otherwise default palette\n",
    "if \"colors\" in globals() and isinstance(colors, (list, tuple)) and len(colors) >= 3:\n",
    "    bar_colors = [colors[0], colors[1], colors[2]]\n",
    "else:\n",
    "    bar_colors = [\"tab:green\", \"tab:orange\", \"tab:gray\"]\n",
    "\n",
    "ax.bar(cats, [counts[c] for c in cats], color=bar_colors, alpha=0.9)\n",
    "ax.set_ylabel(\"Number of units\")\n",
    "ax.set_title(\"Progress balancing robustness (across-stable units)\")\n",
    "\n",
    "# annotate counts\n",
    "for i, c in enumerate(cats):\n",
    "    ax.text(i, counts[c] + 0.5, str(counts[c]), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Counts:\", {c: counts[c] for c in cats})\n",
    "print(\"Thresholds:\", dict(corr_thresh=corr_thresh, nrmse_thresh=nrmse_thresh, peak_shift_thresh=peak_shift_thresh))\n",
    "print(\"N evaluated (across_stable_unit_ids):\", len(across_stable_unit_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "da847a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable units across unbalanced vs balanced: 145\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell â€” Plot PROGRESS-ROBUST units (unbalanced vs balanced)\n",
    "# Produces TWO figures:\n",
    "#   1) UNBALANCED tuning curves grid (only units stable across unbalanced vs balanced)\n",
    "#   2) PROGRESS-BALANCED tuning curves grid (same unit set)\n",
    "#\n",
    "# \"stable units in progress\" = units whose unbalanced vs balanced curves are similar\n",
    "# by your 3 metrics (corr high, nrmse low, peak_shift_x low), AND finite metrics.\n",
    "#\n",
    "# Expects (from your progress-balancing pipeline):\n",
    "# - tuning_unbal, lo_unbal, hi_unbal, centers_unbal\n",
    "# - tuning_bal_aligned, lo_bal_aligned, hi_bal_aligned  (or tuning_bal/lo_bal/hi_bal + centers_bal)\n",
    "# - metrics_df_progress (preferred) OR metrics_df (if it's currently the progress one)\n",
    "# =========================\n",
    "\n",
    "\n",
    "# pick the correct metrics table for progress-balancing\n",
    "if \"metrics_df_progress\" in globals():\n",
    "    metrics_df_use = metrics_df_progress\n",
    "elif \"metrics_df\" in globals():\n",
    "    metrics_df_use = metrics_df\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Could not find progress metrics (`metrics_df_progress` or `metrics_df`).\\n\"\n",
    "        \"If you overwrote metrics_df later, rerun the progress comparison cell and do:\\n\"\n",
    "        \"  metrics_df_progress = metrics_df.copy()\"\n",
    "    )\n",
    "\n",
    "need_cols = {\"corr\", \"nrmse\", \"peak_shift_x\"}\n",
    "if not need_cols.issubset(set(metrics_df_use.columns)):\n",
    "    raise ValueError(f\"Progress metrics table missing columns {need_cols}; got {list(metrics_df_use.columns)}\")\n",
    "\n",
    "# thresholds (edit to taste; keep consistent with your other barplots)\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh = 10  # in speed_norm units\n",
    "\n",
    "# make sure we have aligned balanced dicts; if not, fall back to raw balanced dicts\n",
    "# (assumes centers_unbal is the shared axis)\n",
    "centers = np.asarray(centers_unbal, float)\n",
    "\n",
    "# if \"tuning_bal_aligned\" not in globals():\n",
    "#     if not (\"tuning_bal\" in globals() and \"centers_bal\" in globals()):\n",
    "#         raise ValueError(\"Missing `tuning_bal_aligned` (or `tuning_bal` + `centers_bal`). Run your alignment cell first.\")\n",
    "#     tuning_bal_aligned = tuning_bal\n",
    "#     lo_bal_aligned = lo_bal\n",
    "#     hi_bal_aligned = hi_bal\n",
    "\n",
    "tuning_bal_aligned = tuning_bal\n",
    "lo_bal_aligned = lo_bal\n",
    "hi_bal_aligned = hi_bal\n",
    "\n",
    "\n",
    "# optional restriction: if you already restricted tunings to across_stable_unit_ids earlier,\n",
    "# this wonâ€™t change anything. If not, it keeps consistency with your workflow.\n",
    "unit_pool = list(metrics_df_use.index)\n",
    "if \"across_stable_unit_ids\" in globals():\n",
    "    unit_pool = [u for u in unit_pool if u in set(across_stable_unit_ids)]\n",
    "\n",
    "stable_units_progress = []\n",
    "for u in unit_pool:\n",
    "    if u not in metrics_df_use.index:\n",
    "        continue\n",
    "    c = metrics_df_use.loc[u, \"corr\"]\n",
    "    e = metrics_df_use.loc[u, \"nrmse\"]\n",
    "    p = metrics_df_use.loc[u, \"peak_shift_x\"]\n",
    "\n",
    "    if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "        continue\n",
    "\n",
    "    is_stable = (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh)\n",
    "    # is_stable = (c <= corr_thresh) or (e >= nrmse_thresh) or (p >= peak_shift_thresh)\n",
    "\n",
    "    if is_stable:\n",
    "        stable_units_progress.append(u)\n",
    "\n",
    "# also ensure unit exists in BOTH tuning dicts + CIs\n",
    "stable_units_progress = [\n",
    "    u for u in stable_units_progress\n",
    "    if (u in tuning_unbal) and (u in lo_unbal) and (u in hi_unbal)\n",
    "    and (u in tuning_bal_aligned) and (u in lo_bal_aligned) and (u in hi_bal_aligned)\n",
    "]\n",
    "\n",
    "print(\"Stable units across unbalanced vs balanced:\", len(stable_units_progress))\n",
    "if len(stable_units_progress) == 0:\n",
    "    raise ValueError(\"No progress-stable units found under these thresholds (or missing tuning/CI entries).\")\n",
    "\n",
    "# subset dicts so plot_tuning_grid_bootstrap only sees the units you want\n",
    "tun_unbal_stable = {u: tuning_unbal[u] for u in stable_units_progress}\n",
    "lo_unbal_stable  = {u: lo_unbal[u]     for u in stable_units_progress}\n",
    "hi_unbal_stable  = {u: hi_unbal[u]     for u in stable_units_progress}\n",
    "\n",
    "tun_bal_stable = {u: tuning_bal_aligned[u] for u in stable_units_progress}\n",
    "lo_bal_stable  = {u: lo_bal_aligned[u]     for u in stable_units_progress}\n",
    "hi_bal_stable  = {u: hi_bal_aligned[u]     for u in stable_units_progress}\n",
    "\n",
    "# column label (keep consistent with your analysis)\n",
    "col_label = speed_col if \"speed_col\" in globals() else \"speed_norm\"\n",
    "\n",
    "# Figure 1: UNBALANCED\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tun_unbal_stable,\n",
    "    lo_unbal_stable,\n",
    "    hi_unbal_stable,\n",
    "    centers,\n",
    "    column=col_label,\n",
    "    n_units=30,\n",
    "    label=\"UNBALANCED (progress-stable units; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Figure 2: PROGRESS-BALANCED\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tun_bal_stable,\n",
    "    lo_bal_stable,\n",
    "    hi_bal_stable,\n",
    "    centers,\n",
    "    column=col_label,\n",
    "    n_units=30,\n",
    "    label=\"PROGRESS-BALANCED (progress-stable units; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "193f2db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tun_bal_stable[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68166b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant early/late units (q_max<0.05): 0\n"
     ]
    }
   ],
   "source": [
    "mask_early = segment_results[\"early\"][\"mask\"]\n",
    "mask_late  = segment_results[\"late\"][\"mask\"]\n",
    "\n",
    "df = trialized_position.copy().sort_index()\n",
    "\n",
    "res_earlylate = paired_permutation_test_tuning_difference_masks(\n",
    "    df,\n",
    "    spikes_list=spikes_list,\n",
    "    base_mask=base_mask,          # use the same base_mask you used to build segment masks\n",
    "    column=\"speed\",\n",
    "    trial_column=\"trial_number\",\n",
    "    mask_a=mask_early,\n",
    "    mask_b=mask_late,\n",
    "    label_a=\"early\",\n",
    "    label_b=\"late\",\n",
    "    binning=\"sliding\",\n",
    "    window_width=0.20,\n",
    "    window_step=0.02,\n",
    "    tuner_min=0.0,\n",
    "    tuner_max=1.0,\n",
    "    n_perm=2000,\n",
    "    random_state=0,\n",
    "    units=across_stable_unit_ids,  # optional\n",
    ")\n",
    "\n",
    "sig_units_earlylate = res_earlylate[\"q_max\"][res_earlylate[\"q_max\"] < 0.05].index.to_numpy()\n",
    "print(\"Significant early/late units (q_max<0.05):\", len(sig_units_earlylate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de37ceb",
   "metadata": {},
   "source": [
    "##### Outbound vs Inbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9e65d390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials inbound: 107\n",
      "Trials outbound: 92\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 1 â€” Setup masks (INBOUND vs OUTBOUND) using across_stable_unit_ids only\n",
    "# =========================\n",
    "\n",
    "if \"across_stable_unit_ids\" not in globals():\n",
    "    raise ValueError(\"Expected `across_stable_unit_ids` to already exist.\")\n",
    "\n",
    "df = trialized_position.copy().sort_index()\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "# Tuning x-axis\n",
    "speed_col = \"speed\"     # keep consistent with your other tuning (0..1)\n",
    "trial_col = \"trial_number\"\n",
    "\n",
    "# Sliding-window (continuous) binning params\n",
    "window_width = 20\n",
    "window_step = 2\n",
    "tuner_min = 0\n",
    "tuner_max = 120\n",
    "\n",
    "# Bootstrap params\n",
    "n_boot = 500\n",
    "random_state = 0\n",
    "\n",
    "# Metric params\n",
    "min_units_ok_bins = 3\n",
    "\n",
    "# Common inclusion mask (so you only differ by trial_type)\n",
    "base_mask = (\n",
    "    (df[\"zone\"] == \"run\")\n",
    "    & (df[\"trial_type\"].isin([\"inbound\", \"outbound\"]))\n",
    ")\n",
    "\n",
    "mask_common = (\n",
    "    base_mask\n",
    "    & df[trial_col].notna()\n",
    "    & np.isfinite(df[speed_col].to_numpy())\n",
    ")\n",
    "\n",
    "mask_inbound = mask_common & (df[\"trial_type\"] == \"inbound\")\n",
    "mask_outbound = mask_common & (df[\"trial_type\"] == \"outbound\")\n",
    "\n",
    "n_trials_in = int(df.loc[mask_inbound, trial_col].nunique())\n",
    "n_trials_out = int(df.loc[mask_outbound, trial_col].nunique())\n",
    "print(\"Trials inbound:\", n_trials_in)\n",
    "print(\"Trials outbound:\", n_trials_out)\n",
    "\n",
    "if n_trials_in < 2 or n_trials_out < 2:\n",
    "    raise ValueError(\"Need >=2 trials in BOTH inbound and outbound for trial bootstrap.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "38ab23d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inbound units: 180 n_centers: 51\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 2 â€” INBOUND tuning (BOOTSTRAPPED; sliding windows)\n",
    "# =========================\n",
    "\n",
    "(\n",
    "    tuning_in,\n",
    "    centers_in,\n",
    "    lo_in,\n",
    "    hi_in,\n",
    "    slope_boot_in,\n",
    "    curv_boot_in,\n",
    ") = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    column=speed_col,\n",
    "    spikes_list=spikes_list,\n",
    "    n_bins=8,  # ignored for sliding; kept for API compatibility\n",
    "    mask=mask_inbound,\n",
    "    trial_column=trial_col,\n",
    "    n_boot=n_boot,\n",
    "    ci=0.95,\n",
    "    random_state=random_state,\n",
    "    tuner_bins=None,\n",
    "    binning=\"sliding\",\n",
    "    window_width=window_width,\n",
    "    window_step=window_step,\n",
    "    tuner_min=tuner_min,\n",
    "    tuner_max=tuner_max,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Restrict to across-stable units only\n",
    "tuning_in = {u: tuning_in[u] for u in across_stable_unit_ids if u in tuning_in}\n",
    "lo_in = {u: lo_in[u] for u in across_stable_unit_ids if u in lo_in}\n",
    "hi_in = {u: hi_in[u] for u in across_stable_unit_ids if u in hi_in}\n",
    "\n",
    "print(\"Inbound units:\", len(tuning_in), \"n_centers:\", len(centers_in))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6c54432e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outbound units: 180 n_centers: 51\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 3 â€” OUTBOUND tuning (BOOTSTRAPPED; sliding windows)\n",
    "# =========================\n",
    "\n",
    "(\n",
    "    tuning_out,\n",
    "    centers_out,\n",
    "    lo_out,\n",
    "    hi_out,\n",
    "    slope_boot_out,\n",
    "    curv_boot_out,\n",
    ") = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    column=speed_col,\n",
    "    spikes_list=spikes_list,\n",
    "    n_bins=8,  # ignored for sliding; kept for API compatibility\n",
    "    mask=mask_outbound,\n",
    "    trial_column=trial_col,\n",
    "    n_boot=n_boot,\n",
    "    ci=0.95,\n",
    "    random_state=random_state,\n",
    "    tuner_bins=None,\n",
    "    binning=\"sliding\",\n",
    "    window_width=window_width,\n",
    "    window_step=window_step,\n",
    "    tuner_min=tuner_min,\n",
    "    tuner_max=tuner_max,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Restrict to across-stable units only\n",
    "tuning_out = {u: tuning_out[u] for u in across_stable_unit_ids if u in tuning_out}\n",
    "lo_out = {u: lo_out[u] for u in across_stable_unit_ids if u in lo_out}\n",
    "hi_out = {u: hi_out[u] for u in across_stable_unit_ids if u in hi_out}\n",
    "\n",
    "print(\"Outbound units:\", len(tuning_out), \"n_centers:\", len(centers_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5515cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units compared: 180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>peak_shift_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950374768</td>\n",
       "      <td>0.125525721</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.975467967</td>\n",
       "      <td>0.113496839</td>\n",
       "      <td>12.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.953669226</td>\n",
       "      <td>0.103240512</td>\n",
       "      <td>8.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.429299723</td>\n",
       "      <td>0.353061589</td>\n",
       "      <td>10.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.946508243</td>\n",
       "      <td>0.120272524</td>\n",
       "      <td>10.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         corr       nrmse  peak_shift_x\n",
       "0 0.950374768 0.125525721   0.000000000\n",
       "2 0.975467967 0.113496839  12.000000000\n",
       "3 0.953669226 0.103240512   8.000000000\n",
       "4 0.429299723 0.353061589  10.000000000\n",
       "5 0.946508243 0.120272524  10.000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>peak_shift_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000000</td>\n",
       "      <td>180.000000000</td>\n",
       "      <td>180.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.545007758</td>\n",
       "      <td>0.277565903</td>\n",
       "      <td>27.722222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.455855669</td>\n",
       "      <td>0.142825482</td>\n",
       "      <td>33.040867797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.802616845</td>\n",
       "      <td>0.038192540</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.348024170</td>\n",
       "      <td>0.179014905</td>\n",
       "      <td>2.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.710251413</td>\n",
       "      <td>0.246393597</td>\n",
       "      <td>11.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.890051259</td>\n",
       "      <td>0.354414358</td>\n",
       "      <td>54.500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.993106946</td>\n",
       "      <td>0.717068595</td>\n",
       "      <td>100.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               corr         nrmse  peak_shift_x\n",
       "count 180.000000000 180.000000000 180.000000000\n",
       "mean    0.545007758   0.277565903  27.722222222\n",
       "std     0.455855669   0.142825482  33.040867797\n",
       "min    -0.802616845   0.038192540   0.000000000\n",
       "25%     0.348024170   0.179014905   2.000000000\n",
       "50%     0.710251413   0.246393597  11.000000000\n",
       "75%     0.890051259   0.354414358  54.500000000\n",
       "max     0.993106946   0.717068595 100.000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median corr: 0.710251413291781\n",
      "Median nrmse: 0.24639359745350561\n",
      "Median peak_shift_x: 11.0\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 4 â€” Compare + plot (INBOUND vs OUTBOUND)\n",
    "# =========================\n",
    "\n",
    "def _interp_curve_to_centers(curve, from_centers, to_centers):\n",
    "    curve = np.asarray(curve, float)\n",
    "    from_centers = np.asarray(from_centers, float)\n",
    "    to_centers = np.asarray(to_centers, float)\n",
    "\n",
    "    finite = np.isfinite(curve) & np.isfinite(from_centers)\n",
    "    if finite.sum() < 2:\n",
    "        return np.full_like(to_centers, np.nan, dtype=float)\n",
    "\n",
    "    x = from_centers[finite]\n",
    "    y = curve[finite]\n",
    "    order = np.argsort(x)\n",
    "    x = x[order]\n",
    "    y = y[order]\n",
    "\n",
    "    out = np.interp(to_centers, x, y)\n",
    "    out[(to_centers < x.min()) | (to_centers > x.max())] = np.nan\n",
    "    return out\n",
    "\n",
    "# Use inbound centers as the shared x-axis (either is fine)\n",
    "centers = np.asarray(centers_in, float)\n",
    "\n",
    "# Align OUTBOUND onto inbound centers if needed (should usually match if tuner_min/max are fixed)\n",
    "if not np.allclose(centers_in, centers_out, equal_nan=True):\n",
    "    print(\"Center mismatch: interpolating OUTBOUND tuning + CI onto INBOUND centers.\")\n",
    "    tuning_out_aligned = {u: _interp_curve_to_centers(tuning_out[u], centers_out, centers) for u in tuning_out.keys()}\n",
    "    lo_out_aligned = {u: _interp_curve_to_centers(lo_out[u], centers_out, centers) for u in lo_out.keys()}\n",
    "    hi_out_aligned = {u: _interp_curve_to_centers(hi_out[u], centers_out, centers) for u in hi_out.keys()}\n",
    "else:\n",
    "    tuning_out_aligned = tuning_out\n",
    "    lo_out_aligned = lo_out\n",
    "    hi_out_aligned = hi_out\n",
    "\n",
    "# Units to compare: across-stable AND present in both curves\n",
    "plot_units = [u for u in across_stable_unit_ids if (u in tuning_in) and (u in tuning_out_aligned)]\n",
    "print(\"Units compared:\", len(plot_units))\n",
    "if len(plot_units) == 0:\n",
    "    raise ValueError(\"No units left after restricting to across_stable_unit_ids âˆ© (inboundâˆ©outbound).\")\n",
    "\n",
    "# Subset dicts so plotting funcs only see the units you want\n",
    "tuning_in_plot = {u: tuning_in[u] for u in plot_units}\n",
    "lo_in_plot = {u: lo_in[u] for u in plot_units}\n",
    "hi_in_plot = {u: hi_in[u] for u in plot_units}\n",
    "\n",
    "tuning_out_plot = {u: tuning_out_aligned[u] for u in plot_units}\n",
    "lo_out_plot = {u: lo_out_aligned[u] for u in plot_units}\n",
    "hi_out_plot = {u: hi_out_aligned[u] for u in plot_units}\n",
    "\n",
    "# Plot (both bootstrapped; sliding-window bins)\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_in_plot,\n",
    "    lo_in_plot,\n",
    "    hi_in_plot,\n",
    "    centers,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"INBOUND (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_out_plot,\n",
    "    lo_out_plot,\n",
    "    hi_out_plot,\n",
    "    centers,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"OUTBOUND (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Metrics (your 3)\n",
    "metrics = {}\n",
    "for u in plot_units:\n",
    "    a = np.asarray(tuning_in_plot[u], float)\n",
    "    b = np.asarray(tuning_out_plot[u], float)\n",
    "    metrics[u] = dict(\n",
    "        corr=curve_corr(a, b, min_bins=min_units_ok_bins),\n",
    "        nrmse=nrmse(a, b, min_bins=min_units_ok_bins),\n",
    "        peak_shift_x=peak_shift_x(a, b, centers, min_bins=min_units_ok_bins),\n",
    "    )\n",
    "\n",
    "metrics_df_inout = pd.DataFrame.from_dict(metrics, orient=\"index\")\n",
    "display(metrics_df_inout.head())\n",
    "display(metrics_df_inout.describe())\n",
    "\n",
    "print(\"Median corr:\", float(metrics_df_inout[\"corr\"].median(skipna=True)))\n",
    "print(\"Median nrmse:\", float(metrics_df_inout[\"nrmse\"].median(skipna=True)))\n",
    "print(\"Median peak_shift_x:\", float(metrics_df_inout[\"peak_shift_x\"].median(skipna=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ef7b8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell â€” Single-unit overlay: INBOUND vs OUTBOUND (across_stable_unit_ids only)\n",
    "# Requires from the inbound/outbound pipeline:\n",
    "#   - tuning_in_plot, lo_in_plot, hi_in_plot\n",
    "#   - tuning_out_plot, lo_out_plot, hi_out_plot\n",
    "#   - centers\n",
    "#   - plot_units\n",
    "# =========================\n",
    "\n",
    "unit_to_plot = 3  # set to an int unit id, or leave None to auto-pick\n",
    "\n",
    "if \"plot_units\" not in globals() or len(plot_units) == 0:\n",
    "    raise ValueError(\"Expected `plot_units` from the inbound/outbound comparison cell.\")\n",
    "\n",
    "if unit_to_plot is None:\n",
    "    unit_to_plot = plot_units[0]\n",
    "\n",
    "if unit_to_plot not in tuning_in_plot or unit_to_plot not in tuning_out_plot:\n",
    "    raise ValueError(\"unit_to_plot not available in both inbound and outbound tunings.\")\n",
    "\n",
    "x = np.asarray(centers, float)\n",
    "\n",
    "yin = np.asarray(tuning_in_plot[unit_to_plot], float)\n",
    "yout = np.asarray(tuning_out_plot[unit_to_plot], float)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 4.5), layout=\"tight\")\n",
    "\n",
    "ax.plot(x, yin, \"-o\", linewidth=2.0, markersize=4, label=\"INBOUND\")\n",
    "ax.plot(x, yout, \"-o\", linewidth=2.0, markersize=4, label=\"OUTBOUND\")\n",
    "\n",
    "# CI bands (if present)\n",
    "if unit_to_plot in lo_in_plot and unit_to_plot in hi_in_plot:\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        np.asarray(lo_in_plot[unit_to_plot], float),\n",
    "        np.asarray(hi_in_plot[unit_to_plot], float),\n",
    "        alpha=0.20,\n",
    "        label=\"INBOUND CI\",\n",
    "    )\n",
    "if unit_to_plot in lo_out_plot and unit_to_plot in hi_out_plot:\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        np.asarray(lo_out_plot[unit_to_plot], float),\n",
    "        np.asarray(hi_out_plot[unit_to_plot], float),\n",
    "        alpha=0.20,\n",
    "        label=\"OUTBOUND CI\",\n",
    "    )\n",
    "\n",
    "# Your 3 metrics\n",
    "cc = curve_corr(yin, yout, min_bins=min_units_ok_bins)\n",
    "ee = nrmse(yin, yout, min_bins=min_units_ok_bins)\n",
    "pp = peak_shift_x(yin, yout, x, min_bins=min_units_ok_bins)\n",
    "\n",
    "ax.set_title(f\"Unit {unit_to_plot} | corr={cc:.3f} | nrmse={ee:.3f} | peak_shift_x={pp:.3f}\")\n",
    "ax.set_xlabel(speed_col)\n",
    "ax.set_ylabel(\"Peak-normalized firing rate\")\n",
    "ax.set_ylim([-0.05, 1.05])\n",
    "ax.grid(True, alpha=0.25)\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "daf8b14c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected `metrics_df` from the inbound/outbound comparison cell.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[174], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# metrics_df from the inbound/outbound comparison cell should exist\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics_df\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m():\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `metrics_df` from the inbound/outbound comparison cell.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m labels \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m across_stable_unit_ids:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected `metrics_df` from the inbound/outbound comparison cell."
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell â€” Bar plot: stable vs unstable vs insufficient (across_stable_unit_ids only)\n",
    "# For inbound vs outbound, we derive labels by testing whether each unit has enough bins.\n",
    "#\n",
    "# Interpretation:\n",
    "# - \"stable\": corr high AND peak_shift low AND nrmse low (using simple cutoffs you choose)\n",
    "# - \"unstable\": fails any of those cutoffs\n",
    "# - \"insufficient\": metrics are NaN (not enough bins)\n",
    "#\n",
    "# If you want permutation p-values like your drift code, tell me and Iâ€™ll mirror that exactly.\n",
    "# =========================\n",
    "\n",
    "# Choose thresholds (edit to taste)\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh = 0.10  # in x-units of `speed_norm` (since centers are speed_norm)\n",
    "\n",
    "# metrics_df from the inbound/outbound comparison cell should exist\n",
    "if \"metrics_df\" not in globals():\n",
    "    raise ValueError(\"Expected `metrics_df` from the inbound/outbound comparison cell.\")\n",
    "\n",
    "labels = {}\n",
    "for u in across_stable_unit_ids:\n",
    "    if u not in metrics_df.index:\n",
    "        labels[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    row = metrics_df.loc[u]\n",
    "    c = float(row[\"corr\"]) if np.isfinite(row[\"corr\"]) else np.nan\n",
    "    e = float(row[\"nrmse\"]) if np.isfinite(row[\"nrmse\"]) else np.nan\n",
    "    p = float(row[\"peak_shift_x\"]) if np.isfinite(row[\"peak_shift_x\"]) else np.nan\n",
    "\n",
    "    if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "        labels[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    is_stable = (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh)\n",
    "    labels[u] = \"stable\" if is_stable else \"unstable\"\n",
    "\n",
    "cats = [\"stable\", \"unstable\", \"insufficient\"]\n",
    "counts = {c: list(labels.values()).count(c) for c in cats}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.2*2.2, 3.2*2.2), layout=\"tight\")\n",
    "\n",
    "if \"colors\" in globals() and isinstance(colors, (list, tuple)) and len(colors) >= 3:\n",
    "    bar_colors = [colors[0], colors[1], colors[2]]\n",
    "else:\n",
    "    bar_colors = [\"tab:green\", \"tab:orange\", \"tab:gray\"]\n",
    "\n",
    "ax.bar(cats, [counts[c] for c in cats], color=bar_colors, alpha=0.9)\n",
    "ax.set_ylabel(\"Number of units\")\n",
    "ax.set_title(\"Inbound vs Outbound: across-stable units\")\n",
    "\n",
    "for i, c in enumerate(cats):\n",
    "    ax.text(i, counts[c] + 0.5, str(counts[c]), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Counts:\", counts)\n",
    "print(\"Thresholds:\", dict(corr_thresh=corr_thresh, nrmse_thresh=nrmse_thresh, peak_shift_thresh=peak_shift_thresh))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "909023fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts: {'stable': 29, 'unstable': 151, 'insufficient': 0}\n",
      "Thresholds: {'corr_thresh': 0.3, 'nrmse_thresh': 0.5, 'peak_shift_thresh': 0.1}\n",
      "N evaluated (across_stable_unit_ids): 180\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell â€” Barplot for INBOUND vs OUTBOUND comparison (across-stable units)\n",
    "# Categories are computed from the *inbound/outbound metrics* (corr/nrmse/peak_shift_x).\n",
    "#\n",
    "# Requirements:\n",
    "# - `across_stable_unit_ids` exists\n",
    "# - you have a metrics table for inbound vs outbound with columns:\n",
    "#     corr, nrmse, peak_shift_x\n",
    "#\n",
    "# IMPORTANT (because your notebook overwrites `metrics_df`):\n",
    "# - Prefer `metrics_df_inout` if you saved it.\n",
    "# - Otherwise this will use `metrics_df` (ONLY correct if it currently holds the in/out results).\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if \"across_stable_unit_ids\" not in globals():\n",
    "    raise ValueError(\"Expected `across_stable_unit_ids` to exist.\")\n",
    "\n",
    "# Prefer a dedicated snapshot if you made one\n",
    "if \"metrics_df_inout\" in globals():\n",
    "    metrics_df_use = metrics_df_inout\n",
    "elif \"metrics_df\" in globals():\n",
    "    metrics_df_use = metrics_df\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Could not find `metrics_df_inout` or `metrics_df`.\\n\"\n",
    "        \"Run this right after the inbound/outbound comparison cell, or save:\\n\"\n",
    "        \"  metrics_df_inout = metrics_df.copy()\"\n",
    "    )\n",
    "\n",
    "need_cols = {\"corr\", \"nrmse\", \"peak_shift_x\"}\n",
    "if not need_cols.issubset(set(metrics_df_use.columns)):\n",
    "    raise ValueError(f\"In/out metrics table missing columns {need_cols}; got {list(metrics_df_use.columns)}\")\n",
    "\n",
    "# ---- thresholds (keep same across comparisons unless you intend otherwise) ----\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh = 0.10  # in speed_norm units if your centers are speed_norm\n",
    "\n",
    "labels_inout = {}\n",
    "for u in across_stable_unit_ids:\n",
    "    if u not in metrics_df_use.index:\n",
    "        labels_inout[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    c = metrics_df_use.loc[u, \"corr\"]\n",
    "    e = metrics_df_use.loc[u, \"nrmse\"]\n",
    "    p = metrics_df_use.loc[u, \"peak_shift_x\"]\n",
    "\n",
    "    if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "        labels_inout[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    # \"stable\" here means: inbound and outbound tuning curves are similar\n",
    "    is_stable = (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh)\n",
    "    labels_inout[u] = \"stable\" if is_stable else \"unstable\"\n",
    "\n",
    "cats = [\"stable\", \"unstable\", \"insufficient\"]\n",
    "counts = {c: list(labels_inout.values()).count(c) for c in cats}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.2 * 2.2, 3.2 * 2.2), layout=\"tight\")\n",
    "\n",
    "# Reuse your existing `colors` list if you have it; otherwise default palette\n",
    "if \"colors\" in globals() and isinstance(colors, (list, tuple)) and len(colors) >= 3:\n",
    "    bar_colors = [colors[0], colors[1], colors[2]]\n",
    "else:\n",
    "    bar_colors = [\"tab:green\", \"tab:orange\", \"tab:gray\"]\n",
    "\n",
    "ax.bar(cats, [counts[c] for c in cats], color=bar_colors, alpha=0.9)\n",
    "ax.set_ylabel(\"Number of units\")\n",
    "ax.set_title(\"Inbound vs Outbound robustness (across-stable units)\")\n",
    "\n",
    "# annotate counts\n",
    "for i, c in enumerate(cats):\n",
    "    ax.text(i, counts[c] + 0.5, str(counts[c]), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Counts:\", {c: counts[c] for c in cats})\n",
    "print(\"Thresholds:\", dict(corr_thresh=corr_thresh, nrmse_thresh=nrmse_thresh, peak_shift_thresh=peak_shift_thresh))\n",
    "print(\"N evaluated (across_stable_unit_ids):\", len(across_stable_unit_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba5aa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable units across INBOUND vs OUTBOUND: 98\n",
      "First 30 in/out-stable unit IDs: [2, 4, 5, 9, 10, 16, 18, 19, 21, 23, 29, 30, 31, 32, 35, 42, 46, 49, 60, 65, 67, 69, 73, 75, 82, 84, 85, 86, 87, 90]\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell â€” Plot IN/OUT-ROBUST units (INBOUND vs OUTBOUND)\n",
    "# Produces TWO figures:\n",
    "#   1) INBOUND tuning curves grid (only units stable across inbound vs outbound)\n",
    "#   2) OUTBOUND tuning curves grid (same unit set)\n",
    "#\n",
    "# \"stable units in/out\" = units whose inbound vs outbound curves are similar\n",
    "# by your 3 metrics (corr high, nrmse low, peak_shift_x low), AND finite metrics.\n",
    "#\n",
    "# Expects (from your inbound/outbound pipeline):\n",
    "# - tuning_in, lo_in, hi_in, centers_in\n",
    "# - tuning_out_aligned, lo_out_aligned, hi_out_aligned  (or tuning_out/lo_out/hi_out + centers_out)\n",
    "# - a metrics table for in/out with columns: corr, nrmse, peak_shift_x\n",
    "#   Preferably saved as `metrics_df_inout` (otherwise uses `metrics_df`, which may be overwritten).\n",
    "# - across_stable_unit_ids (used as the unit pool)\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "if \"across_stable_unit_ids\" not in globals():\n",
    "    raise ValueError(\"Expected `across_stable_unit_ids` to exist.\")\n",
    "\n",
    "# Pick the correct metrics table for inbound/outbound\n",
    "if \"metrics_df_inout\" in globals():\n",
    "    metrics_df_use = metrics_df_inout\n",
    "elif \"metrics_df\" in globals():\n",
    "    metrics_df_use = metrics_df\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Could not find inbound/outbound metrics (`metrics_df_inout` or `metrics_df`).\\n\"\n",
    "        \"If metrics_df got overwritten later, rerun the in/out comparison cell and do:\\n\"\n",
    "        \"  metrics_df_inout = metrics_df.copy()\"\n",
    "    )\n",
    "\n",
    "need_cols = {\"corr\", \"nrmse\", \"peak_shift_x\"}\n",
    "if not need_cols.issubset(set(metrics_df_use.columns)):\n",
    "    raise ValueError(f\"In/out metrics table missing columns {need_cols}; got {list(metrics_df_use.columns)}\")\n",
    "\n",
    "# thresholds (edit to match your other sections)\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh = 10  # in speed_norm units\n",
    "\n",
    "# Ensure outbound-aligned dicts exist; if not, fall back\n",
    "if \"tuning_out_aligned\" not in globals():\n",
    "    if not (\"tuning_out\" in globals() and \"centers_out\" in globals()):\n",
    "        raise ValueError(\"Missing `tuning_out_aligned` (or `tuning_out` + `centers_out`). Run your alignment cell first.\")\n",
    "    tuning_out_aligned = tuning_out\n",
    "    lo_out_aligned = lo_out\n",
    "    hi_out_aligned = hi_out\n",
    "\n",
    "# Use inbound centers as the shared x-axis\n",
    "centers = np.asarray(centers_in, float)\n",
    "\n",
    "# Compute the stable (robust) unit set: across_stable_unit_ids + finite metrics + passes thresholds\n",
    "stable_units_inout = []\n",
    "for u in across_stable_unit_ids:\n",
    "    if u not in metrics_df_use.index:\n",
    "        continue\n",
    "\n",
    "    c = metrics_df_use.loc[u, \"corr\"]\n",
    "    e = metrics_df_use.loc[u, \"nrmse\"]\n",
    "    p = metrics_df_use.loc[u, \"peak_shift_x\"]\n",
    "\n",
    "    if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "        continue\n",
    "\n",
    "    # is_stable = (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh)\n",
    "    is_stable = (c <= corr_thresh) or (e >= nrmse_thresh) or (p >= peak_shift_thresh)\n",
    "    if is_stable:\n",
    "        stable_units_inout.append(u)\n",
    "\n",
    "# Also ensure each unit exists in BOTH tuning dicts + CI dicts\n",
    "stable_units_inout = [\n",
    "    u for u in stable_units_inout\n",
    "    if (u in tuning_in) and (u in lo_in) and (u in hi_in)\n",
    "    and (u in tuning_out_aligned) and (u in lo_out_aligned) and (u in hi_out_aligned)\n",
    "]\n",
    "\n",
    "print(\"Stable units across INBOUND vs OUTBOUND:\", len(stable_units_inout))\n",
    "if len(stable_units_inout) == 0:\n",
    "    raise ValueError(\"No in/out-stable units found under these thresholds (or missing tuning/CI entries).\")\n",
    "\n",
    "# Subset dicts so the plotting function only sees the units you want\n",
    "tun_in_stable = {u: tuning_in[u] for u in stable_units_inout}\n",
    "lo_in_stable  = {u: lo_in[u]     for u in stable_units_inout}\n",
    "hi_in_stable  = {u: hi_in[u]     for u in stable_units_inout}\n",
    "\n",
    "tun_out_stable = {u: tuning_out_aligned[u] for u in stable_units_inout}\n",
    "lo_out_stable  = {u: lo_out_aligned[u]     for u in stable_units_inout}\n",
    "hi_out_stable  = {u: hi_out_aligned[u]     for u in stable_units_inout}\n",
    "\n",
    "col_label = speed_col if \"speed_col\" in globals() else \"speed_norm\"\n",
    "\n",
    "# Figure 1: INBOUND\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tun_in_stable,\n",
    "    lo_in_stable,\n",
    "    hi_in_stable,\n",
    "    centers,\n",
    "    column=col_label,\n",
    "    n_units=30,\n",
    "    label=\"INBOUND (in/out-unstable units; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Figure 2: OUTBOUND\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tun_out_stable,\n",
    "    lo_out_stable,\n",
    "    hi_out_stable,\n",
    "    centers,\n",
    "    column=col_label,\n",
    "    n_units=30,\n",
    "    label=\"OUTBOUND (in/out-unstable units; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "print(\"First 30 in/out-stable unit IDs:\", stable_units_inout[:30])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ab744",
   "metadata": {},
   "source": [
    "#### Retrieve firing properties of each unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7ce986f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-05 11:45:39,290][WARNING]: MySQL server has gone away. Reconnecting to the server.\n",
      "[2026-01-05 11:48:51,598][WARNING]: Skipped checksum for file with hash: ae416731-c7f6-96c4-58b5-f63c6137d5b2, and path: /media/labuser/NA_1_2025/spyglass/wilbur/analysis/wilbur20210512/wilbur20210512_5T9T8087C9.nwb\n",
      "[2026-01-05 11:49:21,140][WARNING]: Skipped checksum for file with hash: efa5c4e3-437f-9f80-dc82-071a6852253d, and path: /media/labuser/NA_1_2025/spyglass/wilbur/analysis/wilbur20210512/wilbur20210512_3GTLT4U0L5.nwb\n",
      "[2026-01-05 11:49:50,178][WARNING]: Skipped checksum for file with hash: 4fe4d66a-3248-0b34-c4f8-15d475921734, and path: /media/labuser/NA_1_2025/spyglass/wilbur/analysis/wilbur20210512/wilbur20210512_AAB10XJKBQ.nwb\n",
      "[2026-01-05 11:50:19,214][WARNING]: Skipped checksum for file with hash: 3e76aad8-7e8e-a8b0-c4da-193fe09fc10a, and path: /media/labuser/NA_1_2025/spyglass/wilbur/analysis/wilbur20210512/wilbur20210512_E3F5MSQTCQ.nwb\n",
      "[2026-01-05 11:50:48,358][WARNING]: Skipped checksum for file with hash: 676121b3-a983-4d36-9931-85731ed52264, and path: /media/labuser/NA_1_2025/spyglass/wilbur/analysis/wilbur20210512/wilbur20210512_8U2V42ZXRX.nwb\n",
      "[2026-01-05 11:51:17,892][WARNING]: Skipped checksum for file with hash: 080a0ccb-e708-9189-9d3b-1494584723d1, and path: /media/labuser/NA_1_2025/spyglass/wilbur/analysis/wilbur20210512/wilbur20210512_718I728WPW.nwb\n",
      "[2026-01-05 11:51:46,995][WARNING]: Skipped checksum for file with hash: 2cc6b441-7ed5-0614-6be0-5dfa638d9225, and path: /media/labuser/NA_1_2025/spyglass/wilbur/analysis/wilbur20210512/wilbur20210512_819RJCTZU8.nwb\n",
      "[2026-01-05 11:52:16,160][WARNING]: Skipped checksum for file with hash: 7c0d0b44-2a9c-3b78-ab11-f74b25a3251f, and path: /media/labuser/NA_1_2025/spyglass/wilbur/analysis/wilbur20210512/wilbur20210512_YF9UMEI5Z0.nwb\n"
     ]
    }
   ],
   "source": [
    "# l_mpfc_recording, l_mpfc_sorting = get_si_recording_and_sorting({\"sorted_spikes_group_name\": \"left mPFC\"})\n",
    "mpfc_recording, mpfc_sorting =  get_si_recording_and_sorting({\"sorted_spikes_group_name\": \"mPFC\", **session_restrict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f88c613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34486/2250251112.py:3: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  mpfc_we = si.extract_waveforms(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e415418050294bc39115b83f81c5932f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms shared_memory multi buffer:   0%|          | 0/3637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd96c6e4a244d0eb21ccdc86a17ed21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms shared_memory multi buffer:   0%|          | 0/3637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd7f1e3d97c474c8fcd4a5dcea25443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/3637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "waveform_folder = \"/media/labuser/NA_1_2025/spyglass/wilbur/analysis/waveforms_mpfc/\" # always add to base dir!\n",
    "\n",
    "mpfc_we = si.extract_waveforms(\n",
    "    mpfc_recording,\n",
    "    mpfc_sorting,\n",
    "    folder=waveform_folder,\n",
    "    load_if_exists=True,         \n",
    "    overwrite=False,             \n",
    "    max_spikes_per_unit=300,     \n",
    "    ms_before=0.75,               \n",
    "    ms_after=1.5,                \n",
    "    n_jobs= 5,                    \n",
    "    chunk_duration=\"1s\",         \n",
    "    progress_bar=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c8621dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unit_spike_waveform_grid(\n",
    "    waveform_extractor,\n",
    "    recording,\n",
    "    unit_ids=None,\n",
    "    *,\n",
    "    n_units=6,\n",
    "    n_spikes=6,                 # spikes PER unit\n",
    "    segment_index=0,\n",
    "    seed=0,\n",
    "    ncols=3,                    # 6 units -> 2 rows x 3 cols by default\n",
    "    y_unit=\"uV\",                # \"uV\" or \"V\"\n",
    "    show_template=True,\n",
    "    alpha=0.35,\n",
    "    spike_lw=0.8,\n",
    "    template_lw=2.5,\n",
    "    unit_label_offset=0,        # set to 1 if you want to display 1-based unit numbers\n",
    "    figsize=None,\n",
    "    spike_indices_by_unit=None, # optional dict: {unit_id: array/list of spike indices}\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot waveforms for 6 units in a grid, each subplot overlays N spike waveforms\n",
    "    (N must be even; default N=6). Uses each unit's \"best channel\" (max template PTP).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    waveform_extractor : spikeinterface WaveformExtractor (or compatible)\n",
    "        Must support .get_waveforms(unit_id, ...) and .get_template(unit_id).\n",
    "    recording : spikeinterface Recording (or compatible)\n",
    "        Used for sampling frequency to compute time axis.\n",
    "    unit_ids : list[int] | None\n",
    "        Which units to plot. If None, uses the first `n_units` units from the extractor.\n",
    "    n_units : int\n",
    "        Number of units/subplots. Default 6.\n",
    "    n_spikes : int (even)\n",
    "        Number of spikes PER unit to overlay. Default 6.\n",
    "    spike_indices_by_unit : dict | None\n",
    "        If provided, choose these spike indices per unit (overrides random sampling).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig, axes, chosen_spike_indices_by_unit\n",
    "    \"\"\"\n",
    "    if n_spikes <= 0:\n",
    "        raise ValueError(\"n_spikes must be >= 1\")\n",
    "    if n_spikes % 2 != 0:\n",
    "        raise ValueError(f\"n_spikes must be even (got {n_spikes})\")\n",
    "\n",
    "    # Get unit list (default: first n_units available)\n",
    "    if unit_ids is None:\n",
    "        if hasattr(waveform_extractor, \"sorting\"):\n",
    "            unit_ids = list(waveform_extractor.sorting.get_unit_ids())\n",
    "        elif hasattr(waveform_extractor, \"unit_ids\"):\n",
    "            unit_ids = list(waveform_extractor.unit_ids)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Couldn't infer unit_ids from waveform_extractor; pass unit_ids=[...] explicitly.\"\n",
    "            )\n",
    "    unit_ids = list(unit_ids)[:n_units]\n",
    "    if len(unit_ids) != n_units:\n",
    "        raise ValueError(f\"Need {n_units} unit_ids, got {len(unit_ids)}\")\n",
    "\n",
    "    # y scaling\n",
    "    if y_unit == \"uV\":\n",
    "        scale = 1.0\n",
    "        ylabel = \"amplitude (ÂµV)\"\n",
    "    elif y_unit == \"V\":\n",
    "        scale = 1e-6\n",
    "        ylabel = \"amplitude (V)\"\n",
    "    else:\n",
    "        raise ValueError(\"y_unit must be 'uV' or 'V'\")\n",
    "\n",
    "    # Robust helper for older/newer spikeinterface signatures\n",
    "    def _we_get_waveforms(we, unit_id, segment_index=0):\n",
    "        try:\n",
    "            return we.get_waveforms(unit_id, segment_index=segment_index)\n",
    "        except TypeError:\n",
    "            try:\n",
    "                return we.get_waveforms(unit_id, segment_index)\n",
    "            except TypeError:\n",
    "                return we.get_waveforms(unit_id)\n",
    "\n",
    "    fs = float(recording.get_sampling_frequency())\n",
    "    t_ms = (\n",
    "        (np.arange(waveform_extractor.nbefore + waveform_extractor.nafter) - waveform_extractor.nbefore)\n",
    "        / fs\n",
    "        * 1000.0\n",
    "    )\n",
    "\n",
    "    nrows = int(np.ceil(n_units / ncols))\n",
    "    if figsize is None:\n",
    "        figsize = (4.2 * ncols, 2.8 * nrows)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        figsize=figsize,\n",
    "        layout=\"tight\",\n",
    "    )\n",
    "    axes = np.atleast_1d(axes).ravel()\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    chosen = {}\n",
    "\n",
    "    for ax_i, unit_id in enumerate(unit_ids):\n",
    "        ax = axes[ax_i]\n",
    "\n",
    "        wfs = _we_get_waveforms(waveform_extractor, unit_id, segment_index=segment_index)\n",
    "        # wfs shape: (n_spikes_available, n_samples, n_channels)\n",
    "        if wfs is None or wfs.size == 0:\n",
    "            ax.set_title(f\"unit {unit_id + unit_label_offset} (no waveforms)\")\n",
    "            ax.axis(\"off\")\n",
    "            chosen[unit_id] = np.array([], dtype=int)\n",
    "            continue\n",
    "\n",
    "        template = waveform_extractor.get_template(unit_id)  # (n_samples, n_chans)\n",
    "        best_chan = int(np.argmax(template.ptp(axis=0)))\n",
    "\n",
    "        n_available = wfs.shape[0]\n",
    "        if spike_indices_by_unit is not None and unit_id in spike_indices_by_unit:\n",
    "            idx = np.asarray(spike_indices_by_unit[unit_id], dtype=int)\n",
    "            idx = idx[(idx >= 0) & (idx < n_available)]\n",
    "            if idx.size == 0:\n",
    "                raise ValueError(f\"spike_indices_by_unit[{unit_id}] had no valid indices in [0, {n_available})\")\n",
    "            if idx.size > n_spikes:\n",
    "                idx = idx[:n_spikes]\n",
    "        else:\n",
    "            n_show = min(n_spikes, n_available)\n",
    "            idx = rng.choice(n_available, size=n_show, replace=False) if n_available > n_show else np.arange(n_available)\n",
    "\n",
    "        chosen[unit_id] = idx\n",
    "\n",
    "        # plot spike waveforms on best channel\n",
    "        y = wfs[idx, :, best_chan] * scale\n",
    "        ax.plot(t_ms, y.T, color=\"k\", alpha=alpha, linewidth=spike_lw)\n",
    "\n",
    "        # optional: overlay template thicker\n",
    "        if show_template:\n",
    "            ax.plot(t_ms, template[:, best_chan] * scale, color=\"tab:blue\", linewidth=template_lw)\n",
    "\n",
    "        ax.axvline(0, color=\"k\", linewidth=1.2, alpha=0.35, linestyle=\"--\")\n",
    "        # ax.set_title(f\"unit {unit_id + unit_label_offset}  (n={len(idx)})\")\n",
    "\n",
    "    # Turn off any unused axes\n",
    "    for j in range(n_units, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    # Axis labels (outer)\n",
    "    for ax in axes[:n_units]:\n",
    "        ax.set_xlabel(\"time (ms)\")\n",
    "    axes[0].set_ylabel(ylabel)\n",
    "\n",
    "    return fig, axes.reshape(nrows, ncols), chosen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "363b0961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 1260x560 with 6 Axes>,\n",
       " array([[<Axes: xlabel='time (ms)', ylabel='amplitude (ÂµV)'>,\n",
       "         <Axes: xlabel='time (ms)'>, <Axes: xlabel='time (ms)'>],\n",
       "        [<Axes: xlabel='time (ms)'>, <Axes: xlabel='time (ms)'>,\n",
       "         <Axes: xlabel='time (ms)'>]], dtype=object),\n",
       " {0: array([141, 153]),\n",
       "  7: array([ 10, 284]),\n",
       "  12: array([284, 246]),\n",
       "  23: array([260,  93]),\n",
       "  31: array([248,  81]),\n",
       "  44: array([122, 193])})"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default: first 6 units, 6 spikes/unit, 2x3 grid\n",
    "plot_unit_spike_waveform_grid(mpfc_we, mpfc_recording)\n",
    "\n",
    "# choose exactly which units (6 of them)\n",
    "plot_unit_spike_waveform_grid(\n",
    "    mpfc_we,\n",
    "    mpfc_recording,\n",
    "    unit_ids=[0, 7, 12, 23, 31, 44],  # <-- your chosen units\n",
    "    n_spikes=2,\n",
    "    seed=1,\n",
    "    unit_label_offset=1,             # if you want titles to show 1-based indexing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mask = (trialized_position[\"zone\"] == \"run\") #& (trialized_position[\"trial_type\"]==\"inbound\")\n",
    "outbound_mask = (trialized_position[\"zone\"] == \"run\") & (trialized_position[\"trial_type\"]==\"outbound\")\n",
    "inbound_mask = (trialized_position[\"zone\"] == \"run\") & (trialized_position[\"trial_type\"]==\"inbound\") \n",
    "\n",
    "mpfc_sorting_run = restrict_sorting_by_position_mask(\n",
    "    sorting=mpfc_sorting,\n",
    "    recording=mpfc_recording,\n",
    "    position_df=trialized_position,\n",
    "    mask=run_mask,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "mpfc_sorting_outbound = restrict_sorting_by_position_mask(\n",
    "    sorting=mpfc_sorting,\n",
    "    recording=mpfc_recording,\n",
    "    position_df=trialized_position,\n",
    "    mask=outbound_mask,\n",
    ")\n",
    "\n",
    "mpfc_sorting_inbound = restrict_sorting_by_position_mask(\n",
    "    sorting=mpfc_sorting,\n",
    "    recording=mpfc_recording,\n",
    "    position_df=trialized_position,\n",
    "    mask=inbound_mask,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "e6014824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 900x440 with 6 Axes>,\n",
       " array([[<Axes: ylabel='unit 23 (1.40 Hz)'>, <Axes: >, <Axes: >],\n",
       "        [<Axes: xlabel='Speed (cm/s)', ylabel='unit 8 (2.80 Hz)'>,\n",
       "         <Axes: xlabel='Lag (ms)'>, <Axes: xlabel='Time (ms)'>]],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_type = \"inbound\"\n",
    "\n",
    "\n",
    "if trial_type == \"inbound\":\n",
    "    sorting = l_mpfc_sorting_inbound\n",
    "elif trial_type == \"outbound\":\n",
    "    sorting = l_mpfc_sorting_outbound\n",
    "\n",
    "plot_unit_speed_acg_template_grid(\n",
    "    # unit_ids=[2, 8, 13, 16, 17, 18, 32, 28], # the \"interesting\" units\n",
    "    unit_ids = [23, 8], # left vs right tuned on the inboud trials\n",
    "    spikes_list=l_mpfc_spikes,\n",
    "    speed_tuning=speed_tuning,\n",
    "    speed_bin_centers=speed_bin_centers,\n",
    "    sorting=sorting,               \n",
    "    waveform_extractor=l_mpfc_we,\n",
    "    position_df=trialized_position[(trialized_position[\"trial_type\"]==trial_type)],     \n",
    "    mask=None,\n",
    "    plot_speed=True,\n",
    "    plot_acg=True,\n",
    "    plot_template=True,\n",
    "    bin_ms=20.0,\n",
    "    window_ms=1000.0,\n",
    "    suptitle = \"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad926318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n"
     ]
    }
   ],
   "source": [
    "# Plot ALL waveforms overlapped (first 5 units), all the same color\n",
    "\n",
    "unit_ids_5 = list(mpfc_sorting.get_unit_ids()[:5])\n",
    "mpfc_sorting_5 = mpfc_sorting.select_units(unit_ids_5)\n",
    "\n",
    "we_folder_5 = Path(base_dir) / \"waveforms\" / \"mpfc_first5_units\"\n",
    "\n",
    "if \"mpfc_we_5\" in globals():\n",
    "    we_5 = mpfc_we_5\n",
    "elif we_folder_5.exists():\n",
    "    we_5 = sc.WaveformExtractor.load(we_folder_5)\n",
    "else:\n",
    "    we_5 = sc.extract_waveforms(\n",
    "        mpfc_recording,\n",
    "        mpfc_sorting_5,\n",
    "        folder=we_folder_5,\n",
    "        ms_before=1.0,\n",
    "        ms_after=2.0,\n",
    "        max_spikes_per_unit=200,\n",
    "        n_jobs=16,\n",
    "        overwrite=False,\n",
    "    )\n",
    "    mpfc_we_5 = we_5\n",
    "\n",
    "\n",
    "def _we_get_waveforms(we, unit_id, segment_index=0):\n",
    "    try:\n",
    "        return we.get_waveforms(unit_id, segment_index=segment_index)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            return we.get_waveforms(unit_id, segment_index)\n",
    "        except TypeError:\n",
    "            return we.get_waveforms(unit_id)\n",
    "\n",
    "\n",
    "color = \"#1188d8\"\n",
    "segment_index = 0\n",
    "max_spikes_to_plot_per_unit = 400  # increase/decrease depending on how dense you want it\n",
    "alpha = 0.1\n",
    "single_lw = 1.5\n",
    "\n",
    "fs = mpfc_recording.get_sampling_frequency()\n",
    "t_ms = (np.arange(we_5.nbefore + we_5.nafter) - we_5.nbefore) / fs * 1000\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10), layout=\"tight\")\n",
    "\n",
    "for unit_id in unit_ids_5:\n",
    "    wfs = _we_get_waveforms(we_5, unit_id, segment_index=segment_index)   # (n_spikes, n_samples, n_chans)\n",
    "    template = we_5.get_template(unit_id)                                 # (n_samples, n_chans)\n",
    "\n",
    "    best_chan = int(np.argmax(template.ptp(axis=0)))\n",
    "    w = wfs[:, :, best_chan]  # (n_spikes, n_samples)\n",
    "\n",
    "    if w.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    n_show = min(w.shape[0], max_spikes_to_plot_per_unit)\n",
    "    idx = (\n",
    "        np.random.choice(w.shape[0], size=n_show, replace=False)\n",
    "        if w.shape[0] > n_show\n",
    "        else np.arange(w.shape[0])\n",
    "    )\n",
    "\n",
    "    # plot all selected waveforms for this unit, overlaid onto the SAME axis\n",
    "    ax.plot(t_ms, w[idx].T, color='k', alpha=alpha, linewidth=single_lw)\n",
    "\n",
    "ax.axvline(0, color=\"k\", linewidth=1.5, alpha=0.4, linestyle = \"--\")\n",
    "# ax.set_title(f\"Overlaid waveforms (first {len(unit_ids_5)} units)\", fontsize=12)\n",
    "ax.set_xlabel(\"time (ms)\")\n",
    "ax.set_ylabel(\"amplitude\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67674e3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'we_5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 56\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fig\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Example (uses your notebook-defined `colors` automatically):\u001b[39;00m\n\u001b[1;32m     55\u001b[0m plot_unit_templates_overlaid_colored(\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mwe_5\u001b[49m,\n\u001b[1;32m     57\u001b[0m     mpfc_recording,\n\u001b[1;32m     58\u001b[0m     unit_ids_5,\n\u001b[1;32m     59\u001b[0m     y_unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     60\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'we_5' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_unit_templates_overlaid_colored(\n",
    "    waveform_extractor,\n",
    "    recording,\n",
    "    unit_ids,\n",
    "    colors=None,             # pass your existing `colors` list; defaults to global `colors` if present\n",
    "    y_unit=\"V\",              # \"uV\" or \"V\"\n",
    "    lw=2.0,\n",
    "    alpha=0.95,\n",
    "):\n",
    "    \"\"\"\n",
    "    Overlay per-unit templates on a single axis, one color per unit,\n",
    "    using each unit's best channel (max peak-to-peak on template).\n",
    "    \"\"\"\n",
    "    unit_ids = list(unit_ids)\n",
    "\n",
    "    if colors is None:\n",
    "        colors = globals().get(\"colors\", None)\n",
    "    if colors is None:\n",
    "        raise ValueError(\"No colors provided and global `colors` not found. Pass colors=colors.\")\n",
    "\n",
    "    if len(colors) < len(unit_ids):\n",
    "        raise ValueError(f\"Need at least {len(unit_ids)} colors, got {len(colors)}\")\n",
    "\n",
    "    if y_unit == \"uV\":\n",
    "        scale = 1.0\n",
    "        ylabel = \"amplitude (ÂµV)\"\n",
    "    elif y_unit == \"V\":\n",
    "        scale = 1e-6\n",
    "        ylabel = \"amplitude (V)\"\n",
    "    else:\n",
    "        raise ValueError(\"y_unit must be 'uV' or 'V'\")\n",
    "\n",
    "    fs = recording.get_sampling_frequency()\n",
    "    t_ms = (np.arange(waveform_extractor.nbefore + waveform_extractor.nafter) - waveform_extractor.nbefore) / fs * 1000\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10), layout=\"tight\")\n",
    "\n",
    "    for i, unit_id in enumerate(unit_ids):\n",
    "        template = waveform_extractor.get_template(unit_id)  # (n_samples, n_chans)\n",
    "        best_chan = int(np.argmax(template.ptp(axis=0)))\n",
    "        y = template[:, best_chan] * scale\n",
    "\n",
    "        ax.plot(t_ms, y, color=colors[i], alpha=alpha, linewidth=5, label=str(unit_id+1))\n",
    "\n",
    "    ax.axvline(0, color=\"k\", linewidth=1.5, alpha=0.4, linestyle = \"--\")\n",
    "    # ax.set_title(\"Overlaid templates\", fontsize=12)\n",
    "    ax.set_xlabel(\"time (ms)\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.legend(title=\"Unit\", frameon=False, fontsize=16, title_fontsize=18)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Example (uses your notebook-defined `colors` automatically):\n",
    "plot_unit_templates_overlaid_colored(\n",
    "    we_5,\n",
    "    mpfc_recording,\n",
    "    unit_ids_5,\n",
    "    y_unit=\"V\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de28db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n",
      "findfont: Font family 'Switzer' not found.\n"
     ]
    }
   ],
   "source": [
    "# Plot 100 ms of raw data from ONE channel, bandpass filtered 300â€“6000 Hz\n",
    "\n",
    "fs = mpfc_recording.get_sampling_frequency()\n",
    "duration_s = 0.100\n",
    "n_frames = int(round(duration_s * fs))\n",
    "\n",
    "t_start_s = 0.0  # change this to move the window\n",
    "start_frame = int(round(t_start_s * fs))\n",
    "end_frame = start_frame + n_frames\n",
    "\n",
    "# choose a single channel (change index or set chan_id explicitly)\n",
    "chan_id = mpfc_recording.channel_ids[0]\n",
    "\n",
    "rec_bp = si.preprocessing.bandpass_filter(\n",
    "    mpfc_recording,\n",
    "    freq_min=300.0,\n",
    "    freq_max=6000.0,\n",
    ")\n",
    "\n",
    "get_traces_kwargs = dict(start_frame=start_frame, end_frame=end_frame, channel_ids=[chan_id])\n",
    "if getattr(mpfc_recording, \"get_num_segments\", lambda: 1)() > 1:\n",
    "    get_traces_kwargs[\"segment_index\"] = 0\n",
    "\n",
    "try:\n",
    "    trace = rec_bp.get_traces(**get_traces_kwargs)[:, 0]  # (n_frames,)\n",
    "except TypeError:\n",
    "    get_traces_kwargs.pop(\"segment_index\", None)\n",
    "    trace = rec_bp.get_traces(**get_traces_kwargs)[:, 0]\n",
    "\n",
    "t_ms = (np.arange(trace.shape[0]) / fs) * 1000\n",
    "\n",
    "# your recording appears to already be in ÂµV; switch to Volts by setting scale=1e-6\n",
    "scale = 1.0\n",
    "ylabel = \"amplitude (ÂµV)\"\n",
    "trace = trace * scale\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10), layout=\"tight\")\n",
    "ax.plot(t_ms, trace, color=\"k\", linewidth=2)\n",
    "ax.set_title(f\"Channel {chan_id} bandpass 300â€“6000 Hz (100 ms)\")\n",
    "ax.set_xlabel(\"time (ms)\")\n",
    "ax.set_ylabel(ylabel)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "59ac6c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 900x440 with 6 Axes>,\n",
       " array([[<Axes: ylabel='unit 21 (2.94 Hz)'>, <Axes: >, <Axes: >],\n",
       "        [<Axes: xlabel='Speed (cm/s)', ylabel='unit 70 (3.06 Hz)'>,\n",
       "         <Axes: xlabel='Lag (ms)'>, <Axes: xlabel='Time (ms)'>]],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_unit_speed_acg_template_grid([21, 70], mpfc_spikes, speed_tuning, speed_centers, mpfc_sorting, mpfc_we, trialized_position, base_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef702712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trialized_position.copy().sort_index()\n",
    "\n",
    "base_mask = (df[\"zone\"] == \"run\") & df[\"trial_type\"].isin([\"inbound\", \"outbound\"])\n",
    "\n",
    "res_inout = permutation_test_tuning_difference_trial_labels(\n",
    "    df,\n",
    "    column=\"speed\",\n",
    "    spikes_list=mpfc_spikes,\n",
    "    base_mask=base_mask,\n",
    "    trial_column=\"trial_number\",\n",
    "    label_column=\"trial_type\",\n",
    "    label_a=\"inbound\",\n",
    "    label_b=\"outbound\",\n",
    "    binning=\"sliding\",\n",
    "    window_width=0.20,\n",
    "    window_step=0.02,\n",
    "    tuner_min=0.0,\n",
    "    tuner_max=1.0,\n",
    "    n_perm=2000,\n",
    "    random_state=0,\n",
    "    strata_column=\"epoch\",              # recommended if epochs differ\n",
    "    units=across_stable_unit_ids,       # optional\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40120340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_corr</th>\n",
       "      <th>p_nrmse</th>\n",
       "      <th>p_peak_shift_x</th>\n",
       "      <th>p_mean_rate_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.442278861</td>\n",
       "      <td>0.221389305</td>\n",
       "      <td>0.999000500</td>\n",
       "      <td>0.095452274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.890269151</td>\n",
       "      <td>0.581709145</td>\n",
       "      <td>0.529735132</td>\n",
       "      <td>0.528235882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.123938031</td>\n",
       "      <td>0.026486757</td>\n",
       "      <td>0.031984008</td>\n",
       "      <td>0.044977511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.355322339</td>\n",
       "      <td>0.042478761</td>\n",
       "      <td>0.663168416</td>\n",
       "      <td>0.306346827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.198900550</td>\n",
       "      <td>0.238880560</td>\n",
       "      <td>0.412293853</td>\n",
       "      <td>0.472263868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       p_corr     p_nrmse  p_peak_shift_x  p_mean_rate_diff\n",
       "0 0.442278861 0.221389305     0.999000500       0.095452274\n",
       "2 0.890269151 0.581709145     0.529735132       0.528235882\n",
       "3 0.123938031 0.026486757     0.031984008       0.044977511\n",
       "4 0.355322339 0.042478761     0.663168416       0.306346827\n",
       "5 0.198900550 0.238880560     0.412293853       0.472263868"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_corr</th>\n",
       "      <th>q_nrmse</th>\n",
       "      <th>q_peak_shift_x</th>\n",
       "      <th>q_mean_rate_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.582752102</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.373508898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.943312128</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.748680778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.339830085</td>\n",
       "      <td>0.605151969</td>\n",
       "      <td>0.307087835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.348086826</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.624631504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.605612687</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.735382309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       q_corr     q_nrmse  q_peak_shift_x  q_mean_rate_diff\n",
       "0 1.000000000 0.582752102     1.000000000       0.373508898\n",
       "2 1.000000000 0.943312128     1.000000000       0.748680778\n",
       "3 1.000000000 0.339830085     0.605151969       0.307087835\n",
       "4 1.000000000 0.348086826     1.000000000       0.624631504\n",
       "5 1.000000000 0.605612687     1.000000000       0.735382309"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sig units (q_max<0.05): 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "display(res_inout[\"p_values\"].head())\n",
    "display(res_inout[\"q_values\"].head())\n",
    "sig_units = res_inout[\"q_max\"][res_inout[\"q_max\"] < 0.05].index.to_numpy()\n",
    "print(\"sig units (q_max<0.05):\", len(sig_units))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d74d5",
   "metadata": {},
   "source": [
    "#### Figurl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "7ca658a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trialized_position\n",
    "# speed (bootstrap)\n",
    "speed_tuning, speed_centers, speed_lower, speed_upper, slope_boot_s, curvature_boot_s = compute_tuning_bootstrap_trials(\n",
    "    df, \"speed\", spikes_list, n_bins=8, mask=mask, trial_column=\"trial_number\", n_boot=500, random_state=0\n",
    ")\n",
    "speed_shape_by_unit, _ = classify_tuning_shapes_from_bootstraps(slope_boot_s, curvature_boot_s, ci=0.95, min_valid_boot=200)\n",
    "\n",
    "# progress (bootstrap)\n",
    "progress_tuning, progress_centers, progress_lower, progress_upper, slope_boot_p, curvature_boot_p = compute_tuning_bootstrap_trials(\n",
    "    df, \"trial_progress\", spikes_list, n_bins=8, mask=mask, trial_column=\"trial_number\", n_boot=500, random_state=0\n",
    ")\n",
    "progress_shape_by_unit, _ = classify_tuning_shapes_from_bootstraps(slope_boot_p, curvature_boot_p, ci=0.95, min_valid_boot=200)\n",
    "\n",
    "# location (non-bootstrap example)\n",
    "location_tuning, location_centers = compute_tuning(\n",
    "    trialized_position, \"trial_progress_distance\", spikes_list, n_bins=8, mask=mask\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "50664301",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_ids = select_units_by_shape(speed_shape_by_unit, include_shapes=[\"decreasing\"])\n",
    "# unit_ids = unit_ids[:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bde235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n"
     ]
    }
   ],
   "source": [
    "df = trialized_position.copy()\n",
    "speed_tuning, speed_centers, lo, hi, slope_boot, curv_boot = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    spikes_list=spikes_list,\n",
    "    mask=mask,\n",
    "    column =\"speed_norm\",\n",
    "    # progress_col=\"trial_progress_distance\",\n",
    "    # progress_bins=np.linspace(0, 1, 6),  # still discrete along progress\n",
    "    binning=\"sliding\",\n",
    "    window_width=0.20,\n",
    "    window_step=0.04,\n",
    "    tuner_min=0.0,\n",
    "    tuner_max=1.0,\n",
    "    n_boot=500,\n",
    "    random_state=0,\n",
    "    peak_normalize = True\n",
    ")\n",
    "\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    speed_tuning, lo, hi, speed_centers,\n",
    "    column=\"speed_norm\",\n",
    "    n_units=60,\n",
    "    s=1,\n",
    "    color=\"tab:blue\",\n",
    "    ylims = (0,1),\n",
    "    peak_normalize = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4d81d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_by_unit, stats_by_unit = classify_tuning_shapes_from_bootstraps(\n",
    "    slope_boot,\n",
    "    curv_boot,\n",
    "    bin_centers=speed_centers,\n",
    "    ci=0.95,\n",
    "    min_valid_boot=200,\n",
    "    normalize_x=False #is fine for speed_norm in [0,1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d08d28",
   "metadata": {},
   "source": [
    "#### Left vs right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b590528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "across_stable_unit_ids = sorted([u for u, s in across_epoch_status.items() if s == \"stable\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4b2d25e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials LEFT: 46\n",
      "Trials RIGHT: 46\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 1 â€” Setup masks (OUTBOUND LEFT vs OUTBOUND RIGHT) using across_stable_unit_ids only\n",
    "# =========================\n",
    "\n",
    "if \"across_stable_unit_ids\" not in globals():\n",
    "    raise ValueError(\"Expected `across_stable_unit_ids` to already exist.\")\n",
    "\n",
    "df = trialized_position.copy().sort_index()\n",
    "spikes_list = mpfc_spikes.copy()\n",
    "\n",
    "# Column defining choice on outbound trials\n",
    "choice_col = \"left/right\"   # values: \"left\" or \"right\"\n",
    "choice_left = \"left\"\n",
    "choice_right = \"right\"\n",
    "\n",
    "# Tuning x-axis\n",
    "speed_col = \"speed\"    # keep consistent with your other pipelines (0..1)\n",
    "trial_col = \"trial_number\"\n",
    "\n",
    "# Sliding-window (continuous) binning params\n",
    "window_width = 20\n",
    "window_step = 2\n",
    "tuner_min = 0\n",
    "tuner_max = 120\n",
    "\n",
    "# Bootstrap params\n",
    "n_boot = 500\n",
    "random_state = 0\n",
    "\n",
    "# Metric params\n",
    "min_units_ok_bins = 3\n",
    "\n",
    "# Common inclusion mask (so only the choice differs)\n",
    "base_mask = (\n",
    "    (df[\"zone\"] == \"run\")\n",
    "    & (df[\"trial_type\"] == \"outbound\")\n",
    ")\n",
    "\n",
    "mask_common = (\n",
    "    base_mask\n",
    "    & df[trial_col].notna()\n",
    "    & np.isfinite(df[speed_col].to_numpy())\n",
    "    & df[choice_col].notna()\n",
    ")\n",
    "\n",
    "mask_left = mask_common & (df[choice_col] == choice_left)\n",
    "mask_right = mask_common & (df[choice_col] == choice_right)\n",
    "\n",
    "n_trials_left = int(df.loc[mask_left, trial_col].nunique())\n",
    "n_trials_right = int(df.loc[mask_right, trial_col].nunique())\n",
    "print(\"Trials LEFT:\", n_trials_left)\n",
    "print(\"Trials RIGHT:\", n_trials_right)\n",
    "\n",
    "if n_trials_left < 2 or n_trials_right < 2:\n",
    "    raise ValueError(\"Need >=2 trials in BOTH left and right for trial bootstrap.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e7ba3dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left units: 180 n_centers: 51\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 2 â€” LEFT tuning (BOOTSTRAPPED; sliding windows)\n",
    "# =========================\n",
    "\n",
    "(\n",
    "    tuning_left,\n",
    "    centers_left,\n",
    "    lo_left,\n",
    "    hi_left,\n",
    "    slope_boot_left,\n",
    "    curv_boot_left,\n",
    ") = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    column=speed_col,\n",
    "    spikes_list=spikes_list,\n",
    "    n_bins=8,  # ignored for sliding; kept for API compatibility\n",
    "    mask=mask_left,\n",
    "    trial_column=trial_col,\n",
    "    n_boot=n_boot,\n",
    "    ci=0.95,\n",
    "    random_state=random_state,\n",
    "    tuner_bins=None,\n",
    "    binning=\"sliding\",\n",
    "    window_width=window_width,\n",
    "    window_step=window_step,\n",
    "    tuner_min=tuner_min,\n",
    "    tuner_max=tuner_max,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Restrict to across-stable units only\n",
    "tuning_left = {u: tuning_left[u] for u in across_stable_unit_ids if u in tuning_left}\n",
    "lo_left = {u: lo_left[u] for u in across_stable_unit_ids if u in lo_left}\n",
    "hi_left = {u: hi_left[u] for u in across_stable_unit_ids if u in hi_left}\n",
    "\n",
    "print(\"Left units:\", len(tuning_left), \"n_centers:\", len(centers_left))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e461b754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right units: 180 n_centers: 51\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 3 â€” RIGHT tuning (BOOTSTRAPPED; sliding windows)\n",
    "# =========================\n",
    "\n",
    "(\n",
    "    tuning_right,\n",
    "    centers_right,\n",
    "    lo_right,\n",
    "    hi_right,\n",
    "    slope_boot_right,\n",
    "    curv_boot_right,\n",
    ") = compute_tuning_bootstrap_trials(\n",
    "    df,\n",
    "    column=speed_col,\n",
    "    spikes_list=spikes_list,\n",
    "    n_bins=8,  # ignored for sliding; kept for API compatibility\n",
    "    mask=mask_right,\n",
    "    trial_column=trial_col,\n",
    "    n_boot=n_boot,\n",
    "    ci=0.95,\n",
    "    random_state=random_state,\n",
    "    tuner_bins=None,\n",
    "    binning=\"sliding\",\n",
    "    window_width=window_width,\n",
    "    window_step=window_step,\n",
    "    tuner_min=tuner_min,\n",
    "    tuner_max=tuner_max,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Restrict to across-stable units only\n",
    "tuning_right = {u: tuning_right[u] for u in across_stable_unit_ids if u in tuning_right}\n",
    "lo_right = {u: lo_right[u] for u in across_stable_unit_ids if u in lo_right}\n",
    "hi_right = {u: hi_right[u] for u in across_stable_unit_ids if u in hi_right}\n",
    "\n",
    "print(\"Right units:\", len(tuning_right), \"n_centers:\", len(centers_right))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8020cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units compared: 180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>peak_shift_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.810283484</td>\n",
       "      <td>0.416328933</td>\n",
       "      <td>30.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012215897</td>\n",
       "      <td>0.483568490</td>\n",
       "      <td>26.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.892828859</td>\n",
       "      <td>0.264860740</td>\n",
       "      <td>2.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.229041110</td>\n",
       "      <td>0.516809621</td>\n",
       "      <td>32.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.224708122</td>\n",
       "      <td>0.276972189</td>\n",
       "      <td>22.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          corr       nrmse  peak_shift_x\n",
       "0  0.810283484 0.416328933  30.000000000\n",
       "2  0.012215897 0.483568490  26.000000000\n",
       "3  0.892828859 0.264860740   2.000000000\n",
       "4 -0.229041110 0.516809621  32.000000000\n",
       "5  0.224708122 0.276972189  22.000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>peak_shift_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000000</td>\n",
       "      <td>180.000000000</td>\n",
       "      <td>180.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.361053269</td>\n",
       "      <td>0.336538736</td>\n",
       "      <td>31.188888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.470607168</td>\n",
       "      <td>0.132956228</td>\n",
       "      <td>30.473138440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.859315562</td>\n",
       "      <td>0.062624308</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.032602382</td>\n",
       "      <td>0.233682191</td>\n",
       "      <td>6.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.452657995</td>\n",
       "      <td>0.337181735</td>\n",
       "      <td>18.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.769165678</td>\n",
       "      <td>0.431678072</td>\n",
       "      <td>58.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.977728145</td>\n",
       "      <td>0.862287974</td>\n",
       "      <td>100.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               corr         nrmse  peak_shift_x\n",
       "count 180.000000000 180.000000000 180.000000000\n",
       "mean    0.361053269   0.336538736  31.188888889\n",
       "std     0.470607168   0.132956228  30.473138440\n",
       "min    -0.859315562   0.062624308   0.000000000\n",
       "25%     0.032602382   0.233682191   6.000000000\n",
       "50%     0.452657995   0.337181735  18.000000000\n",
       "75%     0.769165678   0.431678072  58.000000000\n",
       "max     0.977728145   0.862287974 100.000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median corr: 0.45265799539665\n",
      "Median nrmse: 0.33718173523084094\n",
      "Median peak_shift_x: 18.0\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 4 â€” Compare + plot (LEFT vs RIGHT) using 3 metrics (across_stable_unit_ids only)\n",
    "# =========================\n",
    "\n",
    "def _interp_curve_to_centers(curve, from_centers, to_centers):\n",
    "    curve = np.asarray(curve, float)\n",
    "    from_centers = np.asarray(from_centers, float)\n",
    "    to_centers = np.asarray(to_centers, float)\n",
    "\n",
    "    finite = np.isfinite(curve) & np.isfinite(from_centers)\n",
    "    if finite.sum() < 2:\n",
    "        return np.full_like(to_centers, np.nan, dtype=float)\n",
    "\n",
    "    x = from_centers[finite]\n",
    "    y = curve[finite]\n",
    "    order = np.argsort(x)\n",
    "    x = x[order]\n",
    "    y = y[order]\n",
    "\n",
    "    out = np.interp(to_centers, x, y)\n",
    "    out[(to_centers < x.min()) | (to_centers > x.max())] = np.nan\n",
    "    return out\n",
    "\n",
    "# Use LEFT centers as the common x-axis\n",
    "centers = np.asarray(centers_left, float)\n",
    "\n",
    "# Align RIGHT onto LEFT centers if needed\n",
    "if not np.allclose(centers_left, centers_right, equal_nan=True):\n",
    "    print(\"Center mismatch: interpolating RIGHT tuning + CI onto LEFT centers.\")\n",
    "    tuning_right_aligned = {u: _interp_curve_to_centers(tuning_right[u], centers_right, centers) for u in tuning_right.keys()}\n",
    "    lo_right_aligned = {u: _interp_curve_to_centers(lo_right[u], centers_right, centers) for u in lo_right.keys()}\n",
    "    hi_right_aligned = {u: _interp_curve_to_centers(hi_right[u], centers_right, centers) for u in hi_right.keys()}\n",
    "else:\n",
    "    tuning_right_aligned = tuning_right\n",
    "    lo_right_aligned = lo_right\n",
    "    hi_right_aligned = hi_right\n",
    "\n",
    "# Units to compare: across-stable AND present in both curves\n",
    "plot_units = [u for u in across_stable_unit_ids if (u in tuning_left) and (u in tuning_right_aligned)]\n",
    "print(\"Units compared:\", len(plot_units))\n",
    "if len(plot_units) == 0:\n",
    "    raise ValueError(\"No units left after restricting to across_stable_unit_ids âˆ© (leftâˆ©right).\")\n",
    "\n",
    "# Subset dicts so plotting funcs only see the units you want\n",
    "tuning_left_plot = {u: tuning_left[u] for u in plot_units}\n",
    "lo_left_plot = {u: lo_left[u] for u in plot_units}\n",
    "hi_left_plot = {u: hi_left[u] for u in plot_units}\n",
    "\n",
    "tuning_right_plot = {u: tuning_right_aligned[u] for u in plot_units}\n",
    "lo_right_plot = {u: lo_right_aligned[u] for u in plot_units}\n",
    "hi_right_plot = {u: hi_right_aligned[u] for u in plot_units}\n",
    "\n",
    "# Plot (both bootstrapped; sliding-window bins)\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_left_plot,\n",
    "    lo_left_plot,\n",
    "    hi_left_plot,\n",
    "    centers,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"OUTBOUND LEFT (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tuning_right_plot,\n",
    "    lo_right_plot,\n",
    "    hi_right_plot,\n",
    "    centers,\n",
    "    column=speed_col,\n",
    "    n_units=30,\n",
    "    label=\"OUTBOUND RIGHT (bootstrap; across-stable; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Metrics \n",
    "metrics_lr = {}\n",
    "for u in plot_units:\n",
    "    a = np.asarray(tuning_left_plot[u], float)\n",
    "    b = np.asarray(tuning_right_plot[u], float)\n",
    "    metrics_lr[u] = dict(\n",
    "        corr=curve_corr(a, b, min_bins=min_units_ok_bins),\n",
    "        nrmse=nrmse(a, b, min_bins=min_units_ok_bins),\n",
    "        peak_shift_x=peak_shift_x(a, b, centers, min_bins=min_units_ok_bins),\n",
    "    )\n",
    "\n",
    "metrics_df_lr = pd.DataFrame.from_dict(metrics_lr, orient=\"index\")\n",
    "display(metrics_df_lr.head())\n",
    "display(metrics_df_lr.describe())\n",
    "\n",
    "print(\"Median corr:\", float(metrics_df_lr[\"corr\"].median(skipna=True)))\n",
    "print(\"Median nrmse:\", float(metrics_df_lr[\"nrmse\"].median(skipna=True)))\n",
    "print(\"Median peak_shift_x:\", float(metrics_df_lr[\"peak_shift_x\"].median(skipna=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6d7b8115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts: {'stable': 62, 'unstable': 118, 'insufficient': 0}\n",
      "Thresholds: {'corr_thresh': 0.3, 'nrmse_thresh': 0.5, 'peak_shift_thresh': 10}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 6 â€” Bar plot: stable vs unstable vs insufficient (across_stable_unit_ids only)\n",
    "# (Threshold-based classification from metrics_df_lr; mirrors the structure of your earlier barplots.)\n",
    "# =========================\n",
    "\n",
    "# Choose thresholds\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh =10\n",
    "\n",
    "if \"metrics_df_lr\" not in globals():\n",
    "    raise ValueError(\"Expected `metrics_df_lr` from the left/right comparison cell.\")\n",
    "\n",
    "labels_lr = {}\n",
    "for u in across_stable_unit_ids:\n",
    "    if u not in metrics_df_lr.index:\n",
    "        labels_lr[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    row = metrics_df_lr.loc[u]\n",
    "    c = float(row[\"corr\"]) if np.isfinite(row[\"corr\"]) else np.nan\n",
    "    e = float(row[\"nrmse\"]) if np.isfinite(row[\"nrmse\"]) else np.nan\n",
    "    p = float(row[\"peak_shift_x\"]) if np.isfinite(row[\"peak_shift_x\"]) else np.nan\n",
    "\n",
    "    if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "        labels_lr[u] = \"insufficient\"\n",
    "        continue\n",
    "\n",
    "    is_stable = (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh)\n",
    "    labels_lr[u] = \"stable\" if is_stable else \"unstable\"\n",
    "\n",
    "cats = [\"stable\", \"unstable\", \"insufficient\"]\n",
    "counts = {c: list(labels_lr.values()).count(c) for c in cats}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.2*2.2, 3.2*2.2), layout=\"tight\")\n",
    "\n",
    "if \"colors\" in globals() and isinstance(colors, (list, tuple)) and len(colors) >= 3:\n",
    "    bar_colors = [colors[0], colors[1], colors[2]]\n",
    "else:\n",
    "    bar_colors = [\"tab:green\", \"tab:orange\", \"tab:gray\"]\n",
    "\n",
    "ax.bar(cats, [counts[c] for c in cats], color=bar_colors, alpha=0.9)\n",
    "ax.set_ylabel(\"Number of units\")\n",
    "ax.set_title(\"Outbound Left vs Right: across-stable units\")\n",
    "\n",
    "for i, c in enumerate(cats):\n",
    "    ax.text(i, counts[c] + 0.5, str(counts[c]), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Counts:\", counts)\n",
    "print(\"Thresholds:\", dict(corr_thresh=corr_thresh, nrmse_thresh=nrmse_thresh, peak_shift_thresh=peak_shift_thresh))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "77b661c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing variables: ['metrics_df_progress', 'metrics_df_inout']\nMake sure you snapshot metrics_df after each pipeline:\n  metrics_df_progress = metrics_df.copy()\n  metrics_df_inout = metrics_df.copy()\n  metrics_df_lr = metrics_df_lr.copy()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m missing \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m required \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure you snapshot metrics_df after each pipeline:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  metrics_df_progress = metrics_df.copy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  metrics_df_inout = metrics_df.copy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  metrics_df_lr = metrics_df_lr.copy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# thresholds (match your barplot logic; edit once and keep consistent)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m corr_thresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Missing variables: ['metrics_df_progress', 'metrics_df_inout']\nMake sure you snapshot metrics_df after each pipeline:\n  metrics_df_progress = metrics_df.copy()\n  metrics_df_inout = metrics_df.copy()\n  metrics_df_lr = metrics_df_lr.copy()\n"
     ]
    }
   ],
   "source": [
    "required = [\"metrics_df_progress\", \"metrics_df_inout\", \"metrics_df_lr\", \"across_stable_unit_ids\"]\n",
    "missing = [v for v in required if v not in globals()]\n",
    "if missing:\n",
    "    raise ValueError(\n",
    "        f\"Missing variables: {missing}\\n\"\n",
    "        \"Make sure you snapshot metrics_df after each pipeline:\\n\"\n",
    "        \"  metrics_df_progress = metrics_df.copy()\\n\"\n",
    "        \"  metrics_df_inout = metrics_df.copy()\\n\"\n",
    "        \"  metrics_df_lr = metrics_df_lr.copy()\\n\"\n",
    "    )\n",
    "\n",
    "# thresholds (match your barplot logic; edit once and keep consistent)\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh = 10\n",
    "\n",
    "def robust_set(metrics_df: pd.DataFrame, unit_ids):\n",
    "    need_cols = {\"corr\", \"nrmse\", \"peak_shift_x\"}\n",
    "    if not need_cols.issubset(metrics_df.columns):\n",
    "        raise ValueError(f\"metrics_df missing columns {need_cols}; got {list(metrics_df.columns)}\")\n",
    "\n",
    "    stable = set()\n",
    "    insufficient = set()\n",
    "    unstable = set()\n",
    "\n",
    "    for u in unit_ids:\n",
    "        if u not in metrics_df.index:\n",
    "            insufficient.add(u)\n",
    "            continue\n",
    "\n",
    "        c = metrics_df.loc[u, \"corr\"]\n",
    "        e = metrics_df.loc[u, \"nrmse\"]\n",
    "        p = metrics_df.loc[u, \"peak_shift_x\"]\n",
    "\n",
    "        if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "            insufficient.add(u)\n",
    "            continue\n",
    "\n",
    "        if (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh):\n",
    "            stable.add(u)\n",
    "        else:\n",
    "            unstable.add(u)\n",
    "\n",
    "    return stable, unstable, insufficient\n",
    "\n",
    "unit_ids = list(across_stable_unit_ids)\n",
    "\n",
    "stable_prog, unstable_prog, insuff_prog = robust_set(metrics_df_progress, unit_ids)\n",
    "stable_inout, unstable_inout, insuff_inout = robust_set(metrics_df_inout, unit_ids)\n",
    "stable_lr, unstable_lr, insuff_lr = robust_set(metrics_df_lr, unit_ids)\n",
    "\n",
    "print(\"Counts (restricted to across_stable_unit_ids):\")\n",
    "print(\"  progress balancing: stable\", len(stable_prog), \"unstable\", len(unstable_prog), \"insufficient\", len(insuff_prog))\n",
    "print(\"  inbound vs outbound: stable\", len(stable_inout), \"unstable\", len(unstable_inout), \"insufficient\", len(insuff_inout))\n",
    "print(\"  left vs right:       stable\", len(stable_lr), \"unstable\", len(unstable_lr), \"insufficient\", len(insuff_lr))\n",
    "\n",
    "# overlap of \"robust\" (stable) sets\n",
    "all_three = stable_prog & stable_inout & stable_lr\n",
    "prog_only = stable_prog - (stable_inout | stable_lr)\n",
    "inout_only = stable_inout - (stable_prog | stable_lr)\n",
    "lr_only = stable_lr - (stable_prog | stable_inout)\n",
    "\n",
    "print(\"\\nOverlap of ROBUST (stable) units:\")\n",
    "print(\"  stable in ALL 3:\", len(all_three))\n",
    "print(\"  stable only progress:\", len(prog_only))\n",
    "print(\"  stable only in/out:\", len(inout_only))\n",
    "print(\"  stable only L/R:\", len(lr_only))\n",
    "print(\"  progress âˆ© in/out:\", len(stable_prog & stable_inout))\n",
    "print(\"  progress âˆ© L/R:\", len(stable_prog & stable_lr))\n",
    "print(\"  in/out âˆ© L/R:\", len(stable_inout & stable_lr))\n",
    "\n",
    "def jacc(a, b):\n",
    "    a = set(a); b = set(b)\n",
    "    return np.nan if len(a | b) == 0 else len(a & b) / len(a | b)\n",
    "\n",
    "print(\"\\nJaccard similarity (stable sets):\")\n",
    "print(\"  progress vs in/out:\", jacc(stable_prog, stable_inout))\n",
    "print(\"  progress vs L/R:\", jacc(stable_prog, stable_lr))\n",
    "print(\"  in/out vs L/R:\", jacc(stable_inout, stable_lr))\n",
    "\n",
    "# per-unit summary table (so you can see if itâ€™s the same units)\n",
    "summary = pd.DataFrame(\n",
    "    {\n",
    "        \"robust_progress\": [u in stable_prog for u in unit_ids],\n",
    "        \"robust_inout\": [u in stable_inout for u in unit_ids],\n",
    "        \"robust_lr\": [u in stable_lr for u in unit_ids],\n",
    "        \"insuff_progress\": [u in insuff_prog for u in unit_ids],\n",
    "        \"insuff_inout\": [u in insuff_inout for u in unit_ids],\n",
    "        \"insuff_lr\": [u in insuff_lr for u in unit_ids],\n",
    "    },\n",
    "    index=unit_ids,\n",
    ")\n",
    "\n",
    "summary[\"n_robust\"] = summary[[\"robust_progress\", \"robust_inout\", \"robust_lr\"]].sum(axis=1)\n",
    "summary[\"n_insufficient\"] = summary[[\"insuff_progress\", \"insuff_inout\", \"insuff_lr\"]].sum(axis=1)\n",
    "\n",
    "display(summary.sort_values([\"n_robust\", \"n_insufficient\"], ascending=[False, True]).head(40))\n",
    "\n",
    "print(\"\\nFirst 25 stable in all 3:\", sorted(list(all_three))[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aae2b0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unstable units across LEFT vs RIGHT: 125\n",
      "First 30 L/R-unstable unit IDs: [0, 2, 4, 5, 6, 9, 10, 13, 18, 19, 23, 30, 31, 32, 34, 40, 41, 42, 43, 46, 49, 62, 64, 65, 67, 68, 69, 72, 73, 75]\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell â€” Plot L/R-ROBUST units (OUTBOUND LEFT vs OUTBOUND RIGHT)\n",
    "# Produces TWO figures:\n",
    "#   1) OUTBOUND LEFT tuning curves grid (only units stable across left vs right)\n",
    "#   2) OUTBOUND RIGHT tuning curves grid (same unit set)\n",
    "#\n",
    "# \"stable units L/R\" = units whose left vs right curves are similar\n",
    "# by your 3 metrics (corr high, nrmse low, peak_shift_x low), AND finite metrics.\n",
    "#\n",
    "# Expects (from your left/right pipeline):\n",
    "# - tuning_left, lo_left, hi_left, centers_left\n",
    "# - tuning_right_aligned, lo_right_aligned, hi_right_aligned (or tuning_right/lo_right/hi_right + centers_right)\n",
    "# - metrics_df_lr (your L/R metrics table with corr/nrmse/peak_shift_x; index=unit_id)\n",
    "# - across_stable_unit_ids\n",
    "# =========================\n",
    "\n",
    "if \"across_stable_unit_ids\" not in globals():\n",
    "    raise ValueError(\"Expected `across_stable_unit_ids` to exist.\")\n",
    "\n",
    "# metrics table for left/right\n",
    "if \"metrics_df_lr\" in globals():\n",
    "    metrics_df_use = metrics_df_lr\n",
    "elif \"metrics_df_leftright\" in globals():\n",
    "    metrics_df_use = metrics_df_leftright\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Could not find left/right metrics table (`metrics_df_lr` or `metrics_df_leftright`).\\n\"\n",
    "        \"Make sure you ran the L/R comparison cell that creates `metrics_df_lr`.\"\n",
    "    )\n",
    "\n",
    "need_cols = {\"corr\", \"nrmse\", \"peak_shift_x\"}\n",
    "if not need_cols.issubset(set(metrics_df_use.columns)):\n",
    "    raise ValueError(f\"L/R metrics table missing columns {need_cols}; got {list(metrics_df_use.columns)}\")\n",
    "\n",
    "# thresholds (edit to match other sections)\n",
    "corr_thresh = 0.3\n",
    "nrmse_thresh = 0.5\n",
    "peak_shift_thresh = 10  \n",
    "\n",
    "# Ensure right-aligned dicts exist; if not, fall back\n",
    "if \"tuning_right_aligned\" not in globals():\n",
    "    if \"tuning_right\" not in globals():\n",
    "        raise ValueError(\"Missing `tuning_right_aligned` (or `tuning_right`). Run your L/R alignment cell first.\")\n",
    "    tuning_right_aligned = tuning_right\n",
    "    lo_right_aligned = lo_right\n",
    "    hi_right_aligned = hi_right\n",
    "\n",
    "# Use LEFT centers as the shared x-axis\n",
    "centers = np.asarray(centers_left, float)\n",
    "\n",
    "# Compute the stable (robust) unit set: across_stable_unit_ids + finite metrics + passes thresholds\n",
    "stable_units_lr = []\n",
    "for u in across_stable_unit_ids:\n",
    "    if u not in metrics_df_use.index:\n",
    "        continue\n",
    "\n",
    "    c = metrics_df_use.loc[u, \"corr\"]\n",
    "    e = metrics_df_use.loc[u, \"nrmse\"]\n",
    "    p = metrics_df_use.loc[u, \"peak_shift_x\"]\n",
    "\n",
    "    if not (np.isfinite(c) and np.isfinite(e) and np.isfinite(p)):\n",
    "        continue\n",
    "\n",
    "    # is_stable = (c >= corr_thresh) and (e <= nrmse_thresh) and (p <= peak_shift_thresh)\n",
    "    is_stable = (c <= corr_thresh) or (e >= nrmse_thresh) or (p >= peak_shift_thresh)\n",
    "    if is_stable:\n",
    "        stable_units_lr.append(u)\n",
    "\n",
    "# Ensure each unit exists in BOTH tuning dicts + CI dicts\n",
    "stable_units_lr = [\n",
    "    u for u in stable_units_lr\n",
    "    if (u in tuning_left) and (u in lo_left) and (u in hi_left)\n",
    "    and (u in tuning_right_aligned) and (u in lo_right_aligned) and (u in hi_right_aligned)\n",
    "]\n",
    "\n",
    "print(\"Unstable units across LEFT vs RIGHT:\", len(stable_units_lr))\n",
    "if len(stable_units_lr) == 0:\n",
    "    raise ValueError(\"No L/R-stable units found under these thresholds (or missing tuning/CI entries).\")\n",
    "\n",
    "# Subset dicts so the plotting function only sees the units you want\n",
    "tun_left_stable = {u: tuning_left[u] for u in stable_units_lr}\n",
    "lo_left_stable  = {u: lo_left[u]     for u in stable_units_lr}\n",
    "hi_left_stable  = {u: hi_left[u]     for u in stable_units_lr}\n",
    "\n",
    "tun_right_stable = {u: tuning_right_aligned[u] for u in stable_units_lr}\n",
    "lo_right_stable  = {u: lo_right_aligned[u]     for u in stable_units_lr}\n",
    "hi_right_stable  = {u: hi_right_aligned[u]     for u in stable_units_lr}\n",
    "\n",
    "col_label = speed_col if \"speed_col\" in globals() else \"speed_norm\"\n",
    "\n",
    "# Figure 1: OUTBOUND LEFT\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tun_left_stable,\n",
    "    lo_left_stable,\n",
    "    hi_left_stable,\n",
    "    centers,\n",
    "    column=col_label,\n",
    "    n_units=30,\n",
    "    label=\"OUTBOUND LEFT (L/R-unstable units; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "# Figure 2: OUTBOUND RIGHT\n",
    "plot_tuning_grid_bootstrap(\n",
    "    tun_right_stable,\n",
    "    lo_right_stable,\n",
    "    hi_right_stable,\n",
    "    centers,\n",
    "    column=col_label,\n",
    "    n_units=30,\n",
    "    label=\"OUTBOUND RIGHT (L/R-unstable units; sliding)\",\n",
    "    indices=None,\n",
    "    s=5,\n",
    "    linewidth=2,\n",
    "    peak_normalize=True,\n",
    ")\n",
    "\n",
    "print(\"First 30 L/R-unstable unit IDs:\", stable_units_lr[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "98750141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>peak_shift_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.810283484</td>\n",
       "      <td>0.416328933</td>\n",
       "      <td>30.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012215897</td>\n",
       "      <td>0.483568490</td>\n",
       "      <td>26.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.892828859</td>\n",
       "      <td>0.264860740</td>\n",
       "      <td>2.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.229041110</td>\n",
       "      <td>0.516809621</td>\n",
       "      <td>32.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.224708122</td>\n",
       "      <td>0.276972189</td>\n",
       "      <td>22.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          corr       nrmse  peak_shift_x\n",
       "0  0.810283484 0.416328933  30.000000000\n",
       "2  0.012215897 0.483568490  26.000000000\n",
       "3  0.892828859 0.264860740   2.000000000\n",
       "4 -0.229041110 0.516809621  32.000000000\n",
       "5  0.224708122 0.276972189  22.000000000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_use.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0aa028c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>peak_shift_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.810283484</td>\n",
       "      <td>0.416328933</td>\n",
       "      <td>30.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012215897</td>\n",
       "      <td>0.483568490</td>\n",
       "      <td>26.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.892828859</td>\n",
       "      <td>0.264860740</td>\n",
       "      <td>2.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.229041110</td>\n",
       "      <td>0.516809621</td>\n",
       "      <td>32.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.224708122</td>\n",
       "      <td>0.276972189</td>\n",
       "      <td>22.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          corr       nrmse  peak_shift_x\n",
       "0  0.810283484 0.416328933  30.000000000\n",
       "2  0.012215897 0.483568490  26.000000000\n",
       "3  0.892828859 0.264860740   2.000000000\n",
       "4 -0.229041110 0.516809621  32.000000000\n",
       "5  0.224708122 0.276972189  22.000000000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_lr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0da5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a48aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyglass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
